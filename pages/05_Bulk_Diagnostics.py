import streamlit as st
import pandas as pd
import json
import os
from core.phonology import sanskrit_varna_vichhed, sanskrit_varna_samyoga
from core.it_sanjna_engine import ItSanjnaEngine
from core.upadesha_registry import UpadeshaType

# --- рез. рдкреЗрдЬ рд╕реЗрдЯрдЕрдк ---
st.set_page_config(page_title="Bulk Diagnostics - рдЕрд╖реНрдЯрд╛рдзреНрдпрд╛рдпреА-рдпрдВрддреНрд░", layout="wide")
st.title("ЁЯУК рд╡реГрд╣рджреН рд╡реНрдпрд╛рдХрд░рдгрд┐рдХ рдкрд░реАрдХреНрд╖рдг (Bulk Diagnostics)")
st.caption("реирежрежреж+ рдЙрдкрджреЗрд╢реЛрдВ рдХрд╛ рдПрдХ рд╕рд╛рде рдЗрддреН-рд╕рдВрдЬреНрдЮрд╛ рдПрд╡рдВ рдЕрдЩреНрдЧ-рдкреНрд░рд╛рдкреНрддрд┐ рд╡рд┐рд╢реНрд▓реЗрд╖рдг")


# --- реи. рдбреЗрдЯрд╛ рд▓реЛрдбрд░ ---
@st.cache_data
def load_all_datasets():
    files = {
        "Dhatupatha": "dhatu_master_structured.json",
        "Krit Pratyaya": "krit_pratyayas.json",
        "Taddhita Pratyaya": "taddhita_master_data.json",
        "Vibhakti": "vibhaktipatha.json"
    }
    loaded = {}
    for label, fname in files.items():
        path = f'data/{fname}'
        if os.path.exists(path):
            with open(path, 'r', encoding='utf-8') as f:
                loaded[label] = json.load(f)
    return loaded


all_datasets = load_all_datasets()


# --- рей. рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдЗрдВрдЬрди (Batch Processor) ---
def run_bulk_test(data_list, source_type):
    report = []

    # рдХреА-рдореИрдкрд┐рдВрдЧ (Key Mapping)
    # рдбреЗрдЯрд╛рдмреЗрд╕ рдореЗрдВ 'upadesha' рдпрд╛ 'pratyay' рдЕрд▓рдЧ-рдЕрд▓рдЧ рдирд╛рдо рд╕реЗ рд╣реЛ рд╕рдХрддреЗ рд╣реИрдВ
    search_key = ""
    if data_list:
        sample = data_list[0]
        search_key = 'upadesha' if 'upadesha' in sample else \
            ('pratyay' if 'pratyay' in sample else 'name')

    for entry in data_list:
        original = str(entry.get(search_key, ""))
        if not original: continue

        # рез. рд╡рд┐рдЪреНрдЫреЗрдж
        v_list = sanskrit_varna_vichhed(original)

        # реи. рдЗрддреН-рд╕рдВрдЬреНрдЮрд╛ (рдХреМрдореБрджреА рдХреНрд░рдо)
        # рддрджреНрдзрд┐рдд рдХреЗ рд▓рд┐рдП рд╡рд┐рд╢реЗрд╖ рдЪреЗрдХ
        is_taddhita = "рддрджреНрдзрд┐рдд" in str(entry.get('note', '')) or "рддрджреНрдзрд┐рдд" in str(entry.get('meaning', ''))

        remaining, tags = ItSanjnaEngine.run_it_sanjna_prakaran(
            varna_list=v_list.copy(),
            original_input=original,
            source_type=source_type,
            is_taddhita=is_taddhita
        )

        # рей. рдЕрдЩреНрдЧ рдирд┐рд░реНрдорд╛рдг
        final_anga = sanskrit_varna_samyoga(remaining)

        report.append({
            "Original (рдЙрдкрджреЗрд╢)": original,
            "Type": source_type.value,
            "Anga (рдЕрдЩреНрдЧ)": final_anga,
            "Sutras Applied": ", ".join(tags) if tags else "None",
            "Meaning": entry.get('meaning', entry.get('artha_sanskrit', '-'))
        })

    return pd.DataFrame(report)


# --- рек. рдпреВрдЖрдИ рдХрдВрдЯреНрд░реЛрд▓реНрд╕ (UI Controls) ---
if not all_datasets:
    st.error("рдбреЗрдЯрд╛ рдлреЛрд▓реНрдбрд░ рдореЗрдВ рдХреЛрдИ JSON рдлрд╛рдЗрд▓ рдирд╣реАрдВ рдорд┐рд▓реАред")
else:
    db_choice = st.selectbox("рдкрд░реАрдХреНрд╖рдг рдХреЗ рд▓рд┐рдП рдбреЗрдЯрд╛рдмреЗрд╕ рдЪреБрдиреЗрдВ:", options=list(all_datasets.keys()))

    # рдЯрд╛рдЗрдк рдореИрдкрд┐рдВрдЧ
    type_map = {
        "Dhatupatha": UpadeshaType.DHATU,
        "Krit Pratyaya": UpadeshaType.PRATYAYA,
        "Taddhita Pratyaya": UpadeshaType.PRATYAYA,
        "Vibhakti": UpadeshaType.VIBHAKTI
    }

    if st.button(f"ЁЯЪА {db_choice} рдХрд╛ рдкрд░реАрдХреНрд╖рдг рд╢реБрд░реВ рдХрд░реЗрдВ"):
        with st.spinner(f"{db_choice} рдХреЗ рдЙрджрд╛рд╣рд░рдгреЛрдВ рдХреЛ рд╕реНрдХреИрди рдХрд┐рдпрд╛ рдЬрд╛ рд░рд╣рд╛ рд╣реИ..."):
            df_report = run_bulk_test(all_datasets[db_choice], type_map[db_choice])

            st.success(f"рдХреБрд▓ {len(df_report)} рдЙрджрд╛рд╣рд░рдгреЛрдВ рдХрд╛ рдкрд░реАрдХреНрд╖рдг рд╕рдлрд▓ рд░рд╣рд╛!")

            # рел. рдореЗрдЯреНрд░рд┐рдХреНрд╕ рдФрд░ рдлрд┐рд▓реНрдЯрд░реНрд╕
            st.subheader("ЁЯУИ рдкрд░реАрдХреНрд╖рдг рдореЗрдЯреНрд░рд┐рдХреНрд╕")
            c1, c2, c3 = st.columns(3)
            c1.metric("рдХреБрд▓ рдЙрджрд╛рд╣рд░рдг", len(df_report))
            # рдХрд┐рддрдиреЗ рд╢рдмреНрджреЛрдВ рдореЗрдВ рдЗрддреН-рд╕рдВрдЬреНрдЮрд╛ рд╣реБрдИ
            it_count = len(df_report[df_report['Sutras Applied'] != "None"])
            c2.metric("рдЗрддреН-рд╕рдВрдЬреНрдЮрд╛ рд╡рд╛рд▓реЗ рд╢рдмреНрдж", it_count)
            c3.metric("рдЕрдкрд░рд┐рд╡рд░реНрддрд┐рдд рд╢рдмреНрдж", len(df_report) - it_count)

            # рем. рдкрд░рд┐рдгрд╛рдо рддрд╛рд▓рд┐рдХрд╛ (Interactive Table)
            st.markdown("### ЁЯУЛ рд╡рд┐рд╕реНрддреГрдд рд░рд┐рдкреЛрд░реНрдЯ")
            st.dataframe(df_report, use_container_width=True)

            # рен. рдбрд╛рдЙрдирд▓реЛрдб рдмрдЯрди (Excel/CSV Export)
            csv = df_report.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="ЁЯУе рдкрд░реАрдХреНрд╖рдг рд░рд┐рдкреЛрд░реНрдЯ рдбрд╛рдЙрдирд▓реЛрдб рдХрд░реЗрдВ (CSV)",
                data=csv,
                file_name=f"Panini_Bulk_Test_{db_choice}.csv",
                mime='text/csv',
            )