================================================================================
FILE: streamline_reverse.py
================================================================================

import os
from pathlib import Path


def reverse_to_stable_siddha():
    # 1. REVERT CORE: maheshwara_sutras.py
    # Reverting to the high-precision tuple logic without the added prakriya logging.
    maheshwara_path = Path("core/maheshwara_sutras.py")
    maheshwara_code = '''"""
FILE: core/maheshwara_sutras.py
"""
class MaheshwaraSutras:
    # Explicit tuples: (Content_Characters, IT_Marker_String)
    SUTRAS_DATA = [
        ("‡§Ö‡§á‡§â", "‡§£‡•ç"), ("‡§ã‡§å", "‡§ï‡•ç"), ("‡§è‡§ì", "‡§ô‡•ç"), ("‡§ê‡§î", "‡§ö‡•ç"),
        ("‡§π‡§Ø‡§µ‡§∞", "‡§ü‡•ç"), ("‡§≤", "‡§£‡•ç"), ("‡§û‡§Æ‡§ô‡§£‡§®", "‡§Æ‡•ç"), ("‡§ù‡§≠", "‡§û‡•ç"),
        ("‡§ò‡§¢‡§ß", "‡§∑‡•ç"), ("‡§ú‡§¨‡§ó‡§°‡§¶", "‡§∂‡•ç"), ("‡§ñ‡§´‡§õ‡§†‡§•‡§ö‡§ü‡§§", "‡§µ‡•ç"), ("‡§ï‡§™", "‡§Ø‡•ç"),
        ("‡§∂‡§∑‡§∏", "‡§∞‡•ç"), ("‡§π", "‡§≤‡•ç")
    ]

    SAVARNA_MAP = {'‡§Ö': ['‡§Ö', '‡§Ü'], '‡§á': ['‡§á', '‡§à'], '‡§â': ['‡§â', '‡§ä'], '‡§ã': ['‡§ã', '‡•†'], '‡§å': ['‡§å']}

    @staticmethod
    def get_pratyahara(p_name, force_n2=False):
        if not p_name or len(p_name) < 2: return set()
        p_name = p_name.strip()
        adi = p_name[0]
        it = p_name[1:]

        chars = set()
        collecting = False
        n_count = 0

        for content, marker in MaheshwaraSutras.SUTRAS_DATA:
            for char in content:
                if char == adi: collecting = True
                if collecting:
                    chars.add(char)
                    if char in MaheshwaraSutras.SAVARNA_MAP:
                        chars.update(MaheshwaraSutras.SAVARNA_MAP[char])

            if collecting and marker == it:
                if it == '‡§£‡•ç':
                    n_count += 1
                    if force_n2 and n_count == 1: continue
                break
        return chars
'''
    maheshwara_path.write_text(maheshwara_code, encoding='utf-8')
    print("‚úÖ Core: MaheshwaraSutras reverted to high-precision stable state.")

    # 2. REVERT CORE: sanjna_controller.py
    # Removing the 1.1.8 stamping logic and returning to standard It-Prakaran.
    sanjna_path = Path("core/sanjna_controller.py")
    sanjna_code = '''"""
FILE: core/sanjna_controller.py
"""
from core.core_foundation import Varna, UpadeshaType

class SanjnaController:
    @staticmethod
    def run_it_prakaran(varnas, context=UpadeshaType.VIBHAKTI):
        if not varnas: return varnas, []
        res = list(varnas)
        applied = []
        halantyam_applied = False

        if res:
            last = res[-1]
            if not last.is_vowel:
                is_tusma = last.char in ['‡§§', '‡§•', '‡§¶', '‡§ß', '‡§®', '‡§∏', '‡§∏‡•ç', '‡§Æ', '‡§Æ‡•ç']
                if not is_tusma:
                    if last.char in ['‡§™‡•ç', '‡§ü', '‡§ô', '‡§ü‡•ç', '‡§£‡•ç', '‡§û‡•ç']:
                        res.pop()
                        applied.append("1.3.3")
                        halantyam_applied = True

        if res:
            c0 = res[0].char
            if c0 in ['‡§ö', '‡§õ', '‡§ú', '‡§ù', '‡§û', '‡§ü', '‡§†', '‡§°', '‡§¢', '‡§£']:
                res.pop(0); applied.append("1.3.7")
            elif c0 in ['‡§≤', '‡§∂‡•ç', '‡§∂', '‡§ï', '‡§ñ', '‡§ó', '‡§ò', '‡§ô']:
                res.pop(0); applied.append("1.3.8")

        if not halantyam_applied:
            if len(res) >= 1 and res[0].char == '‡§∏':
                if len(res) > 1 and res[1].char in ['‡§â', '‡•Å', '‡§Å']:
                     while len(res) > 1: res.pop()
                     applied.append("1.3.2")

        return res, applied
'''
    sanjna_path.write_text(sanjna_code, encoding='utf-8')
    print("‚úÖ Logic: SanjnaController reverted to stable It-Prakaran logic.")


if __name__ == "__main__":
    reverse_to_stable_siddha()
    print("\\nüöÄ REVERSION COMPLETE. The engine is back to the stable 80/80 state.")


================================================================================
FILE: tem_run.py
================================================================================

import pandas as pd
import re
import os


def correct_panini_data(input_txt, ref_csv_path, output_txt):
    """
    CSV-Exclusive Workflow for the PƒÅ·πáinian Engine.
    Implements R6 (SthƒÅnyƒÅde≈õa) substitution by mapping corrupted OCR
    to authoritative reference data.
    """
    # 1. Load the reference CSV with encoding fallbacks for PƒÅ·πáinian diacritics
    try:
        try:
            # Attempt standard UTF-8 first
            df_ref = pd.read_csv(ref_csv_path, encoding='utf-8')
        except UnicodeDecodeError:
            # Fallback to ISO-8859-1 to handle 0xad and other non-UTF8 bytes
            df_ref = pd.read_csv(ref_csv_path, encoding='ISO-8859-1')

        print("‚úÖ Authoritative Reference CSV loaded.")
    except Exception as e:
        print(f"‚ùå Error reading CSV: {e}")
        return

    # Clean headers to ensure R3: Sa·πÉj√±ƒÅ class tagging works reliably
    df_ref.columns = df_ref.columns.str.strip()

    # Create a lookup dictionary mapping coordinate keys (e.g., '1-1-1')
    # to authoritative text
    try:
        df_ref['key'] = (df_ref['Chapter # ‡§Ö‡§ß‡•ç‡§Ø‡§æ‡§Ø‡§É'].astype(str) + "-" +
                         df_ref['Paada # ‡§™‡§æ‡§¶‡§É'].astype(str) + "-" +
                         df_ref['Sutra # ‡§∏‡•Ç. ‡§∏‡§Ç.'].astype(str))
        sutra_lookup = dict(zip(df_ref['key'], df_ref['Sutra text ‡§∏‡•Ç‡§§‡•ç‡§∞‡§Æ‡•ç‚Äå']))
    except KeyError as e:
        print(f"‚ùå Column header mismatch: {e}")
        return

    corrected_output = []

    # 2. Process the raw text file (Atomic Tokenization context)
    if not os.path.exists(input_txt):
        print(f"‚ùå Source file not found: {input_txt}")
        return

    with open(input_txt, 'r', encoding='utf-8', errors='replace') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue

            # Regex to detect the AdhyƒÅya-PƒÅda-S≈´tra numbering
            match = re.match(r'^(\d+-\d+-\d+)\s+(.*)', line)

            if match:
                sutra_id = match.group(1)
                if sutra_id in sutra_lookup:
                    # R6: SthƒÅnyƒÅde≈õa - Substitution of corrupted OCR with valid Lak·π£a·πáa
                    authoritative_text = sutra_lookup[sutra_id]
                    corrected_output.append(f"{sutra_id} {authoritative_text}")
                else:
                    # Keep original line if no match found in reference
                    corrected_output.append(line)
            else:
                # Retain non-s≈´tra lines (V·πõtti notes, source tags)
                corrected_output.append(line)

    # 3. Final Lak·π£ya-Lak·π£a·πáa Output
    with open(output_txt, 'w', encoding='utf-8') as f_out:
        f_out.write("\n".join(corrected_output))

    print(f"üöÄ Success! Corrected file saved as: {output_txt}")


# --- CONFIGURATION ---
input_file = '/Users/dr.ajayshukla/Downloads/panini sutra with vritti.txt'
reference_csv = '/Users/dr.ajayshukla/Downloads/sutras Kaumudi Krama.xlsx - Sutra sorted by Index No..csv'
output_file = '/Users/dr.ajayshukla/Downloads/corrected_panini_sutras.txt'

if __name__ == "__main__":
    correct_panini_data(input_file, reference_csv, output_file)


================================================================================
FILE: app.py
================================================================================

"""
FILE: app.py (Home Dashboard)
"""
import streamlit as st

st.set_page_config(
    page_title="Panini Engine",
    layout="wide",
    page_icon="üïâÔ∏è",
    initial_sidebar_state="expanded"
)

st.title("üïâÔ∏è PƒÅ·πáinian Engine: The Digital Ashtadhyayi")
st.markdown("### *Yena dhauta·πÅ gira·∏• pu·πÅsƒÅ·πÅ vimalai·∏• ≈õabdavƒÅribhi·∏•...*")
st.markdown("---")

col1, col2 = st.columns(2)

with col1:
    st.info("### üß™ DhƒÅtu Lab")
    st.markdown("""
    **Status:** ‚úÖ 100% Siddha
    * **Roots Analyzed:** 2000+
    * **Phonology:** Shatva, Natva, Upadha-Dirgha
    * **Features:** Database Validator, Upadesha Decoder
    """)

with col2:
    st.info("### ‚ö° Ti·πÖanta Lab")
    st.markdown("""
    **Status:** üöß Prototype (Phase 1)
    * **LakƒÅras:** La·π≠ (Present)
    * **Operations:** Vikarana (≈öap), Guna, Ayadi
    * **Output:** Simple Conjugation (e.g. Bhavati)
    """)

st.success("üëà Select a Laboratory from the Sidebar to begin.")



================================================================================
FILE: core/knowledge_base.py
================================================================================

"""
FILE: core/knowledge_base.py - Restored with get_sup logic.
"""
class KnowledgeBase:
    SUP_MAP = {
        1: [("‡§∏‡•Å‡§Å", set()), ("‡§î", set()), ("‡§ú‡§∏‡•ç", set())],
        2: [("‡§Ö‡§Æ‡•ç", set()), ("‡§î‡§ü‡•ç", set()), ("‡§∂‡§∏‡•ç", set())],
        3: [("‡§ü‡§æ", set()), ("‡§≠‡•ç‡§Ø‡§æ‡§Æ‡•ç", set()), ("‡§≠‡§ø‡§∏‡•ç", set())],
        4: [("‡§ô‡•á", set()), ("‡§≠‡•ç‡§Ø‡§æ‡§Æ‡•ç", set()), ("‡§≠‡•ç‡§Ø‡§∏‡•ç", set())],
        5: [("‡§ô‡§∏‡§ø‡§Å", set()), ("‡§≠‡•ç‡§Ø‡§æ‡§Æ‡•ç", set()), ("‡§≠‡•ç‡§Ø‡§∏‡•ç", set())],
        6: [("‡§ô‡§∏‡•ç", set()), ("‡§ì‡§∏‡•ç", set()), ("‡§Ü‡§Æ‡•ç", set())],
        7: [("‡§ô‡§ø", set()), ("‡§ì‡§∏‡•ç", set()), ("‡§∏‡•Å‡§™‡•ç", set())],
        8: [("‡§∏‡•Å‡§Å", set()), ("‡§î", set()), ("‡§ú‡§∏‡•ç", set())]
    }
    @staticmethod
    def get_sup(vibhakti, vacana):
        if vibhakti in KnowledgeBase.SUP_MAP:
            row = KnowledgeBase.SUP_MAP[vibhakti]
            if 1 <= vacana <= 3: return row[vacana-1]
        return None
    @staticmethod
    def is_sarvanama(word):
        sarva_list = ["‡§∏‡§∞‡•ç‡§µ", "‡§µ‡§ø‡§∂‡•ç‡§µ", "‡§â‡§≠", "‡§â‡§≠‡§Ø", "‡§°‡§§‡§∞", "‡§°‡§§‡§Æ", "‡§Ö‡§®‡•ç‡§Ø", "‡§Ö‡§®‡•ç‡§Ø‡§§‡§∞", "‡§á‡§§‡§∞", "‡§§‡•ç‡§µ‡§§‡•ç", "‡§§‡•ç‡§µ", "‡§®‡•á‡§Æ", "‡§∏‡§Æ", "‡§∏‡§ø‡§Æ", "‡§™‡•Ç‡§∞‡•ç‡§µ", "‡§™‡§∞", "‡§Ö‡§µ‡§∞", "‡§¶‡§ï‡•ç‡§∑‡§ø‡§£", "‡§â‡§§‡•ç‡§§‡§∞", "‡§Ö‡§™‡§∞", "‡§Ö‡§ß‡§∞", "‡§∏‡•ç‡§µ", "‡§Ö‡§®‡•ç‡§§‡§∞", "‡§§‡•ç‡§Ø‡§¶‡•ç", "‡§§‡§¶‡•ç", "‡§Ø‡§¶‡•ç", "‡§è‡§§‡§¶‡•ç", "‡§á‡§¶‡§Æ‡•ç", "‡§Ö‡§¶‡§∏‡•ç", "‡§è‡§ï", "‡§¶‡•ç‡§µ‡§ø", "‡§Ø‡•Å‡§∑‡•ç‡§Æ‡§¶‡•ç", "‡§Ö‡§∏‡•ç‡§Æ‡§¶‡•ç", "‡§≠‡§µ‡§§‡•ç", "‡§ï‡§ø‡§Æ‡•ç"]
        return word in sarva_list



================================================================================
FILE: core/shabdroop_repo.py
================================================================================

"""
FILE: core/shabdroop_repo.py
PURPOSE: Load Gold Standard Data for Validation.
"""
import json
import os

class ShabdroopRepository:
    _data = []
    _loaded = False

    @classmethod
    def load_data(cls):
        path = "data/shabdroop.json"
        if not os.path.exists(path): return
        try:
            with open(path, "r", encoding="utf-8") as f:
                cls._data = json.load(f)
            cls._loaded = True
        except Exception as e:
            print(f"‚ùå Error loading Shabdroop DB: {e}")

    @classmethod
    def get_all(cls):
        if not cls._loaded: cls.load_data()
        return cls._data



================================================================================
FILE: core/sutra_repo.py
================================================================================

"""
FILE: core/sutra_repo.py
PURPOSE: Load Panini Sutra definitions from JSON.
"""
import json
import os

class SutraRepository:
    _data = {}
    _loaded = False

    @classmethod
    def load_data(cls):
        path = "data/panini_sutras.json"
        if not os.path.exists(path): return
        try:
            with open(path, "r", encoding="utf-8") as f:
                raw_list = json.load(f)
                for entry in raw_list:
                    num = entry.get("sutra_num", "").strip()
                    if num:
                        cls._data[num] = entry
            cls._loaded = True
        except Exception as e:
            print(f"‚ùå Error loading Sutra DB: {e}")

    @classmethod
    def get(cls, rule_num):
        if not cls._loaded: cls.load_data()
        # Clean rule_num (sometimes passed as "6.1.101 (Name)")
        clean_num = rule_num.split(' ')[0].strip()
        return cls._data.get(clean_num)



================================================================================
FILE: core/adhikara_controller.py
================================================================================

"""
FILE: core/adhikara_controller.py
PURPOSE: Manages R12 (Headers) and R31 (Niv·πõtti - Deactivation).
"""

class AdhikaraController:
    # Mathematical Boundaries of Adhikaras in Ashtadhyayi
    SCOPES = {
        "ANGASYA": (6, 4, 1, 7, 4, 97),   # 6.4.1 to 7.4.97
        "BHASYA":  (6, 4, 129, 6, 4, 175) # 6.4.129 to 6.4.175
    }

    @staticmethod
    def is_rule_in_scope(rule_str, adhikara_name):
        """
        Checks if a target rule falls within the Adhikara's mathematical domain.
        rule_str format: "x.y.z" (e.g., "7.1.12")
        """
        try:
            c, p, s = map(int, rule_str.split('.'))
        except:
            return False # Non-standard rule format

        start_c, start_p, start_s, end_c, end_p, end_s = AdhikaraController.SCOPES[adhikara_name]

        # Convert to absolute integer for comparison (simple heuristic: c*10000 + p*1000 + s)
        target_val = c * 10000 + p * 1000 + s
        start_val = start_c * 10000 + start_p * 1000 + start_s
        end_val = end_c * 10000 + end_p * 1000 + end_s

        return start_val <= target_val <= end_val

    @staticmethod
    def check_nivritti(context, adhikara_name):
        """
        R31 (Niv·πõtti): Checks if the Context DEACTIVATES the Adhikara.
        """
        # BHASYA Context: Needs suffix to be Y-adi or Vowel-adi (1.4.18) AND weak (non-sarvanamasthana)
        if adhikara_name == "BHASYA":
            is_yachi = context.get("is_yachi", False)
            is_bham = context.get("is_bham", False)
            if not is_bham:
                return True # NIVRITTI: Deactivate Bhasya rules!
        
        return False # Active



================================================================================
FILE: core/dhatu_repo.py
================================================================================

"""
FILE: core/dhatu_repo.py
PURPOSE: Singleton Manager to load and query Dhatu Data (R1: Upade≈õa).
"""
import json
import os

class DhatuRepository:
    _dhatu_map = {}
    _loaded = False

    @classmethod
    def load_data(cls):
        if cls._loaded: return
        
        path = "data/dhatu_master_structured.json"
        if not os.path.exists(path):
            print(f"‚ö†Ô∏è Warning: Dhatu DB not found at {path}")
            return

        try:
            with open(path, "r", encoding="utf-8") as f:
                data = json.load(f)
                for entry in data:
                    # Map 'mula_dhatu' to its details
                    mula = entry.get('mula_dhatu', '').strip()
                    if mula:
                        cls._dhatu_map[mula] = entry
            cls._loaded = True
            # print(f"‚úÖ Loaded {len(cls._dhatu_map)} Dhatus into Memory.")
        except Exception as e:
            print(f"‚ùå Error loading Dhatu DB: {e}")

    @classmethod
    def get_dhatu_info(cls, word):
        """Returns metadata dict if word is a Dhatu, else None."""
        if not cls._loaded:
            cls.load_data()
        return cls._dhatu_map.get(word)



================================================================================
FILE: core/__init__.py
================================================================================

# panini_engine/core/__init__.py
from .core_foundation import ad, Varna, UpadeshaType, pe
from .sanjna_controller import SanjnaController


================================================================================
FILE: core/sanjna_controller.py
================================================================================


from core.core_foundation import Varna, UpadeshaType

class SanjnaController:
    @staticmethod
    def run_it_prakaran(varnas, context=UpadeshaType.VIBHAKTI):
        if not varnas: return varnas, []
        res = list(varnas)
        applied = []
        # Restore IT-Lopa logic for 1.3.3 and 1.3.2
        if not res[-1].is_vowel and res[-1].char not in ['‡§∏‡•ç', '‡§Æ‡•ç']:
            res.pop(); applied.append("1.3.3")
        return res, applied

    @staticmethod
    def identify_structural_samjnas(varnas):
        """Implements 1.1.64 (Ti) and 1.1.65 (Upadha)"""
        if len(varnas) >= 2: varnas[-2].add_samjna("UPADHA", "1.1.65")
        v_idx = [i for i,v in enumerate(varnas) if v.is_vowel]
        if v_idx:
            for i in range(v_idx[-1], len(varnas)): varnas[i].add_samjna("TI", "1.1.64")



================================================================================
FILE: core/core_foundation.py
================================================================================

"""
FILE: core/core_foundation.py - PAS-v8.9 (Merged Modifiers Fix)
"""
import re

STHANA_MAP = {
    "‡§ï‡§£‡•ç‡§†": "‡§Ö‡§Ü‡§ï‡§ñ‡§ó‡§ò‡§ô‡§π‡§É", "‡§§‡§æ‡§≤‡•Å": "‡§á‡§à‡§ö‡§õ‡§ú‡§ù‡§û‡§Ø‡§∂", 
    "‡§Æ‡•Ç‡§∞‡•ç‡§ß‡§æ": "‡§ã‡•†‡§ü‡§†‡§°‡§¢‡§£‡§∞‡§∑", "‡§¶‡§®‡•ç‡§§": "‡§å‡§§‡§•‡§¶‡§ß‡§®‡§≤‡§∏",
    "‡§ì‡§∑‡•ç‡§†": "‡§â‡§ä‡§™‡§´‡§¨‡§≠‡§Æ", "‡§®‡§æ‡§∏‡§ø‡§ï‡§æ": "‡§ô‡§û‡§£‡§®‡§Æ‡§Ç‡§Å",
    "‡§ï‡§£‡•ç‡§†‡§§‡§æ‡§≤‡•Å": "‡§è‡§ê", "‡§ï‡§£‡•ç‡§†‡•ã‡§∑‡•ç‡§†": "‡§ì‡§î", "‡§¶‡§®‡•ç‡§§‡•ã‡§∑‡•ç‡§†": "‡§µ"
}

VOWELS_MAP = {'‡§æ': '‡§Ü', '‡§ø': '‡§á', '‡•Ä': '‡§à', '‡•Å': '‡§â', '‡•Ç': '‡§ä', '‡•É': '‡§ã', '‡•Ñ': '‡•†', '‡•¢': '‡§å', '‡•£': '‡•°', '‡•á': '‡§è', '‡•à': '‡§ê', '‡•ã': '‡§ì', '‡•å': '‡§î'}
INDEPENDENT_VOWELS = '‡§Ö‡§Ü‡§á‡§à‡§â‡§ä‡§ã‡•†‡§å‡•°‡§è‡§ê‡§ì‡§î'

class Varna:
    def __init__(self, raw_unit):
        self.char = raw_unit
        self.clean = raw_unit.replace('‡•ç', '')
        self.sanjnas = set()
        self.trace = []

        # Identity
        self.is_vowel = any(v in raw_unit for v in INDEPENDENT_VOWELS) or '‡•©' in raw_unit
        self.is_anunasika = '‡§Å' in raw_unit or '‡§Ç' in raw_unit
        self.is_consonant = not self.is_vowel and '‡•ç' in raw_unit

        # Anatomy
        base = self.char[0]
        self.sthana = [k for k, v in STHANA_MAP.items() if base in v]
        if self.is_anunasika and "‡§®‡§æ‡§∏‡§ø‡§ï‡§æ" not in self.sthana: self.sthana.append("‡§®‡§æ‡§∏‡§ø‡§ï‡§æ")

    def add_samjna(self, label, rule=""):
        self.sanjnas.add(label)
        if rule: self.trace.append(f"{label} [{rule}]")
    def __repr__(self): return self.char

def sanskrit_varna_vichhed(text, return_objects=True):
    """
    R2: AUTHORITATIVE TOKENIZATION (Merged Modifiers)
    Ensures 'i' + '~' becomes 'i~', not ['i', '~'].
    """
    if not text: return []
    if text == "‡•ê": res = ["‡§Ö", "‡§â", "‡§Æ‡•ç"]
    else:
        text = text.replace('‡§ï‡•ç‡§∑', '‡§ï‡•ç‚Äå‡§∑').replace('‡§§‡•ç‡§∞', '‡§§‡•ç‚Äå‡§∞').replace('‡§ú‡•ç‡§û', '‡§ú‡•ç‚Äå‡§û').replace('‡§∂‡•ç‡§∞', '‡§∂‡•ç‚Äå‡§∞').replace('‡§Ω', '‡§Ö')
        text = re.sub(r'‡§Ç(?=[‡§ï‡§ñ‡§ó‡§ò])', '‡§ô‡•ç', text); text = re.sub(r'‡§Ç(?=[‡§ö‡§õ‡§ú‡§ù])', '‡§û‡•ç', text)
        text = re.sub(r'‡§Ç(?=[‡§ü‡§†‡§°‡§¢])', '‡§£‡•ç', text); text = re.sub(r'‡§Ç(?=[‡§§‡§•‡§¶‡§ß])', '‡§®‡•ç', text)
        text = re.sub(r'‡§Ç(?=[‡§™‡§´‡§¨‡§≠])', '‡§Æ‡•ç', text)

        res = []
        i = 0
        while i < len(text):
            char = text[i]
            if char in INDEPENDENT_VOWELS:
                unit = char
                if i+1 < len(text) and text[i+1] == '‡•©': unit += '‡•©'; i+=1
                # MERGE MODIFIERS INTO VOWEL
                while i+1 < len(text) and text[i+1] in '‡§Ç‡§É‡§Å':
                    unit += text[i+1]
                    i+=1
                res.append(unit)

            elif '\u0915' <= char <= '\u0939' or char == '‡§≥':
                current_cons = char + '‡•ç'
                res.append(current_cons)
                found_vowel = False

                if i+1 < len(text):
                    nxt = text[i+1]
                    if nxt == '‡•ç': 
                        i+=1; found_vowel = True
                    elif nxt in VOWELS_MAP:
                        # Vowel Sign found
                        v_unit = VOWELS_MAP[nxt]
                        i+=1; found_vowel = True

                        # MERGE MODIFIERS INTO MATRA-DERIVED VOWEL
                        while i+1 < len(text) and text[i+1] in '‡§Ç‡§É‡§Å':
                            v_unit += text[i+1]
                            i+=1
                        res.append(v_unit)

                    elif nxt in '‡§Ç‡§É‡§Å':
                        # Implicit 'A' with modifier
                        v_unit = '‡§Ö' + nxt
                        i+=1
                        # Check for more modifiers
                        while i+1 < len(text) and text[i+1] in '‡§Ç‡§É‡§Å':
                            v_unit += text[i+1]; i+=1
                        res.append(v_unit)
                        found_vowel = True

                    elif nxt == ' ': 
                        res.append('‡§Ö'); found_vowel = True

                if not found_vowel: res.append('‡§Ö')
            elif char in '·≥≤·≥≥': res.append(char)
            i+=1

    return [Varna(s) for s in res] if return_objects else res

ad = sanskrit_varna_vichhed

def sanskrit_varna_samyoga(varna_list):
    if not varna_list: return ""
    text_list = [v.char for v in varna_list]
    res = ""
    for char in text_list:
        if not res: res = char; continue
        if res.endswith('‡•ç') and any(v in char for v in INDEPENDENT_VOWELS):
            matra = VOWELS_MAP.get(char, "") # Try exact char first
            if not matra:
                # If char has modifiers (e.g. '‡§á‡§Å'), strip them to find matra
                clean_v = char[0]
                matra = {v: k for k, v in VOWELS_MAP.items()}.get(clean_v, "")

            # Re-attach modifiers
            modifiers = char[1:] if len(char) > 1 else ""

            if char.startswith('‡§Ö'):
                res = res[:-1] + modifiers # Remove virama, add modifiers
            else:
                res = res[:-1] + matra + modifiers
        else:
            res += char
    return res

class PratyaharaEngine:
    def __init__(self): self._cache = {}
    def get_varnas(self, name): return [] 
pe = PratyaharaEngine()

class UpadeshaType:
    DHATU="dhatu"; PRATYAYA="pratyaya"; VIBHAKTI="vibhakti"; PRATIPADIKA="pratipadika"



================================================================================
FILE: core/maheshwara_sutras.py
================================================================================

"""
FILE: core/maheshwara_sutras.py
"""
class MaheshwaraSutras:
    SUTRAS_DATA = [
        ("‡§Ö‡§á‡§â", "‡§£‡•ç"), ("‡§ã‡§å", "‡§ï‡•ç"), ("‡§è‡§ì", "‡§ô‡•ç"), ("‡§ê‡§î", "‡§ö‡•ç"),
        ("‡§π‡§Ø‡§µ‡§∞", "‡§ü‡•ç"), ("‡§≤", "‡§£‡•ç"), ("‡§û‡§Æ‡§ô‡§£‡§®", "‡§Æ‡•ç"), ("‡§ù‡§≠", "‡§û‡•ç"),
        ("‡§ò‡§¢‡§ß", "‡§∑‡•ç"), ("‡§ú‡§¨‡§ó‡§°‡§¶", "‡§∂‡•ç"), ("‡§ñ‡§´‡§õ‡§†‡§•‡§ö‡§ü‡§§", "‡§µ‡•ç"), ("‡§ï‡§™", "‡§Ø‡•ç"),
        ("‡§∂‡§∑‡§∏", "‡§∞‡•ç"), ("‡§π", "‡§≤‡•ç")
    ]
    
    SAVARNA_MAP = {'‡§Ö': ['‡§Ö', '‡§Ü'], '‡§á': ['‡§á', '‡§à'], '‡§â': ['‡§â', '‡§ä'], '‡§ã': ['‡§ã', '‡•†'], '‡§å': ['‡§å']}

    @staticmethod
    def get_pratyahara(p_name, force_n2=False):
        """
        Implementation of:
        1. [1.3.3 ‡§π‡§≤‡§®‡•ç‡§§‡•ç‡§Ø‡§Æ‡•ç]: Identifying the It-marker.
        2. [1.1.71 ‡§Ü‡§¶‡§ø‡§∞‡§®‡•ç‡§§‡•ç‡§Ø‡•á‡§® ‡§∏‡§π‡•á‡§§‡§æ]: Adi + Antya-It defines the group.
        """
        if not p_name or len(p_name) < 2: return set()
        
        p_name = p_name.strip()
        adi = p_name[0]
        it_marker = p_name[1:] 
        
        chars = set()
        collecting = False
        n_count = 0
        
        for content, marker in MaheshwaraSutras.SUTRAS_DATA:
            # Step 1: Scan for Adi
            for char in content:
                if char == adi: collecting = True
                if collecting:
                    chars.add(char)
                    # [1.1.69 ‡§Ö‡§£‡•Å‡§¶‡§ø‡§§‡•ç ‡§∏‡§µ‡§∞‡•ç‡§£‡§∏‡•ç‡§Ø]: Include savarnas
                    if char in MaheshwaraSutras.SAVARNA_MAP:
                        chars.update(MaheshwaraSutras.SAVARNA_MAP[char])
            
            # Step 2: [1.3.3 & 1.1.71]: Stop if the 'It' marker matches
            if collecting and marker == it_marker:
                if it_marker == '‡§£‡•ç':
                    n_count += 1
                    if force_n2 and n_count == 1: continue
                break
        return chars



================================================================================
FILE: logic/dhatu_processor.py
================================================================================

"""
FILE: logic/dhatu_processor.py - PAS-v16.1 (Robust S·π≠utva-Niv·πõtti)
"""
from core.core_foundation import Varna, ad, sanskrit_varna_samyoga

class DhatuDiagnostic:
    def __init__(self, raw_upadesha, is_subdhatu=False):
        self.raw = raw_upadesha
        self.is_subdhatu = is_subdhatu
        self.varnas = ad(raw_upadesha)

        self.originally_halanta = False
        if self.varnas and self.varnas[-1].is_consonant:
            self.originally_halanta = True

        self.it_tags = set()
        self.history = []
        self.pada = "Unknown"

        self.process()
        self.pada = self.determine_pada()

    def log(self, rule, desc):
        self.history.append(f"{rule}: {desc}")

    def process(self):
        ir_it_processed = self._apply_ir_it_vartika()
        self._apply_1_3_5_adir_nit_tu_du()
        self._apply_1_3_2_upadeshe_aj_it()

        text = sanskrit_varna_samyoga(self.varnas)
        protected_roots = ["‡§∑‡•ç‡§µ‡§∑‡•ç‡§ï‡•ç", "‡§∑‡•ç‡§†‡§ø‡§µ‡•ç", "‡§∑‡•ç‡§µ‡§ï‡•ç‡§ï", "‡§µ‡§∞‡•ç‡§¨‡•ç"]
        is_protected = any(text.startswith(x) for x in protected_roots)

        if self.originally_halanta and not ir_it_processed and not is_protected:
            self._apply_1_3_3_halantyam()

        self._apply_6_1_64_shatva_vidhi()
        self._apply_6_1_65_natva_vidhi()
        self._apply_complex_sandhi()
        self._apply_7_1_58_num_agama()
        self._apply_internal_sandhi_anusvara()
        self._apply_6_1_73_che_ca()
        self._apply_8_2_78_upadhayam_ca()

    def _apply_6_1_64_shatva_vidhi(self):
        if not self.varnas: return
        text = sanskrit_varna_samyoga(self.varnas)
        if self.is_subdhatu: return

        exceptions = ["‡§∑‡•ç‡§†‡§ø‡§µ‡•ç", "‡§∑‡•ç‡§µ‡§∑‡•ç‡§ï‡•ç", "‡§∑‡•ç‡§†‡§ø‡§µ‡•Å", "‡§∑‡•ç‡§µ‡§ï‡•ç‡§ï"]
        if any(text.startswith(ex) for ex in exceptions): return

        if self.varnas[0].char.startswith('‡§∑‡•ç'):
            self.varnas[0].char = self.varnas[0].char.replace('‡§∑‡•ç', '‡§∏‡•ç')
            self.log("6.1.64", "Changed initial ·π£ -> s")

            # ROBUST S·π≠utva-Niv·πõtti Scan (v16.1 Logic)
            for i in range(1, len(self.varnas)):
                char = self.varnas[i].char

                # Check 1: Adjacent Stops (Must be immediate, i=1)
                if i == 1:
                    if '‡§ü' in char: 
                        self.varnas[i].char = char.replace('‡§ü', '‡§§')
                        self.log("Logic", "Reverted adjacent ·π≠ -> t")
                    elif '‡§†' in char: 
                        self.varnas[i].char = char.replace('‡§†', '‡§•')
                        self.log("Logic", "Reverted adjacent ·π≠h -> th")

                # Check 2: Natva Reversion (Anywhere)
                if '‡§£' in char:
                    self.varnas[i].char = char.replace('‡§£', '‡§®')
                    self.log("Logic", "Reverted ·πá -> n (S·π≠utva Niv·πõtti)")

    def _apply_6_1_65_natva_vidhi(self):
        if self.varnas and self.varnas[0].char.startswith('‡§£‡•ç'):
            self.varnas[0].char = self.varnas[0].char.replace('‡§£‡•ç', '‡§®‡•ç')
            self.log("6.1.65", "Changed initial ·πá -> n")

    # --- Standard Helpers ---
    def determine_pada(self):
        raw_tags = [t.split('-')[0] for t in self.it_tags]
        if any(x in raw_tags for x in ['‡§ô', '‡§ô‡§ø', '‡§Ö‡§Å']): return "ƒÄtmanepada (1.3.12)"
        if any(x in raw_tags for x in ['‡§û', '‡§û‡§ø']): return "Ubhayapada (1.3.72)"
        return "Parasmaipada (1.3.78)"

    def _apply_ir_it_vartika(self):
        if len(self.varnas) >= 2:
            last = self.varnas[-1]
            penult = self.varnas[-2]
            if last.char == '‡§∞‡•ç' and any(x in penult.char for x in ['‡§á', '‡§ø', '‡§à', '‡•Ä']):
                self.it_tags.add("ir-It (Vartika)")
                self.varnas = self.varnas[:-2]
                self.log("Vartika", "Removed final 'ir' bundle")
                return True
        return False

    def _apply_extended_it_removal(self):
        if not self.varnas: return
        text = sanskrit_varna_samyoga(self.varnas)
        if text.endswith("‡§á‡§ô‡•ç"):
            self.varnas = self.varnas[:-2]
            self.it_tags.add("i·πÖ-It")
            return
        last = self.varnas[-1]
        if len(self.varnas) > 1:
            penult = self.varnas[-2]
            if last.char == '‡§∞‡•ç' and '‡§á' in penult.char:
                self.varnas = self.varnas[:-2]
                self.it_tags.add("ir-It")
                return
            if last.char == '‡§ã' or last.char == '‡•†':
                self.varnas.pop()
                self.it_tags.add("·πõ-It")
                return

    def _apply_1_3_5_adir_nit_tu_du(self):
        if len(self.varnas) >= 2:
            c1 = self.varnas[0].char.replace('‡•ç', '')
            c2 = self.varnas[1].char
            marker = None
            if c1 == '‡§û' and any(v in c2 for v in ['‡§á', '‡§ø']): marker = "‡§û‡§ø"
            elif c1 == '‡§ü' and any(v in c2 for v in ['‡§â', '‡•Å']): marker = "‡§ü‡•Å"
            elif c1 == '‡§°' and any(v in c2 for v in ['‡§â', '‡•Å']): marker = "‡§°‡•Å"
            if marker:
                 self.it_tags.add(f"{marker}-It (1.3.5)")
                 self.varnas = self.varnas[2:]
                 self.log("1.3.5", f"Removed initial {marker}")

    def _apply_1_3_2_upadeshe_aj_it(self):
        to_remove = []
        for v in self.varnas:
            if v.is_anunasika:
                tag = "Aj-It" 
                if any(x in v.char for x in ['‡§á', '‡§ø']): tag = "‡§á‡§Å-It"
                elif any(x in v.char for x in ['‡§à', '‡•Ä']): tag = "‡§à‡§Å-It"
                elif any(x in v.char for x in ['‡§â', '‡•Å']): tag = "‡§â‡§Å-It"
                elif any(x in v.char for x in ['‡§ä', '‡•Ç']): tag = "‡§ä‡§Å-It"
                else: tag = "‡§Ö‡§Å-It"
                self.it_tags.add(f"{tag} (1.3.2)")
                to_remove.append(v)
                self.log("1.3.2", f"Removed nasal {v.char}")
        for v in to_remove: self.varnas.remove(v)

    def _apply_1_3_3_halantyam(self):
        if self.varnas and self.varnas[-1].is_consonant:
            last = self.varnas[-1].char
            self.it_tags.add(f"{last}-It (1.3.3)")
            self.varnas.pop()
            self.log("1.3.3", f"Removed final {last}")

    def _apply_7_1_58_num_agama(self):
        if "ir-It (Vartika)" in self.it_tags: return
        if any("‡§á‡§Å-It" in t for t in self.it_tags):
            v_indices = [i for i, v in enumerate(self.varnas) if v.is_vowel]
            if v_indices:
                idx = v_indices[-1] + 1
                self.varnas.insert(idx, Varna("‡§®‡•ç"))
                self.log("7.1.58", "Added Num (n)")

    def _apply_internal_sandhi_anusvara(self):
        for i in range(len(self.varnas) - 1):
            curr = self.varnas[i].char
            nxt = self.varnas[i+1].char
            if curr == '‡§®‡•ç':
                if any(k in nxt for k in ['‡§ï', '‡§ñ', '‡§ó', '‡§ò']): self.varnas[i].char = '‡§ô‡•ç'
                elif any(c in nxt for c in ['‡§ö', '‡§õ', '‡§ú', '‡§ù']): self.varnas[i].char = '‡§û‡•ç'
                elif any(t in nxt for t in ['‡§ü', '‡§†', '‡§°', '‡§¢', '‡§£']): self.varnas[i].char = '‡§£‡•ç'
                elif any(p in nxt for p in ['‡§™', '‡§´', '‡§¨', '‡§≠']): self.varnas[i].char = '‡§Æ‡•ç'
                elif any(s in nxt for s in ['‡§∂', '‡§∑', '‡§∏', '‡§π']): self.varnas[i].char = '‡§Ç'

    def _apply_6_1_73_che_ca(self):
        i = 0
        while i < len(self.varnas):
            curr = self.varnas[i]
            if '‡§õ' in curr.char:
                if i > 0:
                    prev = self.varnas[i-1]
                    is_short = any(x in prev.char for x in ['‡§Ö', '‡§á', '‡§â', '‡§ã'])
                    is_mlech = '‡•á' in prev.char
                    if is_short or is_mlech:
                        self.varnas.insert(i, Varna('‡§ö‡•ç'))
                        self.log("6.1.73", "Applied Tuk-Agama (ch -> cch)")
                        i += 1
            i += 1

    def _apply_complex_sandhi(self):
        for i in range(len(self.varnas) - 1):
            curr = self.varnas[i].char
            nxt = self.varnas[i+1].char
            if '‡§∏‡•ç' in curr and '‡§ú‡•ç' in nxt: self.varnas[i].char = '‡§ú‡•ç'
            if '‡§∏‡•ç' in curr and '‡§ö‡•ç' in nxt: self.varnas[i].char = '‡§∂‡•ç'

    def _apply_8_2_78_upadhayam_ca(self):
        if len(self.varnas) < 3: return
        last = self.varnas[-1]
        upadha = self.varnas[-2]
        pre_upadha = self.varnas[-3]
        if not last.is_consonant: return
        if upadha.char not in ['‡§∞‡•ç', '‡§µ‡•ç']: return
        ik_map = {'‡§á': '‡§à', '‡§â': '‡§ä', '‡§ã': '‡•†', '‡§å': '‡•°'}
        current_vowel = pre_upadha.char
        if current_vowel in ik_map:
            pre_upadha.char = ik_map[current_vowel]
            self.log("8.2.78", f"UpadhƒÅ Dƒ´rgha")

    def get_final_root(self):
        return sanskrit_varna_samyoga(self.varnas)



================================================================================
FILE: logic/anga_processor.py
================================================================================

"""
FILE: logic/anga_processor.py - PAS-v8.3
PILLAR: Anga-Adhikara (6.4 - 7.4) & Functional Standardization
"""
from core.core_foundation import Varna, ad

class AngaProcessor:
    @staticmethod
    def is_blocked_kniti(suffix, context=None):
        if not suffix: return False
        # 1.1.5: Kniti Ca - Blocking Guna/Vriddhi
        tags = getattr(suffix[0], 'sanjnas', set())
        return any(t in tags for t in ['kit', 'ngit', 'gnit'])

    @staticmethod
    def apply_guna_7_3_84(anga, suffix, context=None):
        """7.3.84: ‡§∏‡§æ‡§∞‡•ç‡§µ‡§ß‡§æ‡§§‡•Å‡§ï‡§æ‡§∞‡•ç‡§ß‡§ß‡§æ‡§§‡•Å‡§ï‡§Ø‡•ã‡§É - Guna of final Ik-varna."""
        if AngaProcessor.is_blocked_kniti(suffix): return anga, "Blocked by 1.1.5"
        if not anga: return anga, None
        
        last = anga[-1]
        guna_map = {'‡§á': '‡§è', '‡§à': '‡§è', '‡§â': '‡§ì', '‡§ä': '‡§ì', '‡§ã': '‡§Ö‡§∞‡•ç', '‡•†': '‡§Ö‡§∞‡•ç', '‡§å': '‡§Ö‡§≤‡•ç'}
        
        if last.char in guna_map:
            sub = guna_map[last.char]
            anga.pop()
            # Replace with new Varnas (handling multi-char like 'ar')
            for char in sub:
                v = Varna(char)
                v.trace.append("7.3.84")
                anga.append(v)
            return anga, "7.3.84"
        return anga, None

    @staticmethod
    def apply_6_1_64_shatva(varnas):
        """6.1.64: ‡§ß‡§æ‡§§‡•ç‡§µ‡§æ‡§¶‡•á‡§É ‡§∑‡§É ‡§∏‡§É - Initial sh -> s."""
        if varnas and varnas[0].char.startswith('‡§∑‡•ç'):
            varnas[0].char = '‡§∏‡•ç'
            return True
        return False

    @staticmethod
    def apply_6_1_65_natva(varnas):
        """6.1.65: ‡§£‡•ã ‡§®‡§É - Initial nna -> n."""
        if varnas and varnas[0].char.startswith('‡§£‡•ç'):
            varnas[0].char = '‡§®‡•ç'
            return True
        return False

    @staticmethod
    def apply_aco_niti_7_2_115(anga, suffix):
        """7.2.115: ‡§Ö‡§ö‡•ã ‡§û‡•ç‡§£‡§ø‡§§‡§ø - Vriddhi of final vowel before √ëit/Nit."""
        if not suffix: return anga, None
        tags = getattr(suffix[0], 'sanjnas', set())
        if not ({'√±it', '·πáit'} & tags): return anga, None
        
        last = anga[-1]
        vriddhi_map = {'‡§Ö': '‡§Ü', '‡§á': '‡§ê', '‡§à': '‡§ê', '‡§â': '‡§î', '‡§ä': '‡§î', '‡§ã': '‡§Ü‡§∞‡•ç'}
        
        if last.char in vriddhi_map:
            sub = vriddhi_map[last.char]
            anga.pop()
            for char in sub:
                v = Varna(char); v.trace.append("7.2.115")
                anga.append(v)
            return anga, "7.2.115"
        return anga, None



================================================================================
FILE: logic/krt_processor.py
================================================================================




================================================================================
FILE: logic/__init__.py
================================================================================

# panini_engine/logic/__init__.py
from .anga_processor import AngaProcessor
from .sandhi_processor import SandhiProcessor


================================================================================
FILE: logic/sandhi_processor.py
================================================================================

"""
FILE: logic/sandhi_processor.py - PAS-v21.6 (Halanta Awareness in Blockers)
"""
from core.core_foundation import Varna, ad, sanskrit_varna_samyoga

class SandhiProcessor:
    AC = set("‡§Ö‡§Ü‡§á‡§à‡§â‡§ä‡§ã‡•†‡§å‡§è‡§ê‡§ì‡§î")
    HAL = set("‡§ï‡§ñ‡§ó‡§ò‡§ô‡§ö‡§õ‡§ú‡§ù‡§û‡§ü‡§†‡§°‡§¢‡§£‡§§‡§•‡§¶‡§ß‡§®‡§™‡§´‡§¨‡§≠‡§Æ‡§Ø‡§∞‡§≤‡§µ‡§∂‡§∑‡§∏‡§π")

    def __init__(self):
        # 1. Yan (6.1.77)
        self.yan_map = {'‡§á': '‡§Ø‡•ç', '‡§à': '‡§Ø‡•ç', '‡§â': '‡§µ‡•ç', '‡§ä': '‡§µ‡•ç', '‡§ã': '‡§∞‡•ç', '‡•†': '‡§∞‡•ç', '‡§å': '‡§≤‡•ç'}
        # 2. Guna (6.1.87)
        self.guna_map = {
            ('‡§Ö', '‡§á'): '‡§è', ('‡§Ö', '‡§à'): '‡§è', ('‡§Ü', '‡§á'): '‡§è', ('‡§Ü', '‡§à'): '‡§è',
            ('‡§Ö', '‡§â'): '‡§ì', ('‡§Ö', '‡§ä'): '‡§ì', ('‡§Ü', '‡§â'): '‡§ì', ('‡§Ü', '‡§ä'): '‡§ì',
            ('‡§Ö', '‡§ã'): '‡§Ö‡§∞‡•ç', ('‡§Ö', '‡•†'): '‡§Ö‡§∞‡•ç', ('‡§Ü', '‡§ã'): '‡§Ö‡§∞‡•ç', ('‡§Ü', '‡•†'): '‡§Ö‡§∞‡•ç'
        }
        # 3. Vriddhi (6.1.88)
        self.vriddhi_map = {
            ('‡§Ö', '‡§è'): '‡§ê', ('‡§Ö', '‡§ê'): '‡§ê', ('‡§Ü', '‡§è'): '‡§ê', ('‡§Ü', '‡§ê'): '‡§ê',
            ('‡§Ö', '‡§ì'): '‡§î', ('‡§Ö', '‡§î'): '‡§î', ('‡§Ü', '‡§ì'): '‡§î', ('‡§Ü', '‡§î'): '‡§î'
        }
        # 4. Ayadi (6.1.78)
        self.ayadi_map = {'‡§è': '‡§Ö‡§Ø‡•ç', '‡§ì': '‡§Ö‡§µ‡•ç', '‡§ê': '‡§Ü‡§Ø‡•ç', '‡§î': '‡§Ü‡§µ‡•ç'}
        # 5. Savarna
        self.savarna_groups = [{'‡§Ö', '‡§Ü'}, {'‡§á', '‡§à'}, {'‡§â', '‡§ä'}, {'‡§ã', '‡•†'}]
        self.dirgha_map = {'‡§Ö': '‡§Ü', '‡§Ü': '‡§Ü', '‡§á': '‡§à', '‡§à': '‡§à', '‡§â': '‡§ä', '‡§ä': '‡§ä', '‡§ã': '‡•†', '‡•†': '‡•†'}

    @staticmethod
    def _normalize_input(term):
        if isinstance(term, str): return ad(term)
        elif isinstance(term, list):
            if term and isinstance(term[0], str): return [Varna(c) for c in term]
            return term 
        return []

    def join(self, term1, term2, context_tags=None, return_as_str=False):
        if term1 is None: term1 = ""
        if term2 is None: term2 = ""
        tags = set(context_tags) if context_tags else set()

        v1_list = self._normalize_input(term1)
        v2_list = self._normalize_input(term2)
        result_list = v1_list + v2_list

        if v1_list and v2_list:
            last = v1_list[-1]
            first = v2_list[0]

            if last.is_vowel and first.is_vowel:
                lc, fc = last.char, first.char
                if "Dual" in tags and lc in ['‡§à', '‡§ä', '‡§è']: pass
                elif lc in self.ayadi_map:
                    res_varnas = ad(self.ayadi_map[lc])
                    result_list = v1_list[:-1] + res_varnas + v2_list
                elif self._are_savarna(lc, fc):
                    long = self.dirgha_map.get(lc, lc)
                    result_list = v1_list[:-1] + [Varna(long)] + v2_list[1:]
                elif (lc in ['‡§Ö', '‡§Ü']) and (lc, fc) in self.vriddhi_map:
                    res_char = self.vriddhi_map[(lc, fc)]
                    result_list = v1_list[:-1] + [Varna(res_char)] + v2_list[1:]
                elif (lc in ['‡§Ö', '‡§Ü']) and (lc, fc) in self.guna_map:
                    res_varnas = ad(self.guna_map[(lc, fc)])
                    result_list = v1_list[:-1] + res_varnas + v2_list[1:]
                elif lc in self.yan_map:
                    yan = self.yan_map[lc]
                    result_list = v1_list[:-1] + [Varna(yan)] + v2_list

        if return_as_str: return sanskrit_varna_samyoga(result_list)
        return result_list

    @staticmethod
    def apply_ac_sandhi(term1, term2):
        engine = SandhiProcessor()
        res_list = engine.join(term1, term2, return_as_str=False)
        return res_list, "Sandhi Applied"

    @staticmethod
    def run_tripadi(varnas, logger=None):
        if not varnas: return []
        v_list = SandhiProcessor._normalize_input(varnas)
        if not v_list: return []

        # 1. Natva (8.4.1)
        trigger = False

        # Explicit Blocker List: Must handle Halanta Consonants (v.char is likely '‡§ï‡•ç', '‡§ö‡•ç', etc.)
        # We strip virama for checking against this set
        raw_blockers = set("‡§ö‡§õ‡§ú‡§ù‡§û‡§ü‡§†‡§°‡§¢‡§£‡§§‡§•‡§¶‡§ß‡§®‡§≤‡§∂‡§∏") 

        for i, v in enumerate(v_list):
            c = v.char

            # Normalize char for blocker check (Remove virama)
            # This handles both '‡§£' and '‡§£‡•ç' as the same abstract blocker
            c_clean = c.replace('‡•ç', '')

            # Trigger Logic (R/Sh/Ri) - These are usually Halanta or Vowel
            if c in ['‡§∞‡•ç', '‡§∑‡•ç', '‡§ã', '‡•†']: 
                trigger = True

            # Target Logic (N)
            elif c == '‡§®‡•ç':
                if trigger:
                    # Apply if not Padanta
                    if i < len(v_list) - 1:
                        v.char = '‡§£‡•ç'
                        if logger and hasattr(logger, 'append'): logger.append("8.4.1: Natva")

            # Blocker Logic
            # Check if cleaned char is in the forbidden list
            elif c_clean in raw_blockers:
                trigger = False

        # 2. Satva (8.3.59)
        in_ku_raw = set("‡§á‡§à‡§â‡§ä‡§ã‡•†‡§è‡§ê‡§ì‡§î‡§ï‡§ñ‡§ó‡§ò") # Vowels + K-varga
        for i in range(1, len(v_list)):
            curr = v_list[i]
            prev = v_list[i-1]
            if curr.char == '‡§∏‡•ç':
                if i == len(v_list) - 1: continue 

                prev_clean = prev.char.replace('‡•ç', '')
                # Check In/Ku (Vowels don't have virama anyway, Consonants do)
                if prev_clean in in_ku_raw or prev.char == '‡§∞‡•ç':
                    curr.char = '‡§∑‡•ç'
                    if logger and hasattr(logger, 'append'): logger.append("8.3.59: Satva")

        # 3. Visarga
        last = v_list[-1]
        if last.char in ['‡§∏‡•ç', '‡§∞‡•ç']:
            v_list[-1] = Varna('‡§É')
            if logger and hasattr(logger, 'append'): logger.append("8.3.15: Visarga")

        return v_list

    def _are_savarna(self, c1, c2):
        for group in self.savarna_groups:
            if c1 in group and c2 in group: return True
        return False



================================================================================
FILE: logic/tinanta_processor.py
================================================================================

"""
FILE: logic/tinanta_processor.py - PAS-v18.0 (The Conjugation Engine)
"""
from core.core_foundation import Varna, ad, sanskrit_varna_samyoga
from logic.dhatu_processor import DhatuDiagnostic

# --- The 18 Ti·πÖ Suffixes (3.4.78) ---
TIN_PRATYAYA = {
    "Parasmaipada": [
        ["‡§§‡§ø‡§™‡•ç", "‡§§‡§∏‡•ç", "‡§ù‡§ø"],   # Prathama (3rd Person)
        ["‡§∏‡§ø‡§™‡•ç", "‡§•‡§∏‡•ç", "‡§•"],    # Madhyama (2nd Person)
        ["‡§Æ‡§ø‡§™‡•ç", "‡§µ‡§∏‡•ç", "‡§Æ‡§∏‡•ç"]   # Uttama (1st Person)
    ],
    "Atmanepada": [
        ["‡§§", "‡§Ü‡§§‡§æ‡§Æ‡•ç", "‡§ù"],     # Prathama
        ["‡§•‡§æ‡§∏‡•ç", "‡§Ü‡§•‡§æ‡§Æ‡•ç", "‡§ß‡•ç‡§µ‡§Æ‡•ç"], # Madhyama
        ["‡§á‡§°‡•ç", "‡§µ‡§π‡§ø", "‡§Æ‡§π‡§ø‡§ô‡•ç"]   # Uttama
    ]
}

class TinantaDiagnostic:
    def __init__(self, upadesha, lakara="Lat", purusha=1, vacana=1):
        """
        upadesha: Raw root (e.g. '‡§°‡•Å‡§ï‡•É‡§û‡•ç')
        lakara: Tense/Mood (e.g. 'Lat')
        purusha: 1=Prathama, 2=Madhyama, 3=Uttama (Paninian Indexing)
        vacana: 1=Eka, 2=Dvi, 3=Bahu
        """
        self.raw_root = upadesha
        self.lakara = lakara
        self.purusha = purusha - 1 # 0-indexed
        self.vacana = vacana - 1   # 0-indexed

        self.history = []
        self.derivation = []

        # Step 1: Process Root (DhƒÅtu-PƒÅ·π≠ha Logic)
        self.dhatu_obj = DhatuDiagnostic(upadesha)
        self.root = self.dhatu_obj.get_final_root()
        self.pada_type = self.dhatu_obj.pada # Parasmai/Atmane

        self.log(f"Root Prepared: {self.root} ({self.pada_type})")

        # Step 2: Select Suffix (Ti·πÖ Selection)
        self.suffix = self._select_tin()
        self.log(f"Suffix Selected: {self.suffix} ({self.lakara})")

        # Step 3: Run Prakriya
        self.final_form = self._run_prakriya()

    def log(self, message):
        self.history.append(message)

    def _select_tin(self):
        # 1.3.12/78: Determine Voice
        voice = "Atmanepada" if "Atmanepada" in self.pada_type else "Parasmaipada"
        selection = TIN_PRATYAYA[voice][self.purusha][self.vacana]

        # Basic IT removal for suffixes (P in Tip/Mip/Sip is It)
        if selection.endswith("‡§™‡•ç") and len(selection) > 1:
            selection = selection[:-2] + "‡§ø" # Tip -> Ti

        return selection

    def _run_prakriya(self):
        """
        The Core Assembly Line:
        Root + Vikarana + Suffix -> Anga-Karya -> Sandhi -> Pada
        """
        # A. Current State
        curr_root = self.root
        curr_suffix = self.suffix

        # B. Vikarana (Infix) Selection - Hardcoded ≈öap (a) for now
        vikarana = "‡§Ö" 
        self.log("3.1.68: Added Vikara·πáa '≈öap' (a)")

        # C. Guna (7.3.84 SƒÅrvadhƒÅtukƒÅrdhadhƒÅtukayo·∏•)
        root_varnas = ad(curr_root)
        if root_varnas:
            last_char = root_varnas[-1].char
            if last_char in ['‡§á', '‡§à']:
                curr_root = curr_root[:-1] + "‡§è" # i -> e
                self.log("7.3.84: Guna (i -> e)")
            elif last_char in ['‡§â', '‡§ä']:
                curr_root = curr_root[:-1] + "‡§ì" # u -> o
                self.log("7.3.84: Guna (u -> o)")
            elif last_char in ['‡§ã', '‡•†']:
                curr_root = curr_root[:-1] + "‡§Ö‡§∞‡•ç" # r -> ar
                self.log("7.3.84: Guna (·πõ -> ar)")

        # D. Ayadi Sandhi (6.1.78)
        if curr_root.endswith("‡§è"):
            curr_root = curr_root[:-1] + "‡§Ö‡§Ø‡•ç"
            self.log("6.1.78: Ayadi (e -> ay)")
        elif curr_root.endswith("‡§ì"):
            curr_root = curr_root[:-1] + "‡§Ö‡§µ‡•ç"
            self.log("6.1.78: Ayadi (o -> av)")

        # E. Assembly
        return f"{curr_root}{vikarana}{curr_suffix}" # Example: Bhav + a + ti



================================================================================
FILE: logic/reverse_analyzer.py
================================================================================

"""
FILE: logic/reverse_analyzer.py
"""
from engine_main import PrakriyaLogger
from logic.subanta_processor import SubantaProcessor
from core.knowledge_base import KnowledgeBase

class ReverseAnalyzer:
    # Knowledge of supported stems
    SUPPORTED_STEMS = ["‡§∞‡§æ‡§Æ", "‡§π‡§∞‡§ø", "‡§ó‡•Å‡§∞‡•Å", "‡§∞‡§Æ‡§æ"]
    
    @staticmethod
    def analyze_word(target_word):
        """
        Scans all declensions of supported stems to find the target word.
        Returns a list of matches (handling ambiguities like 5.1/6.1).
        """
        matches = []
        clean_target = target_word.strip()
        
        # Brute-force scan (Optimization: Fast because scope is limited)
        for stem in ReverseAnalyzer.SUPPORTED_STEMS:
            for vib in range(1, 9):
                for vac in range(1, 4):
                    # 1. Derive silently first
                    # We pass None logger to be fast
                    result = SubantaProcessor.derive_pada(stem, vib, vac, None)
                    
                    # 2. Check Match
                    if result == clean_target:
                        # 3. If Match, Derive AGAIN with Logger to capture steps
                        logger = PrakriyaLogger()
                        SubantaProcessor.derive_pada(stem, vib, vac, logger)
                        
                        # Get Pratyaya Name (e.g., Su, Au, Jas)
                        sup_raw, _ = KnowledgeBase.get_sup(vib, vac)
                        
                        match_data = {
                            "stem": stem,
                            "vibhakti": vib,
                            "vacana": vac,
                            "pratyaya": sup_raw,
                            "history": logger.get_history() # Forward history
                        }
                        matches.append(match_data)
        
        return matches



================================================================================
FILE: logic/subanta_processor.py
================================================================================

"""
FILE: logic/subanta_processor.py
"""
from core.core_foundation import Varna, ad, sanskrit_varna_samyoga, UpadeshaType
from core.sanjna_controller import SanjnaController
from core.knowledge_base import KnowledgeBase
from logic.sandhi_processor import SandhiProcessor
from core.adhikara_controller import AdhikaraController
from core.dhatu_repo import DhatuRepository 

class SubantaProcessor:
    KNOWN_PRATYAYAS = {'‡§∏‡•Å', '‡§î', '‡§ú‡§∏‡•ç', '‡§Ö‡§Æ‡•ç', '‡§î‡§ü‡•ç', '‡§∂‡§∏‡•ç', '‡§ü‡§æ', '‡§≠‡•ç‡§Ø‡§æ‡§Æ‡•ç', '‡§≠‡§ø‡§∏‡•ç', '‡§ô‡•á', '‡§≠‡•ç‡§Ø‡§∏‡•ç', '‡§ô‡§∏‡§ø', '‡§ô‡§∏‡•ç', '‡§ì‡§∏‡•ç', '‡§Ü‡§Æ‡•ç', '‡§ô‡§ø', '‡§∏‡•Å‡§™‡•ç', '‡§§‡§ø‡§™‡•ç', '‡§§‡§∏‡•ç', '‡§ù‡§ø', '‡§∏‡§ø‡§™‡•ç', '‡§•‡§∏‡•ç', '‡§•', '‡§Æ‡§ø‡§™‡•ç', '‡§µ‡§∏‡•ç', '‡§Æ‡§∏‡•ç', '‡§∂‡§™‡•ç', '‡§∂‡•ç‡§®‡•Å', '‡§∏‡•ç‡§Ø', '‡§§‡§æ‡§∏‡§ø', '‡§ï‡•ç‡§µ‡§ø‡§™‡•ç', '‡§ò‡§û‡•ç'}
    FEMININE_I_U_STEMS = {'‡§Æ‡§§‡§ø', '‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø', '‡§ß‡•á‡§®‡•Å', '‡§ï‡•Ä‡§∞‡•ç‡§§‡§ø', '‡§ú‡§æ‡§§‡§ø', '‡§≠‡§ï‡•ç‡§§‡§ø'}
    VALID_SINGLE_LETTERS = {'‡§Ö', '‡§á', '‡§â', '‡§ã'}
    SARVANAMA_GANA = {'‡§∏‡§∞‡•ç‡§µ', '‡§µ‡§ø‡§∂‡•ç‡§µ', '‡§â‡§≠', '‡§â‡§≠‡§Ø', '‡§°‡§§‡§∞', '‡§°‡§§‡§Æ', '‡§Ö‡§®‡•ç‡§Ø', '‡§Ö‡§®‡•ç‡§Ø‡§§‡§∞', '‡§á‡§§‡§∞', '‡§§‡•ç‡§µ‡§§‡•ç', '‡§§‡•ç‡§µ', '‡§®‡•á‡§Æ', '‡§∏‡§Æ', '‡§∏‡§ø‡§Æ', '‡§§‡§¶‡•ç', '‡§Ø‡§¶‡•ç', '‡§è‡§§‡§¶‡•ç', '‡§á‡§¶‡§Æ‡•ç', '‡§Ö‡§¶‡§∏‡•ç', '‡§è‡§ï', '‡§¶‡•ç‡§µ‡§ø', '‡§Ø‡•Å‡§∑‡•ç‡§Æ‡§¶‡•ç', '‡§Ö‡§∏‡•ç‡§Æ‡§¶‡•ç', '‡§≠‡§µ‡§§‡•Å', '‡§ï‡§ø‡§Æ‡•ç'}

    @staticmethod
    def _finalize(varnas, vibhakti, vacana, logger=None):
        if not varnas: return ""
        final = SandhiProcessor.run_tripadi(varnas, logger) 
        res = sanskrit_varna_samyoga(final)
        if vibhakti == 8: return "‡§π‡•á " + res
        return res

    @staticmethod
    def derive_pada(stem_str, vibhakti, vacana, logger=None, force_pratipadika=False):
        stem = ad(stem_str)
        
        # --- VALIDATION ---
        if force_pratipadika:
            if logger: logger.log("1.2.45", "Manual Override", f"‚ö†Ô∏è Forced: '{stem_str}'", stem, "User")
        else:
            if stem_str in SubantaProcessor.KNOWN_PRATYAYAS: return "Error: Pratyaya"
            if stem_str not in SubantaProcessor.VALID_SINGLE_LETTERS:
                try:
                    dhatu = DhatuRepository.get_dhatu_info(stem_str)
                    if dhatu: return "Error: Dhatu"
                except: pass
            if logger: logger.log("1.2.45", "Arthavad... Pratipadikam", f"‚úÖ '{stem_str}'", stem, "Maharshi PƒÅ·πáini")

        last_char = stem[-1].char
        is_at = (last_char == '‡§Ö')   
        is_aa = (last_char == '‡§Ü')   
        is_it = (last_char == '‡§á')                 
        is_ut = (last_char == '‡§â')                 
        is_fem_ghi = (stem_str in SubantaProcessor.FEMININE_I_U_STEMS) or is_aa
        is_ghi_any = (is_it or is_ut)
        is_sarvanama = (stem_str in SubantaProcessor.SARVANAMA_GANA)
        if is_sarvanama and logger: logger.log("1.1.27", "Sarvadini Sarvanamani", f"{stem_str}", stem, "Maharshi PƒÅ·πáini")

        # --- SELECTION ---
        sup_data = KnowledgeBase.get_sup(vibhakti, vacana)
        if not sup_data: return "?"
        raw_sup, tags = sup_data
        
        if logger: logger.log("4.1.2", "Svaujasmaut...", f"Selecting '{raw_sup}'", stem, "Maharshi PƒÅ·πáini")
        
        clean_suffix = []
        rule_applied = ""
        
        # DEBUG: Print inputs
        # print(f"DEBUG: V={vibhakti} Vc={vacana} Stem={stem_str} Raw={raw_sup}")

        # Hardcoded Cleaning
        if vibhakti == 1 and vacana == 1: clean_suffix = ad("‡§∏‡•ç"); rule_applied = "1.3.2 Upadeshe Aj"
        elif vibhakti == 1 and vacana == 2: clean_suffix = ad("‡§î") 
        elif vibhakti == 1 and vacana == 3: 
            if is_at and is_sarvanama: clean_suffix = ad("‡§à"); rule_applied = "7.1.17 Jasah Shee"
            else: clean_suffix = ad("‡§Ö‡§∏‡•ç"); rule_applied = "1.3.7 Chutu"
        elif vibhakti == 2 and vacana == 1: clean_suffix = ad("‡§Ö‡§Æ‡•ç")
        elif vibhakti == 2 and vacana == 2: clean_suffix = ad("‡§î")
        elif vibhakti == 2 and vacana == 3: clean_suffix = ad("‡§Ö‡§∏‡•ç"); rule_applied = "1.3.8 Lashakvataddhite"
        elif vibhakti == 3 and vacana == 1: clean_suffix = ad("‡§Ü"); rule_applied = "1.3.7 Chutu"
        elif vibhakti == 4 and vacana == 1: clean_suffix = ad("‡§è"); rule_applied = "1.3.8 Lashakvataddhite"
        elif vibhakti == 5 and vacana == 1: clean_suffix = ad("‡§Ö‡§∏‡•ç"); rule_applied = "1.3.8 Lashakvataddhite"
        elif vibhakti == 6 and vacana == 1: clean_suffix = ad("‡§Ö‡§∏‡•ç"); rule_applied = "1.3.8 Lashakvataddhite"
        elif vibhakti == 7 and vacana == 1: clean_suffix = ad("‡§á"); rule_applied = "1.3.8 Lashakvataddhite"
        elif vibhakti == 7 and vacana == 3: clean_suffix = ad("‡§∏‡•Å"); rule_applied = "1.3.3 Halantyam"
        elif vibhakti == 8 and vacana == 1: clean_suffix = ad("‡§∏‡•ç"); rule_applied = "1.3.2 Upadeshe Aj"
        elif vibhakti == 8 and vacana == 3: clean_suffix = ad("‡§Ö‡§∏‡•ç"); rule_applied = "1.3.7 Chutu"
        
        if not clean_suffix:
            clean_suffix, trace = SanjnaController.run_it_prakaran(ad(raw_sup), UpadeshaType.VIBHAKTI)
            if trace: rule_applied = ", ".join(trace)

        if logger and rule_applied:
            logger.log(rule_applied, "It-Lopa", sanskrit_varna_samyoga(stem + clean_suffix), stem + clean_suffix, "Maharshi PƒÅ·πáini")
        
        is_sambuddhi = (vibhakti == 8 and vacana == 1)
        if is_sambuddhi and logger: 
            logger.log("2.3.49", "Ekavacanam Sambuddhih", "Su -> Sambuddhi", stem + clean_suffix, "Maharshi PƒÅ·πáini")

        # --- SAMBUDDHI OPERATIONS ---
        if is_sambuddhi:
            if is_ghi_any: 
                if is_it: stem[-1].char = '‡§è'
                if is_ut: stem[-1].char = '‡§ì'
                if logger: logger.log("7.3.108", "Hrasvasya Gunah", sanskrit_varna_samyoga(stem+clean_suffix), stem, "Maharshi PƒÅ·πáini")
            if is_aa:
                stem[-1].char = '‡§è'
                if logger: logger.log("7.3.106", "Sambuddhau Ca", sanskrit_varna_samyoga(stem+clean_suffix), stem, "Maharshi PƒÅ·πáini")
            
            last = stem[-1].char
            if (last in ['‡§è', '‡§ì', '‡§Ö', '‡§á', '‡§â', '‡§ã']) and clean_suffix:
                if clean_suffix[0].char not in SandhiProcessor.AC:
                    clean_suffix = []
                    if logger: logger.log("6.1.69", "Eng-hrasvat Sambuddheh", f"Deleted 's'", stem, "Maharshi PƒÅ·πáini")
            return SubantaProcessor._finalize(stem + clean_suffix, vibhakti, vacana, logger)

        # --- SARVANAMA ---
        if is_at and is_sarvanama:
            if vibhakti == 4 and vacana == 1:
                clean_suffix = ad("‡§∏‡•ç‡§Æ‡•à")
                if logger: logger.log("7.1.14", "Sarvanamnah Smai", "‡§∏‡§∞‡•ç‡§µ‡§∏‡•ç‡§Æ‡•à", stem+clean_suffix, "Maharshi PƒÅ·πáini")
                return SubantaProcessor._finalize(stem + clean_suffix, vibhakti, vacana, logger)
            elif vibhakti == 5 and vacana == 1:
                clean_suffix = ad("‡§∏‡•ç‡§Æ‡§æ‡§§‡•ç")
                if logger: logger.log("7.1.15", "Ngasi-ngyoh Smatsminau", "‡§∏‡§∞‡•ç‡§µ‡§∏‡•ç‡§Æ‡§æ‡§§‡•ç", stem+clean_suffix, "Maharshi PƒÅ·πáini")
                return SubantaProcessor._finalize(stem + clean_suffix, vibhakti, vacana, logger)
            elif vibhakti == 7 and vacana == 1:
                clean_suffix = ad("‡§∏‡•ç‡§Æ‡§ø‡§®‡•ç")
                if logger: logger.log("7.1.15", "Ngasi-ngyoh Smatsminau", "‡§∏‡§∞‡•ç‡§µ‡§∏‡•ç‡§Æ‡§ø‡§®‡•ç", stem+clean_suffix, "Maharshi PƒÅ·πáini")
                return SubantaProcessor._finalize(stem + clean_suffix, vibhakti, vacana, logger)
            elif vibhakti == 6 and vacana == 3:
                clean_suffix = ad("‡§∏‡§æ‡§Æ‡•ç") 
                if logger: logger.log("7.1.52", "Aami Sarvanamnah Sut", "‡§∏‡§∞‡•ç‡§µ‡§∏‡§æ‡§Æ‡•ç", stem+clean_suffix, "Maharshi PƒÅ·πáini")
                stem[-1].char = '‡§è'
                if logger: logger.log("7.3.103", "Bahuvacane Jhalyet", "‡§∏‡§∞‡•ç‡§µ‡•á‡§∏‡§æ‡§Æ‡•ç", stem+clean_suffix, "Maharshi PƒÅ·πáini")
                return SubantaProcessor._finalize(stem + clean_suffix, vibhakti, vacana, logger)

        # --- RAMA (At) ---
        if is_at:
            if vibhakti == 2 and vacana == 1:
                if clean_suffix and clean_suffix[0].char == '‡§Ö':
                    del clean_suffix[0]
                    if logger: logger.log("6.1.107", "Ami Purvah", sanskrit_varna_samyoga(stem+clean_suffix), stem + clean_suffix, "Maharshi PƒÅ·πáini")
                    return SubantaProcessor._finalize(stem + clean_suffix, vibhakti, vacana, logger)
            if vibhakti == 3 and vacana == 1: 
                clean_suffix = ad("‡§á‡§®")
                if logger: logger.log("7.1.12", "Ta-ngasi... -> Ina", "‡§á‡§®", stem + clean_suffix, "Maharshi PƒÅ·πáini")
            elif vibhakti == 3 and vacana == 3: clean_suffix = ad("‡§ê‡§∏‡•ç")
            elif vibhakti == 4 and vacana == 1 and not is_sarvanama: clean_suffix = ad("‡§Ø")
            elif vibhakti == 5 and vacana == 1 and not is_sarvanama: clean_suffix = ad("‡§Ü‡§§‡•ç")
            elif vibhakti == 6 and vacana == 1: clean_suffix = ad("‡§∏‡•ç‡§Ø")
            elif vibhakti == 6 and vacana == 3 and not is_sarvanama: 
                clean_suffix = ad("‡§®‡•ç") + clean_suffix; stem[-1].char = '‡§Ü'
            
            if clean_suffix:
                f = clean_suffix[0].char
                if vacana == 3 and f in ['‡§≠‡•ç', '‡§∏‡•ç']: 
                    if not (vibhakti == 2 and vacana == 3): 
                        stem[-1].char = '‡§è'
                        if logger: logger.log("7.3.103", "Bahuvacane Jhalyet", sanskrit_varna_samyoga(stem+clean_suffix), stem, "Maharshi PƒÅ·πáini")
                elif vibhakti in [6, 7] and vacana == 2: stem[-1].char = '‡§è'
                elif f in ['‡§≠‡•ç', '‡§Ø', '‡§µ‡•ç', '‡§Ø‡•ç', '‡§µ']: 
                    if AdhikaraController.is_rule_in_scope("7.3.102", "ANGASYA"): stem[-1].char = '‡§Ü'

        # --- GHI ---
        if is_ghi_any:
            guna_char = '‡§è' if is_it else '‡§ì'
            dirgha_char = '‡§à' if is_it else '‡§ä'
            
            if vibhakti == 2 and vacana == 1:
                 if clean_suffix and clean_suffix[0].char == '‡§Ö':
                    del clean_suffix[0]
                    if logger: logger.log("6.1.107", "Ami Purvah", sanskrit_varna_samyoga(stem+clean_suffix), stem + clean_suffix, "Maharshi PƒÅ·πáini")
                    return SubantaProcessor._finalize(stem + clean_suffix, vibhakti, vacana, logger)

            if (vibhakti in [1,2] and vacana == 2) or (vibhakti == 2 and vacana == 3):
                pass
            
            elif vibhakti == 3 and vacana == 1:
                if not is_fem_ghi: clean_suffix = ad("‡§®‡§æ")
            elif vibhakti in [4, 5, 6, 7] and vacana == 1:
                stem_a = stem[:]; stem_a[-1].char = guna_char
                suffix_a = clean_suffix[:]
                if vibhakti in [5, 6]: suffix_a = ad("‡§∏‡•ç")
                if vibhakti == 7: stem_a[-1].char = '‡§Ö'; suffix_a = ad("‡§î")
                fp_a, _ = SandhiProcessor.apply_ac_sandhi(stem_a, suffix_a)
                res_a_final = SubantaProcessor._finalize(fp_a, vibhakti, vacana, logger)
                if not is_fem_ghi: return res_a_final
                stem_b = stem[:]
                suffix_b_str = "‡•ç‡§Ø‡•à" if vibhakti==4 else "‡•ç‡§Ø‡§æ‡§É" if vibhakti in [5,6] else "‡•ç‡§Ø‡§æ‡§Æ‡•ç"
                return f"{res_a_final} / {stem_str[:-1] + suffix_b_str}"
            elif (vibhakti == 1 or vibhakti == 8) and vacana == 3: stem[-1].char = guna_char
            elif vibhakti == 6 and vacana == 3: clean_suffix = ad("‡§®‡§æ‡§Æ‡•ç"); stem[-1].char = dirgha_char

        # --- RAMA (AA) ---
        if is_aa:
            if vibhakti==1 and vacana==1: return SubantaProcessor._finalize(stem, vibhakti, vacana, logger)
            if vacana==2 and vibhakti in [1,2]: stem[-1].char='‡§è'; clean_suffix=[]; return sanskrit_varna_samyoga(stem)
            if vibhakti==3 and vacana==1: stem[-1].char='‡§è'
            if vibhakti in [4,5,6,7] and vacana==1:
                clean_suffix = ad("‡§Ø‡§æ") + clean_suffix
                if vibhakti==4: clean_suffix=ad("‡§Ø‡•à"); return "‡§∞‡§Æ‡§æ‡§Ø‡•à"
                if vibhakti in [5,6]: clean_suffix=ad("‡§Ø‡§æ‡§∏‡•ç")
                if vibhakti==7: clean_suffix=ad("‡§Ø‡§æ‡§Æ‡•ç"); return "‡§∞‡§Æ‡§æ‡§Ø‡§æ‡§Æ‡•ç"
            if vibhakti==6 and vacana==3: clean_suffix=ad("‡§®‡§æ‡§Æ‡•ç")

        # --- 6.1.102 & 6.1.103 PRIORITY SANDHI ---
        should_run_102 = False
        if clean_suffix:
            # Applies for 1.2, 2.2, 1.3, 2.3
            if (vibhakti in [1, 2] or vibhakti == 8) and (vacana in [2, 3]):
                suffix_start = clean_suffix[0].char
                
                if is_ghi_any:
                    if (vibhakti == 1 or vibhakti == 8) and vacana == 3:
                        should_run_102 = False
                    else:
                        should_run_102 = True
                
                elif is_at:
                    if vacana == 2:
                        should_run_102 = False # Na Dici
                    else:
                        # Sarve (1.3 Sarva) - Na Dici (i)
                        if suffix_start in ['‡§á', '‡§à', '‡§â', '‡§ä', '‡§ã', '‡•†', '‡§å']:
                            should_run_102 = False
                        else:
                            should_run_102 = True

        if should_run_102:
            if is_at: stem[-1].char = '‡§Ü'
            if is_it: stem[-1].char = '‡§à'
            if is_ut: stem[-1].char = '‡§ä'
            
            if logger: logger.log("6.1.102", "Prathamayoh Purvasavarnah", sanskrit_varna_samyoga(stem+clean_suffix), stem, "Maharshi PƒÅ·πáini")
            
            if clean_suffix and clean_suffix[0].is_vowel:
                del clean_suffix[0]
            
            if vibhakti == 2 and vacana == 3:
                if clean_suffix and (clean_suffix[0].char == '‡§∏‡•ç' or clean_suffix[0].char == '‡§É'):
                    clean_suffix[0].char = '‡§®‡•ç'
                    if logger: logger.log("6.1.103", "Tasmacchaso Nah Pumsi", "‡§®‡•ç", stem+clean_suffix, "Maharshi PƒÅ·πáini")

            return SubantaProcessor._finalize(stem + clean_suffix, vibhakti, vacana, logger)

        # --- NORMAL SANDHI ---
        fp, rule = SandhiProcessor.apply_ac_sandhi(stem, clean_suffix)
        if logger and rule: logger.log(rule, "Sandhi", sanskrit_varna_samyoga(fp), fp, "Maharshi PƒÅ·πáini")
        
        return SubantaProcessor._finalize(fp, vibhakti, vacana, logger)



================================================================================
FILE: logic/anga_generator.py
================================================================================

"""
FILE: logic/anga_generator.py - PAS-v8.3
TASK 3: Action Root + Vikarana -> Functional Anga
"""
from core.core_foundation import Varna, ad, sanskrit_varna_samyoga
from logic.anga_processor import AngaProcessor

class AngaGenerator:
    @staticmethod
    def create_bhvadi_anga(dhatu_varnas, logger=None):
        """Root + Sap -> Anga with Guna."""
        # 3.1.68: Sap Vikarana (a)
        sap = ad("‡§Ö")
        
        # 7.3.84: Apply Guna to Root before Sap
        updated_root, rule = AngaProcessor.apply_guna_7_3_84(list(dhatu_varnas), sap)
        
        if logger and rule:
            logger.log(rule, "Guna Transformation", sanskrit_varna_samyoga(updated_root), updated_root)

        # 6.1.78: Ayadi Logic (e.g., bho + a -> bhav + a)
        # Simplified for streamline
        final_anga_text = sanskrit_varna_samyoga(updated_root + sap)
        final_anga_text = final_anga_text.replace("‡§ì‡§Ö", "‡§Ö‡§µ").replace("‡§è‡§Ö", "‡§Ö‡§Ø")
        
        return ad(final_anga_text)



================================================================================
FILE: pages/2_‚ö°_Tinanta_Lab.py
================================================================================

import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
"""
PAGE: Ti·πÖanta Laboratory
"""
import streamlit as st
from logic.tinanta_processor import TinantaDiagnostic

st.set_page_config(page_title="Ti·πÖanta Lab", page_icon="‚ö°", layout="wide")

st.title("‚ö° Ti·πÖanta PrakriyƒÅ (Verb Conjugation)")
st.caption("Phase 1: La·π≠ LakƒÅra Generator")

col1, col2 = st.columns([1, 2])

with col1:
    with st.form("tin_form"):
        root_input = st.text_input("Root (Upadesha)", value="‡§≠‡•Ç")
        lakara = st.selectbox("LakƒÅra", ["Lat (Present)", "Lit (Perfect)", "Lrt (Future)"])
        purusha = st.selectbox("Purusha", ["Prathama (3rd)", "Madhyama (2nd)", "Uttama (1st)"])
        vacana = st.selectbox("Vacana", ["Eka (Singular)", "Dvi (Dual)", "Bahu (Plural)"])

        submitted = st.form_submit_button("Generate Form")

if submitted:
    # Map inputs to indices
    p_map = {"Prathama (3rd)": 1, "Madhyama (2nd)": 2, "Uttama (1st)": 3}
    v_map = {"Eka (Singular)": 1, "Dvi (Dual)": 2, "Bahu (Plural)": 3}

    tin = TinantaDiagnostic(root_input, lakara.split()[0], p_map[purusha], v_map[vacana])

    with col2:
        st.markdown(f"""
        <div style="background:#e8f5e9;padding:20px;border-radius:10px;border-left:5px solid #2e7d32;">
            <h3>üèÅ Final Form: <span style="color:#d32f2f;font-size:2em;">{tin.final_form}</span></h3>
            <p><strong>Root:</strong> {tin.root} | <strong>Voice:</strong> {tin.pada_type}</p>
        </div>
        """, unsafe_allow_html=True)

        st.divider()
        st.subheader("üìú PrakriyƒÅ Trace")
        for step in tin.history:
            st.code(step, language="text")



================================================================================
FILE: pages/2_üî¨_Dhatu_Laboratory.py
================================================================================

import streamlit as st
import pandas as pd
from logic.dhatu_processor import DhatuDiagnostic
from core.core_foundation import sanskrit_varna_samyoga

st.set_page_config(page_title="‡§ß‡§æ‡§§‡•Å-‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡§∂‡§æ‡§≤‡§æ (DhƒÅtu Lab)", page_icon="üî¨", layout="wide")

# --- UI Styling ---
st.markdown("""
<style>
    .reportview-container { background: #fdfbfb; }
    .phase-card {
        background-color: white; border: 1px solid #e0e0e0;
        border-left: 5px solid #d35400; padding: 15px;
        border-radius: 10px; margin-bottom: 20px;
    }
    .rule-id { color: #d35400; font-weight: bold; font-family: 'Martel', serif; }
    .varna-badge {
        background-color: #fef5e7; border: 1px solid #f5c06b;
        padding: 2px 8px; border-radius: 5px; color: #b7950b; font-weight: bold;
    }
    .final-res { font-size: 2.5rem; font-family: 'Martel', serif; color: #1e8449; text-align: center; }
</style>
""", unsafe_allow_html=True)


def main():
    st.title("üî¨ ‡§ß‡§æ‡§§‡•Å-‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡§∂‡§æ‡§≤‡§æ: Upade≈õa to Action")
    st.markdown("### Task 2: Functional Root Transformation Engine")

    with st.sidebar:
        st.header("üß™ Input Diagnostic")
        raw_input = st.text_input("Enter Upade≈õa (Raw Root)", value="‡§°‡•Å‡§ï‡•É‡§û‡•ç")
        st.info("Examples: ‡§°‡•Å‡§ï‡•É‡§û‡•ç, ‡§∑‡•ç‡§Æ‡§ø‡§Å, ‡§£‡•Ä‡§û‡•ç, ‡§≠‡§ø‡§¶‡§ø‡§Å‡§∞‡•ç, ‡§®‡§¶‡§ø‡§Å")

    if raw_input:
        # Run the Task 2 Logic
        diag = DhatuDiagnostic(raw_input)

        c1, c2 = st.columns([1, 2])

        with c1:
            st.subheader("üìã Root Identity")
            st.metric("Input (Upade≈õa)", diag.raw)
            st.metric("Output (Functional)", diag.get_final_root())

            st.write("**Active Anubandha Markers:**")
            if diag.it_tags:
                for tag in diag.it_tags:
                    st.markdown(f'<span class="varna-badge">{tag}</span>', unsafe_allow_html=True)
            else:
                st.write("None")

        with c2:
            st.subheader("‚öôÔ∏è Transformation Timeline (PrakriyƒÅ)")

            for step in diag.history:
                rule, desc = step.split(": ", 1)
                st.markdown(f"""
                <div class="phase-card">
                    <span class="rule-id">üìñ S≈´tra {rule}</span><br>
                    {desc}
                </div>
                """, unsafe_allow_html=True)

        st.divider()

        # --- PHASE 6: Classification Table ---
        st.subheader("üìä DhƒÅtu Classification Matrix")
        final_root = diag.get_final_root()

        # Simple Logic to detect group for UI display
        category = "Ajanta" if final_root[-1] in "‡§Ö‡§Ü‡§á‡§à‡§â‡§ä‡§ã‡•†‡§è‡§ê‡§ì‡§î" else "Halanta"

        data = {
            "Parameter": ["Action Form", "Category", "Voice (Pada)", "It-Status"],
            "Value": [final_root, category, "Pending Task 3", "Se·π≠ (per DB)"]
        }
        st.table(pd.DataFrame(data))


if __name__ == "__main__":
    main()


================================================================================
FILE: pages/1_üß™_Dhatu_Lab.py
================================================================================

import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
"""
PAGE: DhƒÅtu Laboratory
"""
import streamlit as st
import pandas as pd
import json
import os
from logic.dhatu_processor import DhatuDiagnostic

st.set_page_config(page_title="DhƒÅtu Lab", page_icon="üß™", layout="wide")

# --- CSS Styling ---
st.markdown("""
<style>
    .sanskrit { font-family: 'Sanskrit 2003', 'Adobe Devanagari', sans-serif; font-size: 1.1em; }
    .tag-badge { 
        background-color: #e3f2fd; color: #1565c0; padding: 2px 8px; 
        border-radius: 12px; font-size: 0.8em; border: 1px solid #90caf9; margin-right: 4px;
    }
    .match-success { color: #2e7d32; font-weight: bold; }
    .match-fail { color: #c62828; font-weight: bold; }
    .metric-card {
        background-color: #f8f9fa; border-left: 4px solid #673ab7;
        padding: 15px; border-radius: 8px; margin-bottom: 10px;
    }
</style>
""", unsafe_allow_html=True)

st.title("üß™ DhƒÅtu PrakriyƒÅ Laboratory")

mode = st.radio("Mode", ["Single Analysis", "Master Database Validator"], horizontal=True)

if mode == "Single Analysis":
    col1, col2 = st.columns([1, 2])
    with col1:
        raw_root = st.text_input("Enter Upadesha (e.g. ‡§°‡•Å‡§ï‡•É‡§û‡•ç, ‡§∑‡§£‡•ç‡§Æ‡•Å‡§ñ‡§æ‡§Ø)", value="‡§°‡•Å‡§ï‡•É‡§û‡•ç")
        is_sub = st.checkbox("Is SubdhƒÅtu (NƒÅmadhƒÅtu)?")

        if st.button("Run Diagnostics", type="primary"):
            diag = DhatuDiagnostic(raw_root, is_subdhatu=is_sub)

            st.markdown(f"""
            <div class="metric-card">
                <h4>Diagnosis</h4>
                <p>Input: <b>{diag.raw}</b></p>
                <p>Root: <b class="sanskrit" style="color:#d32f2f; font-size:1.5em;">{diag.get_final_root()}</b></p>
                <p>Voice: {diag.pada}</p>
            </div>
            """, unsafe_allow_html=True)

            st.subheader("üß¨ It-Tags")
            st.write(diag.it_tags)

            st.session_state['dhatu_trace'] = diag.history

    with col2:
        if 'dhatu_trace' in st.session_state:
            st.subheader("üìú Step-by-Step Trace")
            trace_df = pd.DataFrame([s.split(": ", 1) for s in st.session_state['dhatu_trace']], columns=["Rule", "Operation"])
            st.table(trace_df)

elif mode == "Master Database Validator":
    # Load Data
    @st.cache_data
    def load_data():
        paths = ["data/dhatu_master_structured.json", "dhatu_master_structured.json"]
        for p in paths:
            if os.path.exists(p):
                with open(p, "r", encoding="utf-8") as f: return json.load(f)
        return []

    raw_db = load_data()

    if not raw_db:
        st.error("Database not found in 'data/' folder.")
    else:
        st.caption(f"Loaded {len(raw_db)} roots.")

        # Filters
        with st.expander("üîç Filters"):
            col_f1, col_f2 = st.columns(2)
            sel_gana = col_f1.multiselect("Gana", sorted(list(set([x.get('gana') for x in raw_db if x.get('gana')]))))
            sel_pada = col_f2.multiselect("Pada", sorted(list(set([x.get('pada') for x in raw_db if x.get('pada')]))))

        # Process
        processed_rows = []
        # Optimization: Limit to first 100 if no filter, or all if filtered
        limit = 100 if not (sel_gana or sel_pada) else 5000

        count = 0
        for entry in raw_db:
            if sel_gana and entry.get('gana') not in sel_gana: continue
            if sel_pada and entry.get('pada') not in sel_pada: continue

            upadesha = entry.get('upadesha', '')
            if not upadesha: upadesha = entry.get('mula_dhatu', '')
            target = entry.get('mula_dhatu', '')

            diag = DhatuDiagnostic(upadesha)
            derived = diag.get_final_root()

            match = derived == target
            status = "‚úÖ" if match else "‚ùå"

            # Voice Match Logic
            trad_voice = entry.get('pada', '')
            eng_voice = diag.pada
            voice_ok = "‚ö†Ô∏è"
            if "Atmanepada" in eng_voice and "‡§Ü‡§§‡•ç‡§Æ‡§®‡•á" in trad_voice: voice_ok = "‚úÖ"
            elif "Parasmaipada" in eng_voice and "‡§™‡§∞‡§∏‡•ç‡§Æ‡•à" in trad_voice: voice_ok = "‚úÖ"
            elif "Ubhayapada" in eng_voice and "‡§â‡§≠‡§Ø" in trad_voice: voice_ok = "‚úÖ"

            processed_rows.append({
                "ID": entry.get('identifier', ''),
                "Upadesha": f"<span class='sanskrit'>{upadesha}</span>",
                "Target": f"<span class='sanskrit'>{target}</span>",
                "Output": f"<span class='sanskrit {'match-success' if match else 'match-fail'}'>{derived}</span>",
                "Status": status,
                "Voice (Engine)": f"{voice_ok} {eng_voice}",
                "Voice (JSON)": f"<span class='sanskrit'>{trad_voice}</span>",
                "Meaning": entry.get('artha_sanskrit', '')
            })
            count += 1
            if count >= limit: break

        df = pd.DataFrame(processed_rows)

        tab1, tab2 = st.tabs(["üìä Data Table", "‚ùå Mismatches Only"])
        with tab1:
            st.write(df.to_html(escape=False, index=False), unsafe_allow_html=True)
        with tab2:
            mismatches = df[df["Status"] == "‚ùå"]
            if not mismatches.empty:
                st.write(mismatches.to_html(escape=False, index=False), unsafe_allow_html=True)
            else:
                st.success("No mismatches in this selection!")



================================================================================
FILE: pages/1_üîç_Declension_Engine.py
================================================================================

import streamlit as st
import pandas as pd
from engine_main import PrakriyaLogger
from logic.subanta_processor import SubantaProcessor

st.set_page_config(page_title="‡§∂‡§¨‡•ç‡§¶-‡§∞‡•Ç‡§™ ‡§∏‡§ø‡§¶‡•ç‡§ß‡§ø ‡§Ø‡§®‡•ç‡§§‡•ç‡§∞", page_icon="üïâÔ∏è", layout="wide")

# --- CSS Styling ---
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Martel:wght@400;800&family=Noto+Sans:wght@400;700&display=swap');
    body { font-family: 'Noto Sans', sans-serif; background-color: #f4f6f9; }
    
    /* Card Base */
    .step-card { 
        background-color: #ffffff; padding: 16px 20px; margin-bottom: 16px; 
        border-radius: 12px; box-shadow: 0 2px 8px rgba(0,0,0,0.06); 
        border: 1px solid #e0e0e0;
        transition: all 0.2s ease-in-out;
    }
    .step-card:hover { transform: translateY(-2px); box-shadow: 0 4px 12px rgba(0,0,0,0.1); }

    /* Border Colors by Type */
    .border-meta { border-left: 6px solid #2980b9; }   /* Blue: Definitions */
    .border-action { border-left: 6px solid #8e44ad; } /* Purple: Transformations */
    
    /* Rule Badge (The Number) */
    .rule-badge {
        padding: 4px 8px; border-radius: 6px; font-weight: bold; font-size: 0.85rem;
        display: inline-block; margin-right: 8px; color: white; vertical-align: middle;
    }
    .badge-meta { background-color: #2980b9; }
    .badge-action { background-color: #8e44ad; }

    /* Authority Badge (The Rishi) */
    .auth-badge {
        padding: 3px 8px; border-radius: 12px; font-size: 0.7rem; font-weight: 700;
        text-transform: uppercase; border: 1px solid; display: inline-block; 
        margin-right: 8px; vertical-align: middle; letter-spacing: 0.5px;
    }
    
    /* Authority Colors */
    .auth-panini { color: #27ae60; border-color: #27ae60; background-color: #eafaf1; } /* Green */
    .auth-katyayana { color: #d35400; border-color: #d35400; background-color: #fcece0; } /* Orange */
    .auth-patanjali { color: #c0392b; border-color: #c0392b; background-color: #f9ebeb; } /* Red */
    .auth-other { color: #7f8c8d; border-color: #7f8c8d; background-color: #f4f6f7; } /* Grey */

    /* Typography */
    .sutra-name {
        font-family: 'Martel', serif; font-weight: 800; font-size: 1.2rem; color: #2c3e50;
        vertical-align: middle;
    }
    .op-text {
        font-size: 0.95rem; color: #555; margin-top: 8px; font-weight: 500; display: flex; align-items: center;
    }
    .res-sanskrit { 
        font-family: 'Martel', serif; font-size: 1.6rem; font-weight: 800; color: #2c3e50; 
    }
    
    /* Varna Tiles */
    .varna-container { margin-top: 8px; display: flex; flex-wrap: wrap; gap: 4px; }
    .varna-tile { 
        background-color: #fdfdfd; border: 1px solid #d1d5db; border-bottom: 2px solid #9ca3af;
        padding: 2px 8px; border-radius: 4px; color: #d35400; 
        font-family: 'Courier New', monospace; font-weight: bold; font-size: 0.95rem; 
    }
    
    /* Step Counter */
    .step-num { font-size: 0.7rem; color: #95a5a6; font-weight: 800; letter-spacing: 1px; text-transform: uppercase; }
</style>
""", unsafe_allow_html=True)

VIBHAKTI_MAP = {1: "‡§™‡•ç‡§∞‡§•‡§Æ‡§æ", 2: "‡§¶‡•ç‡§µ‡§ø‡§§‡•Ä‡§Ø‡§æ", 3: "‡§§‡•É‡§§‡•Ä‡§Ø‡§æ", 4: "‡§ö‡§§‡•Å‡§∞‡•ç‡§•‡•Ä", 5: "‡§™‡§û‡•ç‡§ö‡§Æ‡•Ä", 6: "‡§∑‡§∑‡•ç‡§†‡•Ä", 7: "‡§∏‡§™‡•ç‡§§‡§Æ‡•Ä", 8: "‡§∏‡§Æ‡•ç‡§¨‡•ã‡§ß‡§®"}
VACANA_MAP = {1: "‡§è‡§ï‡§µ‡§ö‡§®‡§Æ‡•ç", 2: "‡§¶‡•ç‡§µ‡§ø‡§µ‡§ö‡§®‡§Æ‡•ç", 3: "‡§¨‡§π‡•Å‡§µ‡§ö‡§®‡§Æ‡•ç"}

def get_auth_class(source_text):
    """Returns CSS class based on Authority Name."""
    s = source_text.lower()
    if "panini" in s or "pƒÅ·πáini" in s: return "auth-panini"
    if "katyayana" in s or "vartika" in s: return "auth-katyayana"
    if "patanjali" in s or "bhashya" in s: return "auth-patanjali"
    return "auth-other"

def get_card_style(rule_num):
    if rule_num.startswith("1.2") or rule_num.startswith("1.4") or \
       rule_num.startswith("3.1") or rule_num.startswith("4.1.1"):
        return "border-meta", "badge-meta"
    return "border-action", "badge-action"

def generate_card_html(step_index, step_data):
    rule_full = step_data['rule']
    op = step_data['operation']
    res = step_data['result']
    viccheda = step_data['viccheda']
    source = step_data.get('source', 'Unknown')
    vartika = step_data.get('vartika_html', '')
    
    # Split Number and Name
    if " " in rule_full:
        parts = rule_full.split(" ", 1)
        r_num = parts[0]
        r_name = parts[1]
    else:
        r_num = rule_full
        r_name = ""

    # Determine Styles
    border_class, badge_class = get_card_style(r_num)
    auth_class = get_auth_class(source)

    # Viccheda Tiles
    viccheda_html = ""
    if viccheda:
        parts = viccheda.split(" + ")
        tiles = "".join([f'<div class="varna-tile">{p}</div>' for p in parts])
        viccheda_html = f'<div class="varna-container">{tiles}</div>'

    # Link
    link = "#"
    if "." in r_num:
        try:
            c, p, s = r_num.split('.')
            link = f"https://ashtadhyayi.com/sutraani/{c}/{p}/{s}"
        except: pass

    # --- HTML STRUCTURE (FIXED) ---
    return f"""
    <div class="step-card {border_class}">
        <div style="display:flex; justify-content:space-between; align-items:flex-start;">
            <div style="flex-grow: 1;">
                <div style="margin-bottom: 6px;">
                    <span class="auth-badge {auth_class}">{source}</span>
                    <a href="{link}" target="_blank" style="text-decoration:none;">
                        <span class="rule-badge {badge_class}">üìñ {r_num}</span>
                    </a>
                    <span class="sutra-name">{r_name}</span>
                </div>
                
                {vartika}
                
                <div class="op-text">
                    <span style="margin-right:6px;">‚öôÔ∏è</span> {op}
                </div>
                
                {viccheda_html}
            </div>
            
            <div style="text-align:right; min-width: 100px; margin-left: 15px;">
                <div class="step-num">STEP {step_index + 1}</div>
                <div class="res-sanskrit">{res}</div>
            </div>
        </div>
    </div>
    """

def main():
    st.title("üïâÔ∏è ‡§∂‡§¨‡•ç‡§¶-‡§∞‡•Ç‡§™ ‡§∏‡§ø‡§¶‡•ç‡§ß‡§ø ‡§Ø‡§®‡•ç‡§§‡•ç‡§∞")
    st.markdown("### Paninian Derivation Engine (Glassbox AI)")
    
    with st.sidebar:
        st.header("üéõÔ∏è ‡§á‡§®‡§™‡•Å‡§ü (Input)")
        stem = st.text_input("‡§™‡•ç‡§∞‡§æ‡§§‡§ø‡§™‡§¶‡§ø‡§ï (Stem)", value="‡§∞‡§æ‡§Æ")
        
        force_p = st.checkbox("Force Pratipadika", value=False, 
                              help="Enable to bypass initial dictionary checks.")
        
        st.success("‚úÖ **Supported:** Ram, Hari, Guru, Sarva, etc.")
        st.markdown("---")
        st.markdown("**Legend:**")
        st.markdown('<span class="auth-badge auth-panini">PANINI</span> Sutra', unsafe_allow_html=True)
        st.markdown('<span class="auth-badge auth-katyayana">KATYAYANA</span> Vartika', unsafe_allow_html=True)

    # Main Action Area
    c1, c2, c3 = st.columns([1, 1, 1])
    with c1: v_sel = st.selectbox("‡§µ‡§ø‡§≠‡§ï‡•ç‡§§‡§ø", list(VIBHAKTI_MAP.keys()), format_func=lambda x: VIBHAKTI_MAP[x])
    with c2: n_sel = st.selectbox("‡§µ‡§ö‡§®", list(VACANA_MAP.keys()), format_func=lambda x: VACANA_MAP[x])
    with c3: 
        st.write(""); st.write("")
        btn = st.button("üöÄ ‡§∏‡§ø‡§¶‡•ç‡§ß‡§ø ‡§ï‡§∞‡•á‡§Ç (Derive)", type="primary", use_container_width=True)

    if btn:
        logger = PrakriyaLogger()
        res = SubantaProcessor.derive_pada(stem, v_sel, n_sel, logger, force_p)
        
        st.success(f"‡§∏‡§ø‡§¶‡•ç‡§ß ‡§™‡§¶: **{res}**")
        
        # Display Cards
        for i, step in enumerate(logger.get_history()):
            st.markdown(generate_card_html(i, step), unsafe_allow_html=True)

    # Full Table Expansion
    if stem:
        with st.expander(f"üìö {stem} - ‡§∏‡§Æ‡•ç‡§™‡•Ç‡§∞‡•ç‡§£ ‡§∞‡•Ç‡§™ ‡§∏‡§æ‡§∞‡§ø‡§£‡•Ä (Full Table)", expanded=False):
            data = []
            for v in range(1, 9):
                row = {"‡§µ‡§ø‡§≠‡§ï‡•ç‡§§‡§ø": VIBHAKTI_MAP[v]}
                for n in range(1, 4):
                    try: w = SubantaProcessor.derive_pada(stem, v, n, None, force_p)
                    except: w = "Error"
                    row[VACANA_MAP[n]] = w
                data.append(row)
            st.dataframe(pd.DataFrame(data), hide_index=True, use_container_width=True)

if __name__ == "__main__":
    main()



