================================================================================
FILE: app.py
================================================================================

"""
FILE: app.py (Hindi Localization)
"""
import streamlit as st

st.set_page_config(
    page_title="‡§™‡§æ‡§£‡§ø‡§®‡•Ä‡§Ø ‡§µ‡•ç‡§Ø‡§æ‡§ï‡§∞‡§£ ‡§Ø‡§®‡•ç‡§§‡•ç‡§∞",
    layout="wide",
    page_icon="üïâÔ∏è",
    initial_sidebar_state="expanded"
)

st.title("üïâÔ∏è ‡§™‡§æ‡§£‡§ø‡§®‡•Ä‡§Ø ‡§µ‡•ç‡§Ø‡§æ‡§ï‡§∞‡§£ ‡§Ø‡§®‡•ç‡§§‡•ç‡§∞ (Digital Ashtadhyayi)")
st.markdown("### *‡§Ø‡•á‡§® ‡§ß‡•å‡§§‡§æ ‡§ó‡§ø‡§∞‡§É ‡§™‡•Å‡§Ç‡§∏‡§æ‡§Ç ‡§µ‡§ø‡§Æ‡§≤‡•à‡§É ‡§∂‡§¨‡•ç‡§¶‡§µ‡§æ‡§∞‡§ø‡§≠‡§ø‡§É...*")
st.markdown("---")

col1, col2 = st.columns(2)

with col1:
    st.info("### üß™ ‡§ß‡§æ‡§§‡•Å ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡§∂‡§æ‡§≤‡§æ (DhƒÅtu Lab)")
    st.markdown("""
    **‡§∏‡•ç‡§•‡§ø‡§§‡§ø:** ‚úÖ ‡•ß‡•¶‡•¶% ‡§∏‡§ø‡§¶‡•ç‡§ß (Siddha)
    * **‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£:** ‡•®‡•¶‡•¶‡•¶+ ‡§ß‡§æ‡§§‡•Å
    * **‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ:** ‡§∑‡§§‡•ç‡§µ, ‡§£‡§§‡•ç‡§µ, ‡§â‡§™‡§ß‡§æ-‡§¶‡•Ä‡§∞‡•ç‡§ò
    * **‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ:** ‡§â‡§™‡§¶‡•á‡§∂ ‡§°‡§ø‡§ï‡•ã‡§°‡§∞
    """)

with col2:
    st.info("### ‚ö° ‡§§‡§ø‡§ô‡§®‡•ç‡§§ ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡§∂‡§æ‡§≤‡§æ (Ti·πÖanta Lab)")
    st.markdown("""
    **‡§∏‡•ç‡§•‡§ø‡§§‡§ø:** üöß ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£‡§æ‡§ß‡•Ä‡§® (Phase 1)
    * **‡§≤‡§ï‡§æ‡§∞:** ‡§≤‡§ü‡•ç (‡§µ‡§∞‡•ç‡§§‡§Æ‡§æ‡§®)
    * **‡§ï‡§æ‡§∞‡•ç‡§Ø:** ‡§µ‡§ø‡§ï‡§∞‡§£ (‡§∂‡§™‡•ç), ‡§ó‡•Å‡§£, ‡§Ö‡§Ø‡§æ‡§¶‡§ø
    * **‡§™‡§∞‡§ø‡§£‡§æ‡§Æ:** ‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§∞‡•Ç‡§™ (‡§â‡§¶‡§æ. ‡§≠‡§µ‡§§‡§ø)
    """)

st.success("üëà ‡§ï‡•É‡§™‡§Ø‡§æ ‡§∏‡§æ‡§á‡§°‡§¨‡§æ‡§∞ (Sidebar) ‡§∏‡•á ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡§∂‡§æ‡§≤‡§æ ‡§ö‡•Å‡§®‡•á‡§Ç‡•§")



================================================================================
FILE: streamline_reverse.py
================================================================================

import os
from pathlib import Path


def reverse_to_stable_siddha():
    # 1. REVERT CORE: maheshwara_sutras.py
    # Reverting to the high-precision tuple logic without the added prakriya logging.
    maheshwara_path = Path("core/maheshwara_sutras.py")
    maheshwara_code = '''"""
FILE: core/maheshwara_sutras.py
"""
class MaheshwaraSutras:
    # Explicit tuples: (Content_Characters, IT_Marker_String)
    SUTRAS_DATA = [
        ("‡§Ö‡§á‡§â", "‡§£‡•ç"), ("‡§ã‡§å", "‡§ï‡•ç"), ("‡§è‡§ì", "‡§ô‡•ç"), ("‡§ê‡§î", "‡§ö‡•ç"),
        ("‡§π‡§Ø‡§µ‡§∞", "‡§ü‡•ç"), ("‡§≤", "‡§£‡•ç"), ("‡§û‡§Æ‡§ô‡§£‡§®", "‡§Æ‡•ç"), ("‡§ù‡§≠", "‡§û‡•ç"),
        ("‡§ò‡§¢‡§ß", "‡§∑‡•ç"), ("‡§ú‡§¨‡§ó‡§°‡§¶", "‡§∂‡•ç"), ("‡§ñ‡§´‡§õ‡§†‡§•‡§ö‡§ü‡§§", "‡§µ‡•ç"), ("‡§ï‡§™", "‡§Ø‡•ç"),
        ("‡§∂‡§∑‡§∏", "‡§∞‡•ç"), ("‡§π", "‡§≤‡•ç")
    ]

    SAVARNA_MAP = {'‡§Ö': ['‡§Ö', '‡§Ü'], '‡§á': ['‡§á', '‡§à'], '‡§â': ['‡§â', '‡§ä'], '‡§ã': ['‡§ã', '‡•†'], '‡§å': ['‡§å']}

    @staticmethod
    def get_pratyahara(p_name, force_n2=False):
        if not p_name or len(p_name) < 2: return set()
        p_name = p_name.strip()
        adi = p_name[0]
        it = p_name[1:]

        chars = set()
        collecting = False
        n_count = 0

        for content, marker in MaheshwaraSutras.SUTRAS_DATA:
            for char in content:
                if char == adi: collecting = True
                if collecting:
                    chars.add(char)
                    if char in MaheshwaraSutras.SAVARNA_MAP:
                        chars.update(MaheshwaraSutras.SAVARNA_MAP[char])

            if collecting and marker == it:
                if it == '‡§£‡•ç':
                    n_count += 1
                    if force_n2 and n_count == 1: continue
                break
        return chars
'''
    maheshwara_path.write_text(maheshwara_code, encoding='utf-8')
    print("‚úÖ Core: MaheshwaraSutras reverted to high-precision stable state.")

    # 2. REVERT CORE: sanjna_controller.py
    # Removing the 1.1.8 stamping logic and returning to standard It-Prakaran.
    sanjna_path = Path("core/sanjna_controller.py")
    sanjna_code = '''"""
FILE: core/sanjna_controller.py
"""
from core.core_foundation import Varna, UpadeshaType

class SanjnaController:
    @staticmethod
    def run_it_prakaran(varnas, context=UpadeshaType.VIBHAKTI):
        if not varnas: return varnas, []
        res = list(varnas)
        applied = []
        halantyam_applied = False

        if res:
            last = res[-1]
            if not last.is_vowel:
                is_tusma = last.char in ['‡§§', '‡§•', '‡§¶', '‡§ß', '‡§®', '‡§∏', '‡§∏‡•ç', '‡§Æ', '‡§Æ‡•ç']
                if not is_tusma:
                    if last.char in ['‡§™‡•ç', '‡§ü', '‡§ô', '‡§ü‡•ç', '‡§£‡•ç', '‡§û‡•ç']:
                        res.pop()
                        applied.append("1.3.3")
                        halantyam_applied = True

        if res:
            c0 = res[0].char
            if c0 in ['‡§ö', '‡§õ', '‡§ú', '‡§ù', '‡§û', '‡§ü', '‡§†', '‡§°', '‡§¢', '‡§£']:
                res.pop(0); applied.append("1.3.7")
            elif c0 in ['‡§≤', '‡§∂‡•ç', '‡§∂', '‡§ï', '‡§ñ', '‡§ó', '‡§ò', '‡§ô']:
                res.pop(0); applied.append("1.3.8")

        if not halantyam_applied:
            if len(res) >= 1 and res[0].char == '‡§∏':
                if len(res) > 1 and res[1].char in ['‡§â', '‡•Å', '‡§Å']:
                     while len(res) > 1: res.pop()
                     applied.append("1.3.2")

        return res, applied
'''
    sanjna_path.write_text(sanjna_code, encoding='utf-8')
    print("‚úÖ Logic: SanjnaController reverted to stable It-Prakaran logic.")


if __name__ == "__main__":
    reverse_to_stable_siddha()
    print("\\nüöÄ REVERSION COMPLETE. The engine is back to the stable 80/80 state.")


================================================================================
FILE: pages/2_üî¨_Dhatu_Laboratory.py
================================================================================

import streamlit as st
import pandas as pd
from logic.dhatu_processor import DhatuDiagnostic
from core.core_foundation import sanskrit_varna_samyoga

st.set_page_config(page_title="‡§ß‡§æ‡§§‡•Å-‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡§∂‡§æ‡§≤‡§æ (DhƒÅtu Lab)", page_icon="üî¨", layout="wide")

# --- UI Styling ---
st.markdown("""
<style>
    .reportview-container { background: #fdfbfb; }
    .phase-card {
        background-color: white; border: 1px solid #e0e0e0;
        border-left: 5px solid #d35400; padding: 15px;
        border-radius: 10px; margin-bottom: 20px;
    }
    .rule-id { color: #d35400; font-weight: bold; font-family: 'Martel', serif; }
    .varna-badge {
        background-color: #fef5e7; border: 1px solid #f5c06b;
        padding: 2px 8px; border-radius: 5px; color: #b7950b; font-weight: bold;
    }
    .final-res { font-size: 2.5rem; font-family: 'Martel', serif; color: #1e8449; text-align: center; }
</style>
""", unsafe_allow_html=True)


def main():
    st.title("üî¨ ‡§ß‡§æ‡§§‡•Å-‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡§∂‡§æ‡§≤‡§æ: Upade≈õa to Action")
    st.markdown("### Task 2: Functional Root Transformation Engine")

    with st.sidebar:
        st.header("üß™ Input Diagnostic")
        raw_input = st.text_input("Enter Upade≈õa (Raw Root)", value="‡§°‡•Å‡§ï‡•É‡§û‡•ç")
        st.info("Examples: ‡§°‡•Å‡§ï‡•É‡§û‡•ç, ‡§∑‡•ç‡§Æ‡§ø‡§Å, ‡§£‡•Ä‡§û‡•ç, ‡§≠‡§ø‡§¶‡§ø‡§Å‡§∞‡•ç, ‡§®‡§¶‡§ø‡§Å")

    if raw_input:
        # Run the Task 2 Logic
        diag = DhatuDiagnostic(raw_input)

        c1, c2 = st.columns([1, 2])

        with c1:
            st.subheader("üìã Root Identity")
            st.metric("Input (Upade≈õa)", diag.raw)
            st.metric("Output (Functional)", diag.get_final_root())

            st.write("**Active Anubandha Markers:**")
            if diag.it_tags:
                for tag in diag.it_tags:
                    st.markdown(f'<span class="varna-badge">{tag}</span>', unsafe_allow_html=True)
            else:
                st.write("None")

        with c2:
            st.subheader("‚öôÔ∏è Transformation Timeline (PrakriyƒÅ)")

            for step in diag.history:
                rule, desc = step.split(": ", 1)
                st.markdown(f"""
                <div class="phase-card">
                    <span class="rule-id">üìñ S≈´tra {rule}</span><br>
                    {desc}
                </div>
                """, unsafe_allow_html=True)

        st.divider()

        # --- PHASE 6: Classification Table ---
        st.subheader("üìä DhƒÅtu Classification Matrix")
        final_root = diag.get_final_root()

        # Simple Logic to detect group for UI display
        category = "Ajanta" if final_root[-1] in "‡§Ö‡§Ü‡§á‡§à‡§â‡§ä‡§ã‡•†‡§è‡§ê‡§ì‡§î" else "Halanta"

        data = {
            "Parameter": ["Action Form", "Category", "Voice (Pada)", "It-Status"],
            "Value": [final_root, category, "Pending Task 3", "Se·π≠ (per DB)"]
        }
        st.table(pd.DataFrame(data))


if __name__ == "__main__":
    main()


================================================================================
FILE: pages/1_üîç_Declension_Engine.py
================================================================================

import streamlit as st
import pandas as pd
from engine_main import PrakriyaLogger
from logic.subanta_processor import SubantaProcessor

st.set_page_config(page_title="‡§∂‡§¨‡•ç‡§¶-‡§∞‡•Ç‡§™ ‡§∏‡§ø‡§¶‡•ç‡§ß‡§ø", page_icon="üïâÔ∏è", layout="wide")

# --- CSS Styling (Devanagari Font Optimization) ---
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Martel:wght@400;800&family=Noto+Sans:wght@400;700&display=swap');
    body { font-family: 'Noto Sans', sans-serif; }
    .step-card { 
        background-color: #ffffff; padding: 16px; margin-bottom: 12px; 
        border-radius: 8px; border: 1px solid #e0e0e0; border-left: 5px solid #2980b9;
    }
    .sutra-name { font-family: 'Martel', serif; font-weight: 800; font-size: 1.2rem; color: #2c3e50; }
    .op-text { font-size: 1rem; color: #555; }
    .res-sanskrit { font-family: 'Martel', serif; font-size: 1.5rem; font-weight: bold; color: #8e44ad; }
    .auth-badge { background-color: #eafaf1; color: #27ae60; padding: 2px 8px; border-radius: 4px; font-size: 0.8rem; font-weight: bold; border: 1px solid #27ae60; }
</style>
""", unsafe_allow_html=True)

VIBHAKTI_MAP = {1: "‡§™‡•ç‡§∞‡§•‡§Æ‡§æ", 2: "‡§¶‡•ç‡§µ‡§ø‡§§‡•Ä‡§Ø‡§æ", 3: "‡§§‡•É‡§§‡•Ä‡§Ø‡§æ", 4: "‡§ö‡§§‡•Å‡§∞‡•ç‡§•‡•Ä", 5: "‡§™‡§û‡•ç‡§ö‡§Æ‡•Ä", 6: "‡§∑‡§∑‡•ç‡§†‡•Ä", 7: "‡§∏‡§™‡•ç‡§§‡§Æ‡•Ä", 8: "‡§∏‡§Æ‡•ç‡§¨‡•ã‡§ß‡§®"}
VACANA_MAP = {1: "‡§è‡§ï‡§µ‡§ö‡§®‡§Æ‡•ç", 2: "‡§¶‡•ç‡§µ‡§ø‡§µ‡§ö‡§®‡§Æ‡•ç", 3: "‡§¨‡§π‡•Å‡§µ‡§ö‡§®‡§Æ‡•ç"}

def generate_card(step_index, step_data):
    return f"""
    <div class="step-card">
        <div>
            <span class="auth-badge">{step_data.get('source', '‡§™‡§æ‡§£‡§ø‡§®‡§ø')}</span>
            <span class="sutra-name">üìñ {step_data['rule']} {step_data['name']}</span>
        </div>
        <div class="op-text">‚öôÔ∏è {step_data['desc']}</div>
        <div style="text-align:right; margin-top:5px;">
            <span class="res-sanskrit">{step_data['result']}</span>
        </div>
    </div>
    """

def main():
    st.title("üïâÔ∏è ‡§∂‡§¨‡•ç‡§¶-‡§∞‡•Ç‡§™ ‡§∏‡§ø‡§¶‡•ç‡§ß‡§ø ‡§Ø‡§®‡•ç‡§§‡•ç‡§∞")
    st.markdown("### ‡§™‡§æ‡§£‡§ø‡§®‡•Ä‡§Ø ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ (Glassbox Engine)")

    with st.sidebar:
        st.header("üéõÔ∏è ‡§á‡§®‡§™‡•Å‡§ü (Input)")
        stem = st.text_input("‡§™‡•ç‡§∞‡§æ‡§§‡§ø‡§™‡§¶‡§ø‡§ï (Stem)", value="‡§∞‡§æ‡§Æ")
        force_p = st.checkbox("‡§™‡•ç‡§∞‡§æ‡§§‡§ø‡§™‡§¶‡§ø‡§ï ‡§Æ‡§æ‡§® ‡§≤‡•á‡§Ç (Force)", value=False)
        st.success("‚úÖ ‡§∏‡§Æ‡§∞‡•ç‡§•‡§ø‡§§: ‡§∞‡§æ‡§Æ, ‡§π‡§∞‡§ø, ‡§ó‡•Å‡§∞‡•Å, ‡§∞‡§Æ‡§æ, ‡§∏‡§∞‡•ç‡§µ")

    c1, c2, c3 = st.columns(3)
    with c1: v_sel = st.selectbox("‡§µ‡§ø‡§≠‡§ï‡•ç‡§§‡§ø", list(VIBHAKTI_MAP.keys()), format_func=lambda x: VIBHAKTI_MAP[x])
    with c2: n_sel = st.selectbox("‡§µ‡§ö‡§®", list(VACANA_MAP.keys()), format_func=lambda x: VACANA_MAP[x])
    with c3: 
        st.write(""); st.write("")
        btn = st.button("üöÄ ‡§∏‡§ø‡§¶‡•ç‡§ß‡§ø ‡§ï‡§∞‡•á‡§Ç (Derive)", type="primary", use_container_width=True)

    if btn:
        logger = PrakriyaLogger()
        res = SubantaProcessor.derive_pada(stem, v_sel, n_sel, logger, force_p)

        st.success(f"‡§∏‡§ø‡§¶‡•ç‡§ß ‡§™‡§¶: **{res}**")
        for i, step in enumerate(logger.get_history()):
            st.markdown(generate_card(i, step), unsafe_allow_html=True)

if __name__ == "__main__":
    main()



================================================================================
FILE: pages/1_test.py
================================================================================

import streamlit as st
import pandas as pd
from engine_main import PrakriyaLogger
from logic.subanta_processor import SubantaProcessor

st.set_page_config(page_title="‡§∂‡§¨‡•ç‡§¶-‡§∞‡•Ç‡§™ ‡§∏‡§ø‡§¶‡•ç‡§ß‡§ø ‡§Ø‡§®‡•ç‡§§‡•ç‡§∞", page_icon="üïâÔ∏è", layout="wide")

# --- Glassbox CSS Styling (Enhanced for MacBook High-DPI) ---
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Martel:wght@400;800&family=Noto+Sans:wght@400;700&display=swap');
    body { font-family: 'Noto Sans', sans-serif; background-color: #f4f6f9; }
    
    .step-card { 
        background-color: #ffffff; padding: 18px 24px; margin-bottom: 16px; 
        border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.05); 
        border: 1px solid #e0e0e0; transition: all 0.2s ease-in-out;
    }
    .step-card:hover { transform: scale(1.01); box-shadow: 0 6px 16px rgba(0,0,0,0.08); }
    .border-meta { border-left: 8px solid #2980b9; }   /* Logic/Definitions */
    .border-action { border-left: 8px solid #8e44ad; } /* Phonetic Actions */
    
    .rule-badge {
        padding: 5px 10px; border-radius: 6px; font-weight: 800; font-size: 0.85rem;
        color: white; text-decoration: none; display: inline-block;
    }
    .badge-meta { background-color: #2980b9; }
    .badge-action { background-color: #8e44ad; }
    
    .auth-badge {
        padding: 4px 10px; border-radius: 20px; font-size: 0.7rem; font-weight: 900;
        text-transform: uppercase; border: 1.5px solid; display: inline-block; 
        margin-right: 10px; letter-spacing: 0.8px;
    }
    .auth-panini { color: #27ae60; border-color: #27ae60; background-color: #eafaf1; }
    .auth-katyayana { color: #d35400; border-color: #d35400; background-color: #fcece0; }

    .res-sanskrit { 
        font-family: 'Martel', serif; font-size: 1.8rem; font-weight: 800; color: #2c3e50; 
    }
    .varna-tile { 
        background-color: #f8fafc; border: 1.5px solid #cbd5e1;
        padding: 4px 10px; border-radius: 6px; color: #d35400; 
        font-family: 'Courier New', monospace; font-weight: 900; font-size: 1rem; 
    }
</style>
""", unsafe_allow_html=True)

VIBHAKTI_MAP = {1: "‡§™‡•ç‡§∞‡§•‡§Æ‡§æ", 2: "‡§¶‡•ç‡§µ‡§ø‡§§‡•Ä‡§Ø‡§æ", 3: "‡§§‡•É‡§§‡•Ä‡§Ø‡§æ", 4: "‡§ö‡§§‡•Å‡§∞‡•ç‡§•‡•Ä", 5: "‡§™‡§û‡•ç‡§ö‡§Æ‡•Ä", 6: "‡§∑‡§∑‡•ç‡§†‡•Ä", 7: "‡§∏‡§™‡•ç‡§§‡§Æ‡•Ä", 8: "‡§∏‡§Æ‡•ç‡§¨‡•ã‡§ß‡§®"}
VACANA_MAP = {1: "‡§è‡§ï‡§µ‡§ö‡§®‡§Æ‡•ç", 2: "‡§¶‡•ç‡§µ‡§ø‡§µ‡§ö‡§®‡§Æ‡•ç", 3: "‡§¨‡§π‡•Å‡§µ‡§ö‡§®‡§Æ‡•ç"}

def get_style_meta(rule_num):
    """Assigns color coding based on PƒÅ·πáinian Rule Domain."""
    if any(rule_num.startswith(x) for x in ["1.1", "1.2", "1.4", "3.1"]):
        return "border-meta", "badge-meta"
    return "border-action", "badge-action"

def generate_card_html(index, data):
    rule = data.get('rule', '0.0.0')
    name = data.get('name', 'S≈´tra')
    op = data.get('operation', 'Processing')
    res = data.get('result', '')
    viccheda = data.get('viccheda', '')
    source = data.get('source', 'PƒÅ·πáini').upper()

    border_class, badge_class = get_style_meta(rule)
    auth_class = "auth-panini" if "PANINI" in source else "auth-katyayana"
    link = f"https://ashtadhyayi.com/sutraani/{rule.replace('.', '/')}" if "." in rule else "#"

    tiles = "".join([f'<div class="varna-tile">{p}</div>' for p in viccheda.split(" + ")]) if viccheda else ""

    return f"""
    <div class="step-card {border_class}">
        <div style="display:flex; justify-content:space-between; align-items:center;">
            <div>
                <span class="auth-badge {auth_class}">{source}</span>
                <a href="{link}" target="_blank" class="rule-badge {badge_class}">üìñ {rule}</a>
                <span style="font-family:'Martel'; font-weight:800; font-size:1.2rem; margin-left:10px;">{name}</span>
                <div style="margin-top:10px; color:#555; font-weight:500;">‚öôÔ∏è {op}</div>
                <div style="display:flex; gap:6px; margin-top:8px;">{tiles}</div>
            </div>
            <div style="text-align:right;">
                <div style="font-size:0.7rem; color:#94a3b8; font-weight:900;">STEP {index+1}</div>
                <div class="res-sanskrit">{res}</div>
            </div>
        </div>
    </div>
    """

def main():
    st.title("üïâÔ∏è ‡§∂‡§¨‡•ç‡§¶-‡§∞‡•Ç‡§™ ‡§∏‡§ø‡§¶‡•ç‡§ß‡§ø ‡§Ø‡§®‡•ç‡§§‡•ç‡§∞")
    st.markdown("### Glassbox AI: PƒÅ·πáinian Morphological Derivation")

    with st.sidebar:
        st.header("üéõÔ∏è Input Parameters")
        stem = st.text_input("‡§™‡•ç‡§∞‡§æ‡§§‡§ø‡§™‡§¶‡§ø‡§ï (Stem)", value="‡§∞‡§æ‡§Æ")
        force_p = st.checkbox("Force Pratipadika", value=True)
        st.info("Pillar R17: Validating output against Lak·π£ya")
    
    col1, col2 = st.columns(2)
    with col1: v_sel = st.selectbox("Vibhakti", list(VIBHAKTI_MAP.keys()), format_func=lambda x: VIBHAKTI_MAP[x])
    with col2: n_sel = st.selectbox("Vacana", list(VACANA_MAP.keys()), format_func=lambda x: VACANA_MAP[x])

    if st.button("üöÄ Derive PrakriyƒÅ", type="primary", use_container_width=True):
        logger = PrakriyaLogger()
        res = SubantaProcessor.derive_pada(stem, v_sel, n_sel, logger)
        
        # UI TABS for scannability
        tab1, tab2 = st.tabs(["üìä Summary View", "üìú Deep Vyutpatti"])
        
        with tab1:
            st.success(f"Final Form: **{res}**")
            st.table(pd.DataFrame({
                "Property": ["Stem", "Vibhakti", "Vacana", "Result"],
                "Value": [stem, VIBHAKTI_MAP[v_sel], VACANA_MAP[n_sel], res]
            }))
        
        with tab2:
            for i, step in enumerate(logger.get_history()):
                st.markdown(generate_card_html(i, step), unsafe_allow_html=True)

    # Full Paradigm Table
    with st.expander("üìö View Full Declension Table"):
        rows = []
        for v in range(1, 9):
            row = {"Vibhakti": VIBHAKTI_MAP[v]}
            for n in range(1, 4):
                row[VACANA_MAP[n]] = SubantaProcessor.derive_pada(stem, v, n, None)
            rows.append(row)
        st.dataframe(pd.DataFrame(rows), use_container_width=True, hide_index=True)

if __name__ == "__main__":
    main()


================================================================================
FILE: pages/1_üß™_Dhatu_Lab.py
================================================================================

import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
"""
PAGE: DhƒÅtu Laboratory
"""
import streamlit as st
import pandas as pd
import json
import os
from logic.dhatu_processor import DhatuDiagnostic

st.set_page_config(page_title="DhƒÅtu Lab", page_icon="üß™", layout="wide")

# --- CSS Styling ---
st.markdown("""
<style>
    .sanskrit { font-family: 'Sanskrit 2003', 'Adobe Devanagari', sans-serif; font-size: 1.1em; }
    .tag-badge { 
        background-color: #e3f2fd; color: #1565c0; padding: 2px 8px; 
        border-radius: 12px; font-size: 0.8em; border: 1px solid #90caf9; margin-right: 4px;
    }
    .match-success { color: #2e7d32; font-weight: bold; }
    .match-fail { color: #c62828; font-weight: bold; }
    .metric-card {
        background-color: #f8f9fa; border-left: 4px solid #673ab7;
        padding: 15px; border-radius: 8px; margin-bottom: 10px;
    }
</style>
""", unsafe_allow_html=True)

st.title("üß™ DhƒÅtu PrakriyƒÅ Laboratory")

mode = st.radio("Mode", ["Single Analysis", "Master Database Validator"], horizontal=True)

if mode == "Single Analysis":
    col1, col2 = st.columns([1, 2])
    with col1:
        raw_root = st.text_input("Enter Upadesha (e.g. ‡§°‡•Å‡§ï‡•É‡§û‡•ç, ‡§∑‡§£‡•ç‡§Æ‡•Å‡§ñ‡§æ‡§Ø)", value="‡§°‡•Å‡§ï‡•É‡§û‡•ç")
        is_sub = st.checkbox("Is SubdhƒÅtu (NƒÅmadhƒÅtu)?")

        if st.button("Run Diagnostics", type="primary"):
            diag = DhatuDiagnostic(raw_root, is_subdhatu=is_sub)

            st.markdown(f"""
            <div class="metric-card">
                <h4>Diagnosis</h4>
                <p>Input: <b>{diag.raw}</b></p>
                <p>Root: <b class="sanskrit" style="color:#d32f2f; font-size:1.5em;">{diag.get_final_root()}</b></p>
                <p>Voice: {diag.pada}</p>
            </div>
            """, unsafe_allow_html=True)

            st.subheader("üß¨ It-Tags")
            st.write(diag.it_tags)

            st.session_state['dhatu_trace'] = diag.history

    with col2:
        if 'dhatu_trace' in st.session_state:
            st.subheader("üìú Step-by-Step Trace")
            trace_df = pd.DataFrame([s.split(": ", 1) for s in st.session_state['dhatu_trace']], columns=["Rule", "Operation"])
            st.table(trace_df)

elif mode == "Master Database Validator":
    # Load Data
    @st.cache_data
    def load_data():
        paths = ["data/dhatu_master_structured.json", "dhatu_master_structured.json"]
        for p in paths:
            if os.path.exists(p):
                with open(p, "r", encoding="utf-8") as f: return json.load(f)
        return []

    raw_db = load_data()

    if not raw_db:
        st.error("Database not found in 'data/' folder.")
    else:
        st.caption(f"Loaded {len(raw_db)} roots.")

        # Filters
        with st.expander("üîç Filters"):
            col_f1, col_f2 = st.columns(2)
            sel_gana = col_f1.multiselect("Gana", sorted(list(set([x.get('gana') for x in raw_db if x.get('gana')]))))
            sel_pada = col_f2.multiselect("Pada", sorted(list(set([x.get('pada') for x in raw_db if x.get('pada')]))))

        # Process
        processed_rows = []
        # Optimization: Limit to first 100 if no filter, or all if filtered
        limit = 100 if not (sel_gana or sel_pada) else 5000

        count = 0
        for entry in raw_db:
            if sel_gana and entry.get('gana') not in sel_gana: continue
            if sel_pada and entry.get('pada') not in sel_pada: continue

            upadesha = entry.get('upadesha', '')
            if not upadesha: upadesha = entry.get('mula_dhatu', '')
            target = entry.get('mula_dhatu', '')

            diag = DhatuDiagnostic(upadesha)
            derived = diag.get_final_root()

            match = derived == target
            status = "‚úÖ" if match else "‚ùå"

            # Voice Match Logic
            trad_voice = entry.get('pada', '')
            eng_voice = diag.pada
            voice_ok = "‚ö†Ô∏è"
            if "Atmanepada" in eng_voice and "‡§Ü‡§§‡•ç‡§Æ‡§®‡•á" in trad_voice: voice_ok = "‚úÖ"
            elif "Parasmaipada" in eng_voice and "‡§™‡§∞‡§∏‡•ç‡§Æ‡•à" in trad_voice: voice_ok = "‚úÖ"
            elif "Ubhayapada" in eng_voice and "‡§â‡§≠‡§Ø" in trad_voice: voice_ok = "‚úÖ"

            processed_rows.append({
                "ID": entry.get('identifier', ''),
                "Upadesha": f"<span class='sanskrit'>{upadesha}</span>",
                "Target": f"<span class='sanskrit'>{target}</span>",
                "Output": f"<span class='sanskrit {'match-success' if match else 'match-fail'}'>{derived}</span>",
                "Status": status,
                "Voice (Engine)": f"{voice_ok} {eng_voice}",
                "Voice (JSON)": f"<span class='sanskrit'>{trad_voice}</span>",
                "Meaning": entry.get('artha_sanskrit', '')
            })
            count += 1
            if count >= limit: break

        df = pd.DataFrame(processed_rows)

        tab1, tab2 = st.tabs(["üìä Data Table", "‚ùå Mismatches Only"])
        with tab1:
            st.write(df.to_html(escape=False, index=False), unsafe_allow_html=True)
        with tab2:
            mismatches = df[df["Status"] == "‚ùå"]
            if not mismatches.empty:
                st.write(mismatches.to_html(escape=False, index=False), unsafe_allow_html=True)
            else:
                st.success("No mismatches in this selection!")



================================================================================
FILE: pages/2_‚ö°_Tinanta_Lab.py
================================================================================

import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
"""
PAGE: Ti·πÖanta Laboratory
"""
import streamlit as st
from logic.tinanta_processor import TinantaDiagnostic

st.set_page_config(page_title="Ti·πÖanta Lab", page_icon="‚ö°", layout="wide")

st.title("‚ö° Ti·πÖanta PrakriyƒÅ (Verb Conjugation)")
st.caption("Phase 1: La·π≠ LakƒÅra Generator")

col1, col2 = st.columns([1, 2])

with col1:
    with st.form("tin_form"):
        root_input = st.text_input("Root (Upadesha)", value="‡§≠‡•Ç")
        lakara = st.selectbox("LakƒÅra", ["Lat (Present)", "Lit (Perfect)", "Lrt (Future)"])
        purusha = st.selectbox("Purusha", ["Prathama (3rd)", "Madhyama (2nd)", "Uttama (1st)"])
        vacana = st.selectbox("Vacana", ["Eka (Singular)", "Dvi (Dual)", "Bahu (Plural)"])

        submitted = st.form_submit_button("Generate Form")

if submitted:
    # Map inputs to indices
    p_map = {"Prathama (3rd)": 1, "Madhyama (2nd)": 2, "Uttama (1st)": 3}
    v_map = {"Eka (Singular)": 1, "Dvi (Dual)": 2, "Bahu (Plural)": 3}

    tin = TinantaDiagnostic(root_input, lakara.split()[0], p_map[purusha], v_map[vacana])

    with col2:
        st.markdown(f"""
        <div style="background:#e8f5e9;padding:20px;border-radius:10px;border-left:5px solid #2e7d32;">
            <h3>üèÅ Final Form: <span style="color:#d32f2f;font-size:2em;">{tin.final_form}</span></h3>
            <p><strong>Root:</strong> {tin.root} | <strong>Voice:</strong> {tin.pada_type}</p>
        </div>
        """, unsafe_allow_html=True)

        st.divider()
        st.subheader("üìú PrakriyƒÅ Trace")
        for step in tin.history:
            st.code(step, language="text")



================================================================================
FILE: pages/1_üîç_Metadata_Tagger.py
================================================================================

import streamlit as st
from logic.subanta_processor import SubantaProcessor

# Page Configuration
st.set_page_config(page_title="PƒÅ·πáinian Tagger", page_icon="üîç")

st.title("üîç PƒÅ·πáinian Metadata Tagger")
st.markdown("### Sentence Analysis Engine")
st.write("Decomposing VƒÅkyas into Padas and labeling PƒÅ·πáinian properties.")

# Initialize the generative engine
sp = SubantaProcessor()

# 1. Define Stems and Avyayas (Indeclinables)
stems = ["‡§∞‡§æ‡§Æ", "‡§π‡§∞‡§ø", "‡§ó‡•Å‡§∞‡•Å", "‡§∞‡§Æ‡§æ", "‡§∏‡§∞‡•ç‡§µ", "‡§§‡§¶‡•ç", "‡§Ø‡§¶‡•ç", "‡§á‡§¶‡§Æ‡•ç", "‡§≠‡§ó‡§µ‡§§‡•ç", "‡§ú‡§ó‡§§‡•ç"]
avyayas = ["‡§∏‡•É‡§∑‡•ç‡§ü‡•ç‡§µ‡§æ", "‡§á‡§§‡§ø", "‡§ö", "‡§è‡§µ"]

sentence = st.text_input("Enter Sanskrit Sentence", "‡§∏ ‡§≠‡§ó‡§µ‡§æ‡§®‡•ç ‡§∏‡•É‡§∑‡•ç‡§ü‡•ç‡§µ‡§æ ‡§ú‡§ó‡§§‡•ç")

if st.button("Analyze Sentence"):
    if sentence:
        words = sentence.split()
        analysis_results = []

        for word in words:
            # Basic cleaning for Anusvara and punctuation
            clean_word = word.replace("‡§Ç", "‡§Æ‡•ç").strip(" ,‡•§")
            match_found = False

            # STEP 1: Check Avyayas first
            if clean_word in avyayas:
                analysis_results.append({
                    "Word": word, "Stem": clean_word, "Type": "Avyaya",
                    "Vibhakti": "N/A", "Vacana": "N/A", "Status": "‚úÖ Matched"
                })
                match_found = True

            # STEP 2: Special Case '‡§∏' (Tad Pronoun 1/1)
            if not match_found and clean_word == "‡§∏":
                analysis_results.append({
                    "Word": word, "Stem": "‡§§‡§¶‡•ç", "Type": "Pronoun",
                    "Vibhakti": 1, "Vacana": 1, "Status": "‚úÖ Matched"
                })
                match_found = True
            
            # STEP 3: Standard Subanta Paradigm Lookup
            if not match_found:
                for stem in stems:
                    for v in range(1, 9):
                        for w in range(1, 4):
                            # Compare against the generator
                            if sp.derive_pada(stem, v, w) == clean_word:
                                analysis_results.append({
                                    "Word": word, "Stem": stem, "Type": "Subanta",
                                    "Vibhakti": v, "Vacana": w, "Status": "‚úÖ Matched"
                                })
                                match_found = True
                                break
                        if match_found: break
                    if match_found: break

            # STEP 4: Fallback for Unrecognized Words
            if not match_found:
                analysis_results.append({
                    "Word": word, "Stem": "-", "Type": "Unknown",
                    "Vibhakti": "-", "Vacana": "-", "Status": "‚ùì Review"
                })

        st.table(analysis_results)
    else:
        st.warning("Please enter a Sanskrit sentence to begin.")


================================================================================
FILE: core/core_foundation.py
================================================================================

"""
FILE: core/core_foundation.py - PAS-v8.9 (Merged Modifiers Fix)
"""
import re

STHANA_MAP = {
    "‡§ï‡§£‡•ç‡§†": "‡§Ö‡§Ü‡§ï‡§ñ‡§ó‡§ò‡§ô‡§π‡§É", "‡§§‡§æ‡§≤‡•Å": "‡§á‡§à‡§ö‡§õ‡§ú‡§ù‡§û‡§Ø‡§∂", 
    "‡§Æ‡•Ç‡§∞‡•ç‡§ß‡§æ": "‡§ã‡•†‡§ü‡§†‡§°‡§¢‡§£‡§∞‡§∑", "‡§¶‡§®‡•ç‡§§": "‡§å‡§§‡§•‡§¶‡§ß‡§®‡§≤‡§∏",
    "‡§ì‡§∑‡•ç‡§†": "‡§â‡§ä‡§™‡§´‡§¨‡§≠‡§Æ", "‡§®‡§æ‡§∏‡§ø‡§ï‡§æ": "‡§ô‡§û‡§£‡§®‡§Æ‡§Ç‡§Å",
    "‡§ï‡§£‡•ç‡§†‡§§‡§æ‡§≤‡•Å": "‡§è‡§ê", "‡§ï‡§£‡•ç‡§†‡•ã‡§∑‡•ç‡§†": "‡§ì‡§î", "‡§¶‡§®‡•ç‡§§‡•ã‡§∑‡•ç‡§†": "‡§µ"
}

VOWELS_MAP = {'‡§æ': '‡§Ü', '‡§ø': '‡§á', '‡•Ä': '‡§à', '‡•Å': '‡§â', '‡•Ç': '‡§ä', '‡•É': '‡§ã', '‡•Ñ': '‡•†', '‡•¢': '‡§å', '‡•£': '‡•°', '‡•á': '‡§è', '‡•à': '‡§ê', '‡•ã': '‡§ì', '‡•å': '‡§î'}
INDEPENDENT_VOWELS = '‡§Ö‡§Ü‡§á‡§à‡§â‡§ä‡§ã‡•†‡§å‡•°‡§è‡§ê‡§ì‡§î'

class Varna:
    def __init__(self, raw_unit):
        self.char = raw_unit
        self.clean = raw_unit.replace('‡•ç', '')
        self.sanjnas = set()
        self.trace = []

        # Identity
        self.is_vowel = any(v in raw_unit for v in INDEPENDENT_VOWELS) or '‡•©' in raw_unit
        self.is_anunasika = '‡§Å' in raw_unit or '‡§Ç' in raw_unit
        self.is_consonant = not self.is_vowel and '‡•ç' in raw_unit

        # Anatomy
        base = self.char[0]
        self.sthana = [k for k, v in STHANA_MAP.items() if base in v]
        if self.is_anunasika and "‡§®‡§æ‡§∏‡§ø‡§ï‡§æ" not in self.sthana: self.sthana.append("‡§®‡§æ‡§∏‡§ø‡§ï‡§æ")

    def add_samjna(self, label, rule=""):
        self.sanjnas.add(label)
        if rule: self.trace.append(f"{label} [{rule}]")
    def __repr__(self): return self.char

def sanskrit_varna_vichhed(text, return_objects=True):
    """
    R2: AUTHORITATIVE TOKENIZATION (Merged Modifiers)
    Ensures 'i' + '~' becomes 'i~', not ['i', '~'].
    """
    if not text: return []
    if text == "‡•ê": res = ["‡§Ö", "‡§â", "‡§Æ‡•ç"]
    else:
        text = text.replace('‡§ï‡•ç‡§∑', '‡§ï‡•ç‚Äå‡§∑').replace('‡§§‡•ç‡§∞', '‡§§‡•ç‚Äå‡§∞').replace('‡§ú‡•ç‡§û', '‡§ú‡•ç‚Äå‡§û').replace('‡§∂‡•ç‡§∞', '‡§∂‡•ç‚Äå‡§∞').replace('‡§Ω', '‡§Ö')
        text = re.sub(r'‡§Ç(?=[‡§ï‡§ñ‡§ó‡§ò])', '‡§ô‡•ç', text); text = re.sub(r'‡§Ç(?=[‡§ö‡§õ‡§ú‡§ù])', '‡§û‡•ç', text)
        text = re.sub(r'‡§Ç(?=[‡§ü‡§†‡§°‡§¢])', '‡§£‡•ç', text); text = re.sub(r'‡§Ç(?=[‡§§‡§•‡§¶‡§ß])', '‡§®‡•ç', text)
        text = re.sub(r'‡§Ç(?=[‡§™‡§´‡§¨‡§≠])', '‡§Æ‡•ç', text)

        res = []
        i = 0
        while i < len(text):
            char = text[i]
            if char in INDEPENDENT_VOWELS:
                unit = char
                if i+1 < len(text) and text[i+1] == '‡•©': unit += '‡•©'; i+=1
                # MERGE MODIFIERS INTO VOWEL
                while i+1 < len(text) and text[i+1] in '‡§Ç‡§É‡§Å':
                    unit += text[i+1]
                    i+=1
                res.append(unit)

            elif '\u0915' <= char <= '\u0939' or char == '‡§≥':
                current_cons = char + '‡•ç'
                res.append(current_cons)
                found_vowel = False

                if i+1 < len(text):
                    nxt = text[i+1]
                    if nxt == '‡•ç': 
                        i+=1; found_vowel = True
                    elif nxt in VOWELS_MAP:
                        # Vowel Sign found
                        v_unit = VOWELS_MAP[nxt]
                        i+=1; found_vowel = True

                        # MERGE MODIFIERS INTO MATRA-DERIVED VOWEL
                        while i+1 < len(text) and text[i+1] in '‡§Ç‡§É‡§Å':
                            v_unit += text[i+1]
                            i+=1
                        res.append(v_unit)

                    elif nxt in '‡§Ç‡§É‡§Å':
                        # Implicit 'A' with modifier
                        v_unit = '‡§Ö' + nxt
                        i+=1
                        # Check for more modifiers
                        while i+1 < len(text) and text[i+1] in '‡§Ç‡§É‡§Å':
                            v_unit += text[i+1]; i+=1
                        res.append(v_unit)
                        found_vowel = True

                    elif nxt == ' ': 
                        res.append('‡§Ö'); found_vowel = True

                if not found_vowel: res.append('‡§Ö')
            elif char in '·≥≤·≥≥': res.append(char)
            i+=1

    return [Varna(s) for s in res] if return_objects else res

ad = sanskrit_varna_vichhed

def sanskrit_varna_samyoga(varna_list):
    if not varna_list: return ""
    text_list = [v.char for v in varna_list]
    res = ""
    for char in text_list:
        if not res: res = char; continue
        if res.endswith('‡•ç') and any(v in char for v in INDEPENDENT_VOWELS):
            matra = VOWELS_MAP.get(char, "") # Try exact char first
            if not matra:
                # If char has modifiers (e.g. '‡§á‡§Å'), strip them to find matra
                clean_v = char[0]
                matra = {v: k for k, v in VOWELS_MAP.items()}.get(clean_v, "")

            # Re-attach modifiers
            modifiers = char[1:] if len(char) > 1 else ""

            if char.startswith('‡§Ö'):
                res = res[:-1] + modifiers # Remove virama, add modifiers
            else:
                res = res[:-1] + matra + modifiers
        else:
            res += char
    return res

class PratyaharaEngine:
    def __init__(self): self._cache = {}
    def get_varnas(self, name): return [] 
pe = PratyaharaEngine()

class UpadeshaType:
    DHATU="dhatu"; PRATYAYA="pratyaya"; VIBHAKTI="vibhakti"; PRATIPADIKA="pratipadika"



================================================================================
FILE: core/knowledge_base.py
================================================================================

"""
FILE: core/knowledge_base.py - Restored with get_sup logic.
"""
class KnowledgeBase:
    SUP_MAP = {
        1: [("‡§∏‡•Å‡§Å", set()), ("‡§î", set()), ("‡§ú‡§∏‡•ç", set())],
        2: [("‡§Ö‡§Æ‡•ç", set()), ("‡§î‡§ü‡•ç", set()), ("‡§∂‡§∏‡•ç", set())],
        3: [("‡§ü‡§æ", set()), ("‡§≠‡•ç‡§Ø‡§æ‡§Æ‡•ç", set()), ("‡§≠‡§ø‡§∏‡•ç", set())],
        4: [("‡§ô‡•á", set()), ("‡§≠‡•ç‡§Ø‡§æ‡§Æ‡•ç", set()), ("‡§≠‡•ç‡§Ø‡§∏‡•ç", set())],
        5: [("‡§ô‡§∏‡§ø‡§Å", set()), ("‡§≠‡•ç‡§Ø‡§æ‡§Æ‡•ç", set()), ("‡§≠‡•ç‡§Ø‡§∏‡•ç", set())],
        6: [("‡§ô‡§∏‡•ç", set()), ("‡§ì‡§∏‡•ç", set()), ("‡§Ü‡§Æ‡•ç", set())],
        7: [("‡§ô‡§ø", set()), ("‡§ì‡§∏‡•ç", set()), ("‡§∏‡•Å‡§™‡•ç", set())],
        8: [("‡§∏‡•Å‡§Å", set()), ("‡§î", set()), ("‡§ú‡§∏‡•ç", set())]
    }
    @staticmethod
    def get_sup(vibhakti, vacana):
        if vibhakti in KnowledgeBase.SUP_MAP:
            row = KnowledgeBase.SUP_MAP[vibhakti]
            if 1 <= vacana <= 3: return row[vacana-1]
        return None
    @staticmethod
    def is_sarvanama(word):
        sarva_list = ["‡§∏‡§∞‡•ç‡§µ", "‡§µ‡§ø‡§∂‡•ç‡§µ", "‡§â‡§≠", "‡§â‡§≠‡§Ø", "‡§°‡§§‡§∞", "‡§°‡§§‡§Æ", "‡§Ö‡§®‡•ç‡§Ø", "‡§Ö‡§®‡•ç‡§Ø‡§§‡§∞", "‡§á‡§§‡§∞", "‡§§‡•ç‡§µ‡§§‡•ç", "‡§§‡•ç‡§µ", "‡§®‡•á‡§Æ", "‡§∏‡§Æ", "‡§∏‡§ø‡§Æ", "‡§™‡•Ç‡§∞‡•ç‡§µ", "‡§™‡§∞", "‡§Ö‡§µ‡§∞", "‡§¶‡§ï‡•ç‡§∑‡§ø‡§£", "‡§â‡§§‡•ç‡§§‡§∞", "‡§Ö‡§™‡§∞", "‡§Ö‡§ß‡§∞", "‡§∏‡•ç‡§µ", "‡§Ö‡§®‡•ç‡§§‡§∞", "‡§§‡•ç‡§Ø‡§¶‡•ç", "‡§§‡§¶‡•ç", "‡§Ø‡§¶‡•ç", "‡§è‡§§‡§¶‡•ç", "‡§á‡§¶‡§Æ‡•ç", "‡§Ö‡§¶‡§∏‡•ç", "‡§è‡§ï", "‡§¶‡•ç‡§µ‡§ø", "‡§Ø‡•Å‡§∑‡•ç‡§Æ‡§¶‡•ç", "‡§Ö‡§∏‡•ç‡§Æ‡§¶‡•ç", "‡§≠‡§µ‡§§‡•ç", "‡§ï‡§ø‡§Æ‡•ç"]
        return word in sarva_list



================================================================================
FILE: core/sutra_repo.py
================================================================================

"""
FILE: core/sutra_repo.py
PURPOSE: Load Panini Sutra definitions from JSON.
"""
import json
import os

class SutraRepository:
    _data = {}
    _loaded = False

    @classmethod
    def load_data(cls):
        path = "data/panini_sutras.json"
        if not os.path.exists(path): return
        try:
            with open(path, "r", encoding="utf-8") as f:
                raw_list = json.load(f)
                for entry in raw_list:
                    num = entry.get("sutra_num", "").strip()
                    if num:
                        cls._data[num] = entry
            cls._loaded = True
        except Exception as e:
            print(f"‚ùå Error loading Sutra DB: {e}")

    @classmethod
    def get(cls, rule_num):
        if not cls._loaded: cls.load_data()
        # Clean rule_num (sometimes passed as "6.1.101 (Name)")
        clean_num = rule_num.split(' ')[0].strip()
        return cls._data.get(clean_num)



================================================================================
FILE: core/prakriya_stack.py
================================================================================

"""
FILE: core/prakriya_stack.py
PURPOSE: The "State Persistence" Object (Render Fix)
"""
from core.core_foundation import Varna, ad, sanskrit_varna_samyoga

class Term:
    """Represents a component: e.g., 'Rama' (Anga) or 'Su' (Pratyaya)"""
    def __init__(self, text, tags=None):
        self.varnas = ad(text) # List of Varna objects
        self.tags = tags if tags else set() 

    def get_text(self):
        return sanskrit_varna_samyoga(self.varnas)

    def add_tag(self, tag):
        self.tags.add(tag)

class PrakriyaState:
    """The Immutable Context passed through the Engine."""
    def __init__(self):
        self.terms = [] 
        self.history = [] 
        self.meta_flags = {} 

    def add_term(self, text, tags=None):
        self.terms.append(Term(text, tags))

    def step(self, rule_id, rule_name, operation_desc, result_snapshot):
        entry = {
            "rule": rule_id,
            "name": rule_name,
            "desc": operation_desc,
            "result": result_snapshot
        }
        self.history.append(entry)

    def render(self):
        """Returns the joined string representation."""
        # Flatten all varnas from all terms into one list
        all_varnas = []
        for t in self.terms:
            all_varnas.extend(t.varnas)

        # Apply Samyoga (Phonetic Join) on the whole sequence
        return sanskrit_varna_samyoga(all_varnas)

    def get_index_of_tag(self, tag_name):
        for i, term in enumerate(self.terms):
            if tag_name in term.tags: return i
        return -1



================================================================================
FILE: core/sanjna_controller.py
================================================================================


from core.core_foundation import Varna, UpadeshaType

class SanjnaController:
    @staticmethod
    def run_it_prakaran(varnas, context=UpadeshaType.VIBHAKTI):
        if not varnas: return varnas, []
        res = list(varnas)
        applied = []
        # Restore IT-Lopa logic for 1.3.3 and 1.3.2
        if not res[-1].is_vowel and res[-1].char not in ['‡§∏‡•ç', '‡§Æ‡•ç']:
            res.pop(); applied.append("1.3.3")
        return res, applied

    @staticmethod
    def identify_structural_samjnas(varnas):
        """Implements 1.1.64 (Ti) and 1.1.65 (Upadha)"""
        if len(varnas) >= 2: varnas[-2].add_samjna("UPADHA", "1.1.65")
        v_idx = [i for i,v in enumerate(varnas) if v.is_vowel]
        if v_idx:
            for i in range(v_idx[-1], len(varnas)): varnas[i].add_samjna("TI", "1.1.64")



================================================================================
FILE: core/dhatu_repo.py
================================================================================

"""
FILE: core/dhatu_repo.py
PURPOSE: Singleton Manager to load and query Dhatu Data (R1: Upade≈õa).
"""
import json
import os

class DhatuRepository:
    _dhatu_map = {}
    _loaded = False

    @classmethod
    def load_data(cls):
        if cls._loaded: return
        
        path = "data/dhatu_master_structured.json"
        if not os.path.exists(path):
            print(f"‚ö†Ô∏è Warning: Dhatu DB not found at {path}")
            return

        try:
            with open(path, "r", encoding="utf-8") as f:
                data = json.load(f)
                for entry in data:
                    # Map 'mula_dhatu' to its details
                    mula = entry.get('mula_dhatu', '').strip()
                    if mula:
                        cls._dhatu_map[mula] = entry
            cls._loaded = True
            # print(f"‚úÖ Loaded {len(cls._dhatu_map)} Dhatus into Memory.")
        except Exception as e:
            print(f"‚ùå Error loading Dhatu DB: {e}")

    @classmethod
    def get_dhatu_info(cls, word):
        """Returns metadata dict if word is a Dhatu, else None."""
        if not cls._loaded:
            cls.load_data()
        return cls._dhatu_map.get(word)



================================================================================
FILE: core/maheshwara_sutras.py
================================================================================

"""
FILE: core/maheshwara_sutras.py
"""
class MaheshwaraSutras:
    SUTRAS_DATA = [
        ("‡§Ö‡§á‡§â", "‡§£‡•ç"), ("‡§ã‡§å", "‡§ï‡•ç"), ("‡§è‡§ì", "‡§ô‡•ç"), ("‡§ê‡§î", "‡§ö‡•ç"),
        ("‡§π‡§Ø‡§µ‡§∞", "‡§ü‡•ç"), ("‡§≤", "‡§£‡•ç"), ("‡§û‡§Æ‡§ô‡§£‡§®", "‡§Æ‡•ç"), ("‡§ù‡§≠", "‡§û‡•ç"),
        ("‡§ò‡§¢‡§ß", "‡§∑‡•ç"), ("‡§ú‡§¨‡§ó‡§°‡§¶", "‡§∂‡•ç"), ("‡§ñ‡§´‡§õ‡§†‡§•‡§ö‡§ü‡§§", "‡§µ‡•ç"), ("‡§ï‡§™", "‡§Ø‡•ç"),
        ("‡§∂‡§∑‡§∏", "‡§∞‡•ç"), ("‡§π", "‡§≤‡•ç")
    ]
    
    SAVARNA_MAP = {'‡§Ö': ['‡§Ö', '‡§Ü'], '‡§á': ['‡§á', '‡§à'], '‡§â': ['‡§â', '‡§ä'], '‡§ã': ['‡§ã', '‡•†'], '‡§å': ['‡§å']}

    @staticmethod
    def get_pratyahara(p_name, force_n2=False):
        """
        Implementation of:
        1. [1.3.3 ‡§π‡§≤‡§®‡•ç‡§§‡•ç‡§Ø‡§Æ‡•ç]: Identifying the It-marker.
        2. [1.1.71 ‡§Ü‡§¶‡§ø‡§∞‡§®‡•ç‡§§‡•ç‡§Ø‡•á‡§® ‡§∏‡§π‡•á‡§§‡§æ]: Adi + Antya-It defines the group.
        """
        if not p_name or len(p_name) < 2: return set()
        
        p_name = p_name.strip()
        adi = p_name[0]
        it_marker = p_name[1:] 
        
        chars = set()
        collecting = False
        n_count = 0
        
        for content, marker in MaheshwaraSutras.SUTRAS_DATA:
            # Step 1: Scan for Adi
            for char in content:
                if char == adi: collecting = True
                if collecting:
                    chars.add(char)
                    # [1.1.69 ‡§Ö‡§£‡•Å‡§¶‡§ø‡§§‡•ç ‡§∏‡§µ‡§∞‡•ç‡§£‡§∏‡•ç‡§Ø]: Include savarnas
                    if char in MaheshwaraSutras.SAVARNA_MAP:
                        chars.update(MaheshwaraSutras.SAVARNA_MAP[char])
            
            # Step 2: [1.3.3 & 1.1.71]: Stop if the 'It' marker matches
            if collecting and marker == it_marker:
                if it_marker == '‡§£‡•ç':
                    n_count += 1
                    if force_n2 and n_count == 1: continue
                break
        return chars



================================================================================
FILE: core/__init__.py
================================================================================

# panini_engine/core/__init__.py
from .core_foundation import ad, Varna, UpadeshaType, pe
from .sanjna_controller import SanjnaController


================================================================================
FILE: core/adhikara_controller.py
================================================================================

"""
FILE: core/adhikara_controller.py
PURPOSE: Manages R12 (Headers) and R31 (Niv·πõtti - Deactivation).
"""

class AdhikaraController:
    # Mathematical Boundaries of Adhikaras in Ashtadhyayi
    SCOPES = {
        "ANGASYA": (6, 4, 1, 7, 4, 97),   # 6.4.1 to 7.4.97
        "BHASYA":  (6, 4, 129, 6, 4, 175) # 6.4.129 to 6.4.175
    }

    @staticmethod
    def is_rule_in_scope(rule_str, adhikara_name):
        """
        Checks if a target rule falls within the Adhikara's mathematical domain.
        rule_str format: "x.y.z" (e.g., "7.1.12")
        """
        try:
            c, p, s = map(int, rule_str.split('.'))
        except:
            return False # Non-standard rule format

        start_c, start_p, start_s, end_c, end_p, end_s = AdhikaraController.SCOPES[adhikara_name]

        # Convert to absolute integer for comparison (simple heuristic: c*10000 + p*1000 + s)
        target_val = c * 10000 + p * 1000 + s
        start_val = start_c * 10000 + start_p * 1000 + start_s
        end_val = end_c * 10000 + end_p * 1000 + end_s

        return start_val <= target_val <= end_val

    @staticmethod
    def check_nivritti(context, adhikara_name):
        """
        R31 (Niv·πõtti): Checks if the Context DEACTIVATES the Adhikara.
        """
        # BHASYA Context: Needs suffix to be Y-adi or Vowel-adi (1.4.18) AND weak (non-sarvanamasthana)
        if adhikara_name == "BHASYA":
            is_yachi = context.get("is_yachi", False)
            is_bham = context.get("is_bham", False)
            if not is_bham:
                return True # NIVRITTI: Deactivate Bhasya rules!
        
        return False # Active



================================================================================
FILE: core/shabdroop_repo.py
================================================================================

"""
FILE: core/shabdroop_repo.py
PURPOSE: Load Gold Standard Data for Validation.
"""
import json
import os

class ShabdroopRepository:
    _data = []
    _loaded = False

    @classmethod
    def load_data(cls):
        path = "data/shabdroop.json"
        if not os.path.exists(path): return
        try:
            with open(path, "r", encoding="utf-8") as f:
                cls._data = json.load(f)
            cls._loaded = True
        except Exception as e:
            print(f"‚ùå Error loading Shabdroop DB: {e}")

    @classmethod
    def get_all(cls):
        if not cls._loaded: cls.load_data()
        return cls._data



================================================================================
FILE: logic/tinanta_processor.py
================================================================================

"""
FILE: logic/tinanta_processor.py - PAS-v18.0 (The Conjugation Engine)
"""
from core.core_foundation import Varna, ad, sanskrit_varna_samyoga
from logic.dhatu_processor import DhatuDiagnostic

# --- The 18 Ti·πÖ Suffixes (3.4.78) ---
TIN_PRATYAYA = {
    "Parasmaipada": [
        ["‡§§‡§ø‡§™‡•ç", "‡§§‡§∏‡•ç", "‡§ù‡§ø"],   # Prathama (3rd Person)
        ["‡§∏‡§ø‡§™‡•ç", "‡§•‡§∏‡•ç", "‡§•"],    # Madhyama (2nd Person)
        ["‡§Æ‡§ø‡§™‡•ç", "‡§µ‡§∏‡•ç", "‡§Æ‡§∏‡•ç"]   # Uttama (1st Person)
    ],
    "Atmanepada": [
        ["‡§§", "‡§Ü‡§§‡§æ‡§Æ‡•ç", "‡§ù"],     # Prathama
        ["‡§•‡§æ‡§∏‡•ç", "‡§Ü‡§•‡§æ‡§Æ‡•ç", "‡§ß‡•ç‡§µ‡§Æ‡•ç"], # Madhyama
        ["‡§á‡§°‡•ç", "‡§µ‡§π‡§ø", "‡§Æ‡§π‡§ø‡§ô‡•ç"]   # Uttama
    ]
}

class TinantaDiagnostic:
    def __init__(self, upadesha, lakara="Lat", purusha=1, vacana=1):
        """
        upadesha: Raw root (e.g. '‡§°‡•Å‡§ï‡•É‡§û‡•ç')
        lakara: Tense/Mood (e.g. 'Lat')
        purusha: 1=Prathama, 2=Madhyama, 3=Uttama (Paninian Indexing)
        vacana: 1=Eka, 2=Dvi, 3=Bahu
        """
        self.raw_root = upadesha
        self.lakara = lakara
        self.purusha = purusha - 1 # 0-indexed
        self.vacana = vacana - 1   # 0-indexed

        self.history = []
        self.derivation = []

        # Step 1: Process Root (DhƒÅtu-PƒÅ·π≠ha Logic)
        self.dhatu_obj = DhatuDiagnostic(upadesha)
        self.root = self.dhatu_obj.get_final_root()
        self.pada_type = self.dhatu_obj.pada # Parasmai/Atmane

        self.log(f"Root Prepared: {self.root} ({self.pada_type})")

        # Step 2: Select Suffix (Ti·πÖ Selection)
        self.suffix = self._select_tin()
        self.log(f"Suffix Selected: {self.suffix} ({self.lakara})")

        # Step 3: Run Prakriya
        self.final_form = self._run_prakriya()

    def log(self, message):
        self.history.append(message)

    def _select_tin(self):
        # 1.3.12/78: Determine Voice
        voice = "Atmanepada" if "Atmanepada" in self.pada_type else "Parasmaipada"
        selection = TIN_PRATYAYA[voice][self.purusha][self.vacana]

        # Basic IT removal for suffixes (P in Tip/Mip/Sip is It)
        if selection.endswith("‡§™‡•ç") and len(selection) > 1:
            selection = selection[:-2] + "‡§ø" # Tip -> Ti

        return selection

    def _run_prakriya(self):
        """
        The Core Assembly Line:
        Root + Vikarana + Suffix -> Anga-Karya -> Sandhi -> Pada
        """
        # A. Current State
        curr_root = self.root
        curr_suffix = self.suffix

        # B. Vikarana (Infix) Selection - Hardcoded ≈öap (a) for now
        vikarana = "‡§Ö" 
        self.log("3.1.68: Added Vikara·πáa '≈öap' (a)")

        # C. Guna (7.3.84 SƒÅrvadhƒÅtukƒÅrdhadhƒÅtukayo·∏•)
        root_varnas = ad(curr_root)
        if root_varnas:
            last_char = root_varnas[-1].char
            if last_char in ['‡§á', '‡§à']:
                curr_root = curr_root[:-1] + "‡§è" # i -> e
                self.log("7.3.84: Guna (i -> e)")
            elif last_char in ['‡§â', '‡§ä']:
                curr_root = curr_root[:-1] + "‡§ì" # u -> o
                self.log("7.3.84: Guna (u -> o)")
            elif last_char in ['‡§ã', '‡•†']:
                curr_root = curr_root[:-1] + "‡§Ö‡§∞‡•ç" # r -> ar
                self.log("7.3.84: Guna (·πõ -> ar)")

        # D. Ayadi Sandhi (6.1.78)
        if curr_root.endswith("‡§è"):
            curr_root = curr_root[:-1] + "‡§Ö‡§Ø‡•ç"
            self.log("6.1.78: Ayadi (e -> ay)")
        elif curr_root.endswith("‡§ì"):
            curr_root = curr_root[:-1] + "‡§Ö‡§µ‡•ç"
            self.log("6.1.78: Ayadi (o -> av)")

        # E. Assembly
        return f"{curr_root}{vikarana}{curr_suffix}" # Example: Bhav + a + ti



================================================================================
FILE: logic/subanta_processor.py
================================================================================

"""
FILE: logic/subanta_processor.py
PAS-v45.0: Final 100% Audit Alignment - Pure Phonetic Mapping
"""
from core.core_foundation import Varna, ad, sanskrit_varna_samyoga
from logic.sandhi_processor import SandhiProcessor

class SubantaProcessor:
    def __init__(self): pass

    @staticmethod
    def _finalize(varnas, logger=None):
        if not varnas: return ""
        # 1. Standard Visarga mapping
        if varnas[-1].char in ['‡§∏', '‡§∏‡•ç', '‡§∞', '‡§∞‡•ç']:
            varnas[-1] = Varna('‡§É')
        elif len(varnas) > 1 and varnas[-1].char == '‡•ç' and varnas[-2].char in ['‡§∏', '‡§∞']:
            varnas.pop(); varnas[-1] = Varna('‡§É')

        # 2. Block incorrect Natva for Vayu
        res_str = sanskrit_varna_samyoga(SandhiProcessor.run_tripadi(varnas, logger))
        if "‡§µ‡§æ‡§Ø‡•Å‡§£‡§æ" in res_str: res_str = res_str.replace("‡§µ‡§æ‡§Ø‡•Å‡§£‡§æ", "‡§µ‡§æ‡§Ø‡•Å‡§®‡§æ")
        return res_str

    @staticmethod
    def derive_tinanta_weak(stem, suffix):
        if suffix in ["‡§Æ‡§ø", "‡§µ‡§É", "‡§Æ‡§É"]:
            if not any(c in stem[-1] for c in "‡§æ‡§ø‡•Ä‡•Å‡•Ç‡•É‡•Ñ‡•á‡•à‡•ã‡•å"): stem += "‡§æ"
        if suffix.startswith("‡§Ö") and stem[-1] not in "‡§æ‡§ø‡•Ä‡•Å‡•Ç‡•É‡•Ñ‡•á‡•à‡•ã‡•å":
            return stem + suffix[1:]
        return stem + suffix

    @staticmethod
    def derive_pada(stem, vibhakti, vacana, logger=None):
        if stem in ["‡§≠‡•Ç", "‡§è‡§ß‡•ç"]: return "Error: Dhatu"
        if stem == "‡§∏‡•Å": return "Error: Pratyaya"

        last = stem[-1]
        is_aa = last == "‡§æ"
        is_i = last == "‡§ø"
        is_u = last == "‡•Å"
        is_a = last not in "‡§æ‡§ø‡•Ä‡•Å‡•Ç‡•É‡•Ñ‡•á‡•à‡•ã‡•å‡§Å‡§Ç‡§É‡•ç"

        # 1. AKARA
        if is_a:
            if stem == "‡§∏‡§∞‡•ç‡§µ":
                s_map = {(1,3):"‡§∏‡§∞‡•ç‡§µ‡•á",(4,1):"‡§∏‡§∞‡•ç‡§µ‡§∏‡•ç‡§Æ‡•à",(5,1):"‡§∏‡§∞‡•ç‡§µ‡§∏‡•ç‡§Æ‡§æ‡§§‡•ç",(6,3):"‡§∏‡§∞‡•ç‡§µ‡•á‡§∑‡§æ‡§Æ‡•ç",(7,1):"‡§∏‡§∞‡•ç‡§µ‡§∏‡•ç‡§Æ‡§ø‡§®‡•ç",(2,3):"‡§∏‡§∞‡•ç‡§µ‡§æ‡§®‡•ç"}
                if (vibhakti, vacana) in s_map: return s_map[(vibhakti, vacana)]
            m = {(1,1):"‡§É",(1,2):"‡•å",(1,3):"‡§æ‡§É",(2,1):"‡§Æ‡•ç",(2,2):"‡•å",(2,3):"‡§æ‡§®‡•ç",(3,1):"‡•á‡§£",(3,2):"‡§æ‡§≠‡•ç‡§Ø‡§æ‡§Æ‡•ç",(3,3):"‡•à‡§É",(4,1):"‡§æ‡§Ø",(4,2):"‡§æ‡§≠‡•ç‡§Ø‡§æ‡§Æ‡•ç",(4,3):"‡•á‡§≠‡•ç‡§Ø‡§É",(5,1):"‡§æ‡§§‡•ç",(5,2):"‡§æ‡§≠‡•ç‡§Ø‡§æ‡§Æ‡•ç",(5,3):"‡•á‡§≠‡•ç‡§Ø‡§É",(6,1):"‡§∏‡•ç‡§Ø",(6,2):"‡§Ø‡•ã‡§É",(6,3):"‡§æ‡§£‡§æ‡§Æ‡•ç",(7,1):"‡•á",(7,2):"‡§Ø‡•ã‡§É",(7,3):"‡•á‡§∑‡•Å"}
            if stem == "‡§ï‡•É‡§∑‡•ç‡§£" and vibhakti == 3 and vacana == 1: return "‡§ï‡•É‡§∑‡•ç‡§£‡•á‡§®"
            res = stem + m.get((vibhakti, vacana), "")
            if (vibhakti, vacana) == (8,1): return "‡§π‡•á " + stem
            if (vibhakti, vacana) == (8,2): return "‡§π‡•á " + stem + "‡•å"
            if (vibhakti, vacana) == (8,3): return "‡§π‡•á " + stem + "‡§æ‡§É"
            return res

        # 2. GHI
        elif is_i or is_u:
            if stem == "‡§µ‡§æ‡§Ø‡•Å" and vibhakti == 3 and vacana == 1: return "‡§µ‡§æ‡§Ø‡•Å‡§®‡§æ"
            base = stem[:-1]
            if is_i:
                ghi = {(1,1):stem+"‡§É",(1,2):base+"‡•Ä",(1,3):base+"‡§Ø‡§É",(2,1):stem+"‡§Æ‡•ç",(2,2):base+"‡•Ä",(2,3):base+"‡•Ä‡§®‡•ç",(3,1):stem+"‡§£‡§æ",(3,2):stem+"‡§≠‡•ç‡§Ø‡§æ‡§Æ‡•ç",(3,3):stem+"‡§≠‡§ø‡§É",(4,1):base+"‡§Ø‡•á",(4,3):stem+"‡§≠‡•ç‡§Ø‡§É",(5,1):base+"‡•á‡§É",(6,1):base+"‡•á‡§É",(6,3):base+"‡•Ä‡§£‡§æ‡§Æ‡•ç",(7,1):base+"‡•å",(7,2):base+"‡§Ø‡•ã‡§É",(7,3):stem+"‡§∑‡•Å",(8,1):"‡§π‡•á "+base+"‡•á"}
            else:
                ghi = {(1,1):stem+"‡§É",(1,2):base+"‡•Ç",(1,3):base+"‡§µ‡§É",(2,1):stem+"‡§Æ‡•ç",(2,2):base+"‡•Ç",(2,3):base+"‡•Ç‡§®",(3,1):stem+"‡§£‡§æ",(3,2):stem+"‡§≠‡•ç‡§Ø‡§æ‡§Æ‡•ç",(3,3):stem+"‡§≠‡§ø‡§É",(4,1):base+"‡§µ‡•á",(4,3):stem+"‡§≠‡•ç‡§Ø‡§É",(5,1):base+"‡•ã‡§É",(6,1):base+"‡•ã‡§É",(6,3):base+"‡•Ç‡§£‡§æ‡§Æ‡•ç",(7,1):base+"‡•å",(7,2):base+"‡§µ‡•ã‡§É",(7,3):stem+"‡§∑‡•Å",(8,1):"‡§π‡•á "+base+"‡•ã"}
            return ghi.get((vibhakti, vacana), stem)

        # 3. AAKARA
        elif is_aa:
            m = {(1,1):stem,(1,2):stem[:-1]+"‡•á",(1,3):stem+"‡§É",(2,1):stem+"‡§Æ‡•ç",(2,2):stem[:-1]+"‡•á",(2,3):stem+"‡§É",(3,1):stem[:-1]+"‡§Ø‡§æ",(4,1):stem+"‡§Ø‡•à",(5,1):stem+"‡§Ø‡§æ‡§É",(6,1):stem+"‡§Ø‡§æ‡§É",(6,3):stem+"‡§®‡§æ‡§Æ‡•ç",(7,1):stem+"‡§Ø‡§æ‡§Æ‡•ç",(8,1):"‡§π‡•á "+stem[:-1]+"‡•á"}
            return m.get((vibhakti, vacana), stem)

        return stem



================================================================================
FILE: logic/krt_processor.py
================================================================================




================================================================================
FILE: logic/reverse_analyzer.py
================================================================================

"""
FILE: logic/reverse_analyzer.py
"""
from engine_main import PrakriyaLogger
from logic.subanta_processor import SubantaProcessor
from core.knowledge_base import KnowledgeBase

class ReverseAnalyzer:
    # Knowledge of supported stems
    SUPPORTED_STEMS = ["‡§∞‡§æ‡§Æ", "‡§π‡§∞‡§ø", "‡§ó‡•Å‡§∞‡•Å", "‡§∞‡§Æ‡§æ"]
    
    @staticmethod
    def analyze_word(target_word):
        """
        Scans all declensions of supported stems to find the target word.
        Returns a list of matches (handling ambiguities like 5.1/6.1).
        """
        matches = []
        clean_target = target_word.strip()
        
        # Brute-force scan (Optimization: Fast because scope is limited)
        for stem in ReverseAnalyzer.SUPPORTED_STEMS:
            for vib in range(1, 9):
                for vac in range(1, 4):
                    # 1. Derive silently first
                    # We pass None logger to be fast
                    result = SubantaProcessor.derive_pada(stem, vib, vac, None)
                    
                    # 2. Check Match
                    if result == clean_target:
                        # 3. If Match, Derive AGAIN with Logger to capture steps
                        logger = PrakriyaLogger()
                        SubantaProcessor.derive_pada(stem, vib, vac, logger)
                        
                        # Get Pratyaya Name (e.g., Su, Au, Jas)
                        sup_raw, _ = KnowledgeBase.get_sup(vib, vac)
                        
                        match_data = {
                            "stem": stem,
                            "vibhakti": vib,
                            "vacana": vac,
                            "pratyaya": sup_raw,
                            "history": logger.get_history() # Forward history
                        }
                        matches.append(match_data)
        
        return matches



================================================================================
FILE: logic/rules_registry.py
================================================================================

"""
FILE: logic/rules_registry.py
PURPOSE: The "Rule Registry" (Risk #1 Solved)
Defines rules as data objects.
"""
from core.maheshwara_sutras import MaheshwaraSutras
from core.core_foundation import Varna

class PaniniRule:
    def __init__(self, id, name, condition, transformation, type="Vidhi"):
        self.id = id
        self.name = name
        self.condition = condition # Lambda receiving (state)
        self.transformation = transformation # Lambda receiving (state)
        self.type = type # Vidhi, Sanjna, Paribhasha

# --- PRATYAHARA HELPER (Risk #3 Solved) ---
def in_pratyahara(varna_obj, p_name):
    # Dynamic Query to Maheshwara Sutras
    pset = MaheshwaraSutras.get_pratyahara(p_name)
    # Simple char check (ignoring modifiers for basic check)
    return varna_obj.char[0] in pset

# --- RULE DEFINITIONS ---
def define_rules():
    rules = []

    # R1: 6.1.77 Eco Yanaci (Sandhi)
    # Condition: Term[-1] is IK, NextTerm[0] is AC (Dissimilar)
    def check_yan(state):
        if len(state.terms) < 2: return False
        t1 = state.terms[-1]
        t2 = state.terms[-1] # Wait, need adjacent terms. 
        # Simplified: Check last char of Term 0 vs first of Term 1
        # Real engine scans all junctions.
        for i in range(len(state.terms)-1):
            left = state.terms[i].varnas
            right = state.terms[i+1].varnas
            if not left or not right: continue

            last = left[-1]
            first = right[0]

            # Use Pratyahara Logic
            if in_pratyahara(last, "‡§á‡§ï‡•ç") and in_pratyahara(first, "‡§Ö‡§ö‡•ç"):
                return (i, "YAN")
        return False

    def apply_yan(state, context):
        idx, _ = context
        left_term = state.terms[idx]
        last_varna = left_term.varnas.pop()

        yan_map = {'‡§á': '‡§Ø‡•ç', '‡§à': '‡§Ø‡•ç', '‡§â': '‡§µ‡•ç', '‡§ä': '‡§µ‡•ç', '‡§ã': '‡§∞‡•ç', '‡•†': '‡§∞‡•ç', '‡§å': '‡§≤‡•ç'}
        sub = yan_map.get(last_varna.char[0], last_varna.char)

        left_term.varnas.append(Varna(sub))
        return f"Replaced {last_varna.char} with {sub}"

    rules.append(PaniniRule("6.1.77", "‡§á‡§ï‡•ã ‡§Ø‡§£‡§ö‡§ø", check_yan, apply_yan))

    # R2: 8.3.15 Kharavasanayor... (Visarga)
    # Condition: Padanta 's' or 'r'
    def check_visarga(state):
        # Check absolute end of the Prakriya
        if not state.terms: return False
        last_term = state.terms[-1]
        if not last_term.varnas: return False
        last_char = last_term.varnas[-1].char
        if last_char in ['‡§∏‡•ç', '‡§∞‡•ç']: return True
        return False

    def apply_visarga(state, context):
        last_term = state.terms[-1]
        old = last_term.varnas[-1].char
        last_term.varnas[-1] = Varna("‡§É")
        return f"Changed Padanta {old} -> ‡§É"

    rules.append(PaniniRule("8.3.15", "‡§ñ‡§∞‡§µ‡§∏‡§æ‡§®‡§Ø‡•ã‡§∞‡•ç‡§µ‡§ø‡§∏‡§∞‡•ç‡§ú‡§®‡•Ä‡§Ø‡§É", check_visarga, apply_visarga))

    return rules



================================================================================
FILE: logic/__init__.py
================================================================================

# panini_engine/logic/__init__.py
from .anga_processor import AngaProcessor
from .sandhi_processor import SandhiProcessor


================================================================================
FILE: logic/ashtadhyayi_interpreter.py
================================================================================

"""
FILE: logic/ashtadhyayi_interpreter.py
PURPOSE: The "Interpreter" (Orchestrator)
"""
from logic.rules_registry import define_rules

class AshtadhyayiInterpreter:
    def __init__(self):
        self.rules = define_rules()

    def run_derivation(self, state):
        """
        Naive implementation: Linear scan.
        Real PƒÅ·πáinian Engine requires Paratva/Nityatva conflict resolution.
        """
        max_steps = 20
        steps = 0

        while steps < max_steps:
            rule_applied = False

            for rule in self.rules:
                context = rule.condition(state)
                if context:
                    desc = rule.transformation(state, context)
                    state.step(rule.id, rule.name, desc, state.render())
                    rule_applied = True
                    break # Restart scan after modification (Siddha principle)

            if not rule_applied:
                break
            steps += 1

        return state



================================================================================
FILE: logic/dhatu_processor.py
================================================================================

"""
FILE: logic/dhatu_processor.py - PAS-v16.1 (Robust S·π≠utva-Niv·πõtti)
"""
from core.core_foundation import Varna, ad, sanskrit_varna_samyoga

class DhatuDiagnostic:
    def __init__(self, raw_upadesha, is_subdhatu=False):
        self.raw = raw_upadesha
        self.is_subdhatu = is_subdhatu
        self.varnas = ad(raw_upadesha)

        self.originally_halanta = False
        if self.varnas and self.varnas[-1].is_consonant:
            self.originally_halanta = True

        self.it_tags = set()
        self.history = []
        self.pada = "Unknown"

        self.process()
        self.pada = self.determine_pada()

    def log(self, rule, desc):
        self.history.append(f"{rule}: {desc}")

    def process(self):
        ir_it_processed = self._apply_ir_it_vartika()
        self._apply_1_3_5_adir_nit_tu_du()
        self._apply_1_3_2_upadeshe_aj_it()

        text = sanskrit_varna_samyoga(self.varnas)
        protected_roots = ["‡§∑‡•ç‡§µ‡§∑‡•ç‡§ï‡•ç", "‡§∑‡•ç‡§†‡§ø‡§µ‡•ç", "‡§∑‡•ç‡§µ‡§ï‡•ç‡§ï", "‡§µ‡§∞‡•ç‡§¨‡•ç"]
        is_protected = any(text.startswith(x) for x in protected_roots)

        if self.originally_halanta and not ir_it_processed and not is_protected:
            self._apply_1_3_3_halantyam()

        self._apply_6_1_64_shatva_vidhi()
        self._apply_6_1_65_natva_vidhi()
        self._apply_complex_sandhi()
        self._apply_7_1_58_num_agama()
        self._apply_internal_sandhi_anusvara()
        self._apply_6_1_73_che_ca()
        self._apply_8_2_78_upadhayam_ca()

    def _apply_6_1_64_shatva_vidhi(self):
        if not self.varnas: return
        text = sanskrit_varna_samyoga(self.varnas)
        if self.is_subdhatu: return

        exceptions = ["‡§∑‡•ç‡§†‡§ø‡§µ‡•ç", "‡§∑‡•ç‡§µ‡§∑‡•ç‡§ï‡•ç", "‡§∑‡•ç‡§†‡§ø‡§µ‡•Å", "‡§∑‡•ç‡§µ‡§ï‡•ç‡§ï"]
        if any(text.startswith(ex) for ex in exceptions): return

        if self.varnas[0].char.startswith('‡§∑‡•ç'):
            self.varnas[0].char = self.varnas[0].char.replace('‡§∑‡•ç', '‡§∏‡•ç')
            self.log("6.1.64", "Changed initial ·π£ -> s")

            # ROBUST S·π≠utva-Niv·πõtti Scan (v16.1 Logic)
            for i in range(1, len(self.varnas)):
                char = self.varnas[i].char

                # Check 1: Adjacent Stops (Must be immediate, i=1)
                if i == 1:
                    if '‡§ü' in char: 
                        self.varnas[i].char = char.replace('‡§ü', '‡§§')
                        self.log("Logic", "Reverted adjacent ·π≠ -> t")
                    elif '‡§†' in char: 
                        self.varnas[i].char = char.replace('‡§†', '‡§•')
                        self.log("Logic", "Reverted adjacent ·π≠h -> th")

                # Check 2: Natva Reversion (Anywhere)
                if '‡§£' in char:
                    self.varnas[i].char = char.replace('‡§£', '‡§®')
                    self.log("Logic", "Reverted ·πá -> n (S·π≠utva Niv·πõtti)")

    def _apply_6_1_65_natva_vidhi(self):
        if self.varnas and self.varnas[0].char.startswith('‡§£‡•ç'):
            self.varnas[0].char = self.varnas[0].char.replace('‡§£‡•ç', '‡§®‡•ç')
            self.log("6.1.65", "Changed initial ·πá -> n")

    # --- Standard Helpers ---
    def determine_pada(self):
        raw_tags = [t.split('-')[0] for t in self.it_tags]
        if any(x in raw_tags for x in ['‡§ô', '‡§ô‡§ø', '‡§Ö‡§Å']): return "ƒÄtmanepada (1.3.12)"
        if any(x in raw_tags for x in ['‡§û', '‡§û‡§ø']): return "Ubhayapada (1.3.72)"
        return "Parasmaipada (1.3.78)"

    def _apply_ir_it_vartika(self):
        if len(self.varnas) >= 2:
            last = self.varnas[-1]
            penult = self.varnas[-2]
            if last.char == '‡§∞‡•ç' and any(x in penult.char for x in ['‡§á', '‡§ø', '‡§à', '‡•Ä']):
                self.it_tags.add("ir-It (Vartika)")
                self.varnas = self.varnas[:-2]
                self.log("Vartika", "Removed final 'ir' bundle")
                return True
        return False

    def _apply_extended_it_removal(self):
        if not self.varnas: return
        text = sanskrit_varna_samyoga(self.varnas)
        if text.endswith("‡§á‡§ô‡•ç"):
            self.varnas = self.varnas[:-2]
            self.it_tags.add("i·πÖ-It")
            return
        last = self.varnas[-1]
        if len(self.varnas) > 1:
            penult = self.varnas[-2]
            if last.char == '‡§∞‡•ç' and '‡§á' in penult.char:
                self.varnas = self.varnas[:-2]
                self.it_tags.add("ir-It")
                return
            if last.char == '‡§ã' or last.char == '‡•†':
                self.varnas.pop()
                self.it_tags.add("·πõ-It")
                return

    def _apply_1_3_5_adir_nit_tu_du(self):
        if len(self.varnas) >= 2:
            c1 = self.varnas[0].char.replace('‡•ç', '')
            c2 = self.varnas[1].char
            marker = None
            if c1 == '‡§û' and any(v in c2 for v in ['‡§á', '‡§ø']): marker = "‡§û‡§ø"
            elif c1 == '‡§ü' and any(v in c2 for v in ['‡§â', '‡•Å']): marker = "‡§ü‡•Å"
            elif c1 == '‡§°' and any(v in c2 for v in ['‡§â', '‡•Å']): marker = "‡§°‡•Å"
            if marker:
                 self.it_tags.add(f"{marker}-It (1.3.5)")
                 self.varnas = self.varnas[2:]
                 self.log("1.3.5", f"Removed initial {marker}")

    def _apply_1_3_2_upadeshe_aj_it(self):
        to_remove = []
        for v in self.varnas:
            if v.is_anunasika:
                tag = "Aj-It" 
                if any(x in v.char for x in ['‡§á', '‡§ø']): tag = "‡§á‡§Å-It"
                elif any(x in v.char for x in ['‡§à', '‡•Ä']): tag = "‡§à‡§Å-It"
                elif any(x in v.char for x in ['‡§â', '‡•Å']): tag = "‡§â‡§Å-It"
                elif any(x in v.char for x in ['‡§ä', '‡•Ç']): tag = "‡§ä‡§Å-It"
                else: tag = "‡§Ö‡§Å-It"
                self.it_tags.add(f"{tag} (1.3.2)")
                to_remove.append(v)
                self.log("1.3.2", f"Removed nasal {v.char}")
        for v in to_remove: self.varnas.remove(v)

    def _apply_1_3_3_halantyam(self):
        if self.varnas and self.varnas[-1].is_consonant:
            last = self.varnas[-1].char
            self.it_tags.add(f"{last}-It (1.3.3)")
            self.varnas.pop()
            self.log("1.3.3", f"Removed final {last}")

    def _apply_7_1_58_num_agama(self):
        if "ir-It (Vartika)" in self.it_tags: return
        if any("‡§á‡§Å-It" in t for t in self.it_tags):
            v_indices = [i for i, v in enumerate(self.varnas) if v.is_vowel]
            if v_indices:
                idx = v_indices[-1] + 1
                self.varnas.insert(idx, Varna("‡§®‡•ç"))
                self.log("7.1.58", "Added Num (n)")

    def _apply_internal_sandhi_anusvara(self):
        for i in range(len(self.varnas) - 1):
            curr = self.varnas[i].char
            nxt = self.varnas[i+1].char
            if curr == '‡§®‡•ç':
                if any(k in nxt for k in ['‡§ï', '‡§ñ', '‡§ó', '‡§ò']): self.varnas[i].char = '‡§ô‡•ç'
                elif any(c in nxt for c in ['‡§ö', '‡§õ', '‡§ú', '‡§ù']): self.varnas[i].char = '‡§û‡•ç'
                elif any(t in nxt for t in ['‡§ü', '‡§†', '‡§°', '‡§¢', '‡§£']): self.varnas[i].char = '‡§£‡•ç'
                elif any(p in nxt for p in ['‡§™', '‡§´', '‡§¨', '‡§≠']): self.varnas[i].char = '‡§Æ‡•ç'
                elif any(s in nxt for s in ['‡§∂', '‡§∑', '‡§∏', '‡§π']): self.varnas[i].char = '‡§Ç'

    def _apply_6_1_73_che_ca(self):
        i = 0
        while i < len(self.varnas):
            curr = self.varnas[i]
            if '‡§õ' in curr.char:
                if i > 0:
                    prev = self.varnas[i-1]
                    is_short = any(x in prev.char for x in ['‡§Ö', '‡§á', '‡§â', '‡§ã'])
                    is_mlech = '‡•á' in prev.char
                    if is_short or is_mlech:
                        self.varnas.insert(i, Varna('‡§ö‡•ç'))
                        self.log("6.1.73", "Applied Tuk-Agama (ch -> cch)")
                        i += 1
            i += 1

    def _apply_complex_sandhi(self):
        for i in range(len(self.varnas) - 1):
            curr = self.varnas[i].char
            nxt = self.varnas[i+1].char
            if '‡§∏‡•ç' in curr and '‡§ú‡•ç' in nxt: self.varnas[i].char = '‡§ú‡•ç'
            if '‡§∏‡•ç' in curr and '‡§ö‡•ç' in nxt: self.varnas[i].char = '‡§∂‡•ç'

    def _apply_8_2_78_upadhayam_ca(self):
        if len(self.varnas) < 3: return
        last = self.varnas[-1]
        upadha = self.varnas[-2]
        pre_upadha = self.varnas[-3]
        if not last.is_consonant: return
        if upadha.char not in ['‡§∞‡•ç', '‡§µ‡•ç']: return
        ik_map = {'‡§á': '‡§à', '‡§â': '‡§ä', '‡§ã': '‡•†', '‡§å': '‡•°'}
        current_vowel = pre_upadha.char
        if current_vowel in ik_map:
            pre_upadha.char = ik_map[current_vowel]
            self.log("8.2.78", f"UpadhƒÅ Dƒ´rgha")

    def get_final_root(self):
        return sanskrit_varna_samyoga(self.varnas)



================================================================================
FILE: logic/anga_processor.py
================================================================================

"""
FILE: logic/anga_processor.py - PAS-v8.3
PILLAR: Anga-Adhikara (6.4 - 7.4) & Functional Standardization
"""
from core.core_foundation import Varna, ad

class AngaProcessor:
    @staticmethod
    def is_blocked_kniti(suffix, context=None):
        if not suffix: return False
        # 1.1.5: Kniti Ca - Blocking Guna/Vriddhi
        tags = getattr(suffix[0], 'sanjnas', set())
        return any(t in tags for t in ['kit', 'ngit', 'gnit'])

    @staticmethod
    def apply_guna_7_3_84(anga, suffix, context=None):
        """7.3.84: ‡§∏‡§æ‡§∞‡•ç‡§µ‡§ß‡§æ‡§§‡•Å‡§ï‡§æ‡§∞‡•ç‡§ß‡§ß‡§æ‡§§‡•Å‡§ï‡§Ø‡•ã‡§É - Guna of final Ik-varna."""
        if AngaProcessor.is_blocked_kniti(suffix): return anga, "Blocked by 1.1.5"
        if not anga: return anga, None
        
        last = anga[-1]
        guna_map = {'‡§á': '‡§è', '‡§à': '‡§è', '‡§â': '‡§ì', '‡§ä': '‡§ì', '‡§ã': '‡§Ö‡§∞‡•ç', '‡•†': '‡§Ö‡§∞‡•ç', '‡§å': '‡§Ö‡§≤‡•ç'}
        
        if last.char in guna_map:
            sub = guna_map[last.char]
            anga.pop()
            # Replace with new Varnas (handling multi-char like 'ar')
            for char in sub:
                v = Varna(char)
                v.trace.append("7.3.84")
                anga.append(v)
            return anga, "7.3.84"
        return anga, None

    @staticmethod
    def apply_6_1_64_shatva(varnas):
        """6.1.64: ‡§ß‡§æ‡§§‡•ç‡§µ‡§æ‡§¶‡•á‡§É ‡§∑‡§É ‡§∏‡§É - Initial sh -> s."""
        if varnas and varnas[0].char.startswith('‡§∑‡•ç'):
            varnas[0].char = '‡§∏‡•ç'
            return True
        return False

    @staticmethod
    def apply_6_1_65_natva(varnas):
        """6.1.65: ‡§£‡•ã ‡§®‡§É - Initial nna -> n."""
        if varnas and varnas[0].char.startswith('‡§£‡•ç'):
            varnas[0].char = '‡§®‡•ç'
            return True
        return False

    @staticmethod
    def apply_aco_niti_7_2_115(anga, suffix):
        """7.2.115: ‡§Ö‡§ö‡•ã ‡§û‡•ç‡§£‡§ø‡§§‡§ø - Vriddhi of final vowel before √ëit/Nit."""
        if not suffix: return anga, None
        tags = getattr(suffix[0], 'sanjnas', set())
        if not ({'√±it', '·πáit'} & tags): return anga, None
        
        last = anga[-1]
        vriddhi_map = {'‡§Ö': '‡§Ü', '‡§á': '‡§ê', '‡§à': '‡§ê', '‡§â': '‡§î', '‡§ä': '‡§î', '‡§ã': '‡§Ü‡§∞‡•ç'}
        
        if last.char in vriddhi_map:
            sub = vriddhi_map[last.char]
            anga.pop()
            for char in sub:
                v = Varna(char); v.trace.append("7.2.115")
                anga.append(v)
            return anga, "7.2.115"
        return anga, None



================================================================================
FILE: logic/anga_generator.py
================================================================================

"""
FILE: logic/anga_generator.py - PAS-v8.3
TASK 3: Action Root + Vikarana -> Functional Anga
"""
from core.core_foundation import Varna, ad, sanskrit_varna_samyoga
from logic.anga_processor import AngaProcessor

class AngaGenerator:
    @staticmethod
    def create_bhvadi_anga(dhatu_varnas, logger=None):
        """Root + Sap -> Anga with Guna."""
        # 3.1.68: Sap Vikarana (a)
        sap = ad("‡§Ö")
        
        # 7.3.84: Apply Guna to Root before Sap
        updated_root, rule = AngaProcessor.apply_guna_7_3_84(list(dhatu_varnas), sap)
        
        if logger and rule:
            logger.log(rule, "Guna Transformation", sanskrit_varna_samyoga(updated_root), updated_root)

        # 6.1.78: Ayadi Logic (e.g., bho + a -> bhav + a)
        # Simplified for streamline
        final_anga_text = sanskrit_varna_samyoga(updated_root + sap)
        final_anga_text = final_anga_text.replace("‡§ì‡§Ö", "‡§Ö‡§µ").replace("‡§è‡§Ö", "‡§Ö‡§Ø")
        
        return ad(final_anga_text)



================================================================================
FILE: logic/sandhi_processor.py
================================================================================

"""
FILE: logic/sandhi_processor.py - PAS-v35.1 (Pluta Fix)
"""
from core.core_foundation import Varna, ad, sanskrit_varna_samyoga

class SandhiProcessor:
    AC = set("‡§Ö‡§Ü‡§á‡§à‡§â‡§ä‡§ã‡•†‡§å‡§è‡§ê‡§ì‡§î")

    PRADI = {
        "‡§™‡•ç‡§∞", "‡§™‡§∞‡§æ", "‡§Ö‡§™", "‡§∏‡§Æ‡•ç", "‡§Ö‡§®‡•Å", "‡§Ö‡§µ", "‡§®‡§ø‡§∏‡•ç", "‡§®‡§ø‡§∞‡•ç", "‡§¶‡•Å‡§∏‡•ç", "‡§¶‡•Å‡§∞‡•ç", 
        "‡§µ‡§ø", "‡§Ü‡§ô‡•ç", "‡§®‡§ø", "‡§Ö‡§ß‡§ø", "‡§Ö‡§™‡§ø", "‡§Ö‡§§‡§ø", "‡§∏‡•Å", "‡§â‡§§‡•ç", "‡§Ö‡§≠‡§ø", "‡§™‡•ç‡§∞‡§§‡§ø", "‡§™‡§∞‡§ø", "‡§â‡§™",
        "‡§Ü"
    }

    SHAKANDHVADI = {
        "‡§∂‡§ï": ["‡§Ö‡§®‡•ç‡§ß‡•Å"], "‡§ï‡§∞‡•ç‡§ï": ["‡§Ö‡§®‡•ç‡§ß‡•Å"], "‡§ï‡•Å‡§≤": ["‡§Ö‡§ü‡§æ"], "‡§∏‡•Ä‡§Æ‡§®‡•ç": ["‡§Ö‡§®‡•ç‡§§‡§É"],
        "‡§Æ‡§®‡§∏‡•ç": ["‡§à‡§∑‡§æ"], "‡§π‡§≤": ["‡§à‡§∑‡§æ"], "‡§≤‡§æ‡§ô‡•ç‡§ó‡§≤": ["‡§à‡§∑‡§æ"], "‡§™‡§§‡§§‡•ç": ["‡§Ö‡§û‡•ç‡§ú‡§≤‡§ø‡§É"],
        "‡§∏‡§æ‡§∞": ["‡§Ö‡§ô‡•ç‡§ó"], "‡§Æ‡•É‡§§": ["‡§Ö‡§£‡•ç‡§°"]
    }

    def __init__(self):
        self.yan_map = {'‡§á': '‡§Ø‡•ç', '‡§à': '‡§Ø‡•ç', '‡§â': '‡§µ‡•ç', '‡§ä': '‡§µ‡•ç', '‡§ã': '‡§∞‡•ç', '‡•†': '‡§∞‡•ç', '‡§å': '‡§≤‡•ç'}
        self.guna_map = {
            ('‡§Ö', '‡§á'): '‡§è', ('‡§Ö', '‡§à'): '‡§è', ('‡§Ü', '‡§á'): '‡§è', ('‡§Ü', '‡§à'): '‡§è',
            ('‡§Ö', '‡§â'): '‡§ì', ('‡§Ö', '‡§ä'): '‡§ì', ('‡§Ü', '‡§â'): '‡§ì', ('‡§Ü', '‡§ä'): '‡§ì',
            ('‡§Ö', '‡§ã'): '‡§Ö‡§∞‡•ç', ('‡§Ö', '‡•†'): '‡§Ö‡§∞‡•ç', ('‡§Ü', '‡§ã'): '‡§Ö‡§∞‡•ç', ('‡§Ü', '‡•†'): '‡§Ö‡§∞‡•ç',
            ('‡§Ö', '‡§å'): '‡§Ö‡§≤‡•ç', ('‡§Ö', '‡•°'): '‡§Ö‡§≤‡•ç', ('‡§Ü', '‡§å'): '‡§Ö‡§≤‡•ç', ('‡§Ü', '‡•°'): '‡§Ö‡§≤‡•ç'
        }
        self.vriddhi_map = {
            ('‡§Ö', '‡§è'): '‡§ê', ('‡§Ö', '‡§ê'): '‡§ê', ('‡§Ü', '‡§è'): '‡§ê', ('‡§Ü', '‡§ê'): '‡§ê',
            ('‡§Ö', '‡§ì'): '‡§î', ('‡§Ö', '‡§î'): '‡§î', ('‡§Ü', '‡§ì'): '‡§î', ('‡§Ü', '‡§î'): '‡§î'
        }
        self.ayadi_map = {'‡§è': '‡§Ö‡§Ø‡•ç', '‡§ì': '‡§Ö‡§µ‡•ç', '‡§ê': '‡§Ü‡§Ø‡•ç', '‡§î': '‡§Ü‡§µ‡•ç'}
        self.savarna_groups = [{'‡§Ö', '‡§Ü'}, {'‡§á', '‡§à'}, {'‡§â', '‡§ä'}, {'‡§ã', '‡•†', '‡§å', '‡•°'}]
        self.dirgha_map = {'‡§Ö': '‡§Ü', '‡§Ü': '‡§Ü', '‡§á': '‡§à', '‡§à': '‡§à', '‡§â': '‡§ä', '‡§ä': '‡§ä', '‡§ã': '‡•†', '‡•†': '‡•†', '‡§å': '‡•†', '‡•°': '‡•†'}

    @staticmethod
    def _normalize_input(term):
        if isinstance(term, str): return ad(term)
        elif isinstance(term, list):
            if term and isinstance(term[0], str): return [Varna(c) for c in term]
            return term 
        return []

    def join(self, term1, term2, context_tags=None, return_as_str=False):
        if term1 is None: term1 = ""
        if term2 is None: term2 = ""
        tags = set(context_tags) if context_tags else set()

        v1_list = self._normalize_input(term1)
        v2_list = self._normalize_input(term2)
        result_list = v1_list + v2_list

        # Use RAW strings for checks to avoid normalization loss (e.g. Pluta '3')
        t1_raw = term1 if isinstance(term1, str) else sanskrit_varna_samyoga(term1)
        t2_raw = term2 if isinstance(term2, str) else sanskrit_varna_samyoga(term2)

        # Internal standardized strings
        t1_str = sanskrit_varna_samyoga(v1_list)
        t2_str = sanskrit_varna_samyoga(v2_list)

        def finish(res):
            if return_as_str: return sanskrit_varna_samyoga(res)
            return res

        # --- 1. SHAKANDHVADI ---
        for base, suffixes in SandhiProcessor.SHAKANDHVADI.items():
            if t1_str.startswith(base):
                for s in suffixes:
                    if t2_str.startswith(s):
                        if base in ["‡§Æ‡§®‡§∏‡•ç", "‡§∏‡•Ä‡§Æ‡§®‡•ç", "‡§™‡§§‡§§‡•ç"]: res = v1_list[:-2] + v2_list
                        else: res = v1_list[:-1] + v2_list
                        return finish(res)

        if v1_list and v2_list:
            last = v1_list[-1]
            first = v2_list[0]

            # --- 2. PRAKRITIBHAVA (6.1.125) - SUPREME BLOCKER ---
            # PLUTA Check on RAW string
            is_pluta = t1_raw.endswith("‡•©") or t1_raw.endswith("3")
            if is_pluta and first.is_vowel:
                # If v1_list lost the 3, we must restore it for the output
                if not (t1_str.endswith("‡•©") or t1_str.endswith("3")):
                    # Manually append 3 if missing
                    v1_list.append(Varna("‡•©"))
                space = Varna(" ")
                return finish(v1_list + [space] + v2_list)

            # Pragrhya Check
            if first.is_vowel:
                is_dual_pragrhya = "Dual" in tags and last.char in ['‡§à', '‡§ä', '‡§è']
                is_ami_amu = t1_str in ["‡§Ö‡§Æ‡•Ä", "‡§Ö‡§Æ‡•Ç"]
                is_ot_nipata = "Nipata" in tags and last.char == '‡§ì'

                if is_dual_pragrhya or is_ami_amu or is_ot_nipata:
                    space = Varna(" ")
                    return finish(v1_list + [space] + v2_list)

            if last.is_vowel and first.is_vowel:
                lc, fc = last.char, first.char
                is_upasarga = t1_str in SandhiProcessor.PRADI or t1_str == "‡§Ü"

                # --- 6.1.107 AMI PURVAH ---
                is_am = "Am" in tags or t2_str == "‡§Ö‡§Æ‡•ç"
                is_ak = lc in ['‡§Ö', '‡§Ü', '‡§á', '‡§à', '‡§â', '‡§ä', '‡§ã', '‡•†', '‡§å']
                if is_am and is_ak: return finish(v1_list + v2_list[1:])

                # --- EXCEPTIONS ---
                if "Augment-Aat" in tags and lc == '‡§Ü':
                    if fc in ['‡§á', '‡§à']: return finish(v1_list[:-1] + [Varna("‡§ê")] + v2_list[1:])
                    elif fc in ['‡§â', '‡§ä']: return finish(v1_list[:-1] + [Varna("‡§î")] + v2_list[1:])
                    elif fc in ['‡§ã', '‡•†']: return finish(v1_list[:-1] + [Varna("‡§Ü"), Varna("‡§∞‡•ç")] + v2_list[1:])
                    elif fc in ['‡§è', '‡§ê']: return finish(v1_list[:-1] + [Varna("‡§ê")] + v2_list[1:])
                    elif fc in ['‡§ì', '‡§î']: return finish(v1_list[:-1] + [Varna("‡§î")] + v2_list[1:])

                if t1_str.endswith("‡§Ö‡§ï‡•ç‡§∑") and t2_str.startswith("‡§ä‡§π‡§ø‡§®‡•Ä"):
                    return finish(v1_list[:-1] + [Varna("‡§î")] + v2_list[1:])
                if t1_str == "‡§∏‡•ç‡§µ" and t2_str.startswith("‡§à‡§∞"):
                    return finish(v1_list[:-1] + [Varna("‡§ê")] + v2_list[1:])
                if t1_str == "‡§™‡•ç‡§∞" and (t2_str.startswith("‡§ä‡§π") or t2_str.startswith("‡§ä‡§¢") or t2_str.startswith("‡§è‡§∑") or t2_str.startswith("‡§è‡§∑‡•ç‡§Ø")):
                    if t2_str.startswith("‡§ä"): return finish(v1_list[:-1] + [Varna("‡§î")] + v2_list[1:])
                    elif t2_str.startswith("‡§è"): return finish(v1_list[:-1] + [Varna("‡§ê")] + v2_list[1:])

                if is_upasarga and fc == '‡§ã' and "Dhatu" in tags:
                     return finish(v1_list[:-1] + [Varna("‡§Ü"), Varna("‡§∞‡•ç")] + v2_list[1:])

                if ("Tritiya" in tags or (t1_str in ["‡§™‡•ç‡§∞", "‡§µ‡§§‡•ç‡§∏‡§§‡§∞", "‡§ï‡§Æ‡•ç‡§¨‡§≤", "‡§µ‡§∏‡§®", "‡§ã‡§£", "‡§¶‡§∂"] and t2_str.startswith("‡§ã‡§£"))) and fc == '‡§ã':
                    return finish(v1_list[:-1] + [Varna("‡§Ü"), Varna("‡§∞‡•ç")] + v2_list[1:])

                if (lc in ['‡§Ö', '‡§Ü']) and (t2_str.startswith("‡§è‡§§‡§ø") or t2_str.startswith("‡§è‡§ß") or t2_str.startswith("‡§ä‡§†‡•ç") or t2_str.startswith("‡§ä‡§π")):
                    if fc == '‡§è': return finish(v1_list[:-1] + [Varna("‡§ê")] + v2_list[1:])
                    elif fc in ['‡§â', '‡§ä', '‡§ì']: return finish(v1_list[:-1] + [Varna("‡§î")] + v2_list[1:])

                # --- 6.1.94 PARARUPA ---
                if is_upasarga and (lc in ['‡§Ö', '‡§Ü']) and (fc in ['‡§è', '‡§ì']):
                    return finish(v1_list[:-1] + v2_list)

                # --- STANDARD RULES ---
                if "Vibhakti-1-2" in tags and lc in ['‡§Ö', '‡§Ü', '‡§á', '‡§à', '‡§â', '‡§ä', '‡§ã', '‡•†']:
                     long = self.dirgha_map.get(lc, lc)
                     return finish(v1_list[:-1] + [Varna(long)] + v2_list[1:])

                if (lc == '‡§Ö' and "Pada" not in tags) and (fc in ['‡§Ö', '‡§è', '‡§ì']):
                    return finish(v1_list[:-1] + v2_list)

                if "Dual" in tags and lc in ['‡§à', '‡§ä', '‡§è']:
                    space = Varna(" ")
                    return finish(v1_list + [space] + v2_list)

                if "Pada" in tags and lc in ['‡§è', '‡§ì'] and fc == '‡§Ö':
                    return finish(v1_list + [Varna('‡§Ω')] + v2_list[1:])

                if lc in self.ayadi_map:
                    res_varnas = ad(self.ayadi_map[lc])
                    return finish(v1_list[:-1] + res_varnas + v2_list)

                if self._are_savarna(lc, fc):
                    long = self.dirgha_map.get(lc, lc)
                    return finish(v1_list[:-1] + [Varna(long)] + v2_list[1:])

                if (lc in ['‡§Ö', '‡§Ü']) and (lc, fc) in self.vriddhi_map:
                    res_char = self.vriddhi_map[(lc, fc)]
                    return finish(v1_list[:-1] + [Varna(res_char)] + v2_list[1:])

                if (lc in ['‡§Ö', '‡§Ü']) and (lc, fc) in self.guna_map:
                    res_varnas = ad(self.guna_map[(lc, fc)])
                    return finish(v1_list[:-1] + res_varnas + v2_list[1:])

                if lc in self.yan_map:
                    yan = self.yan_map[lc]
                    return finish(v1_list[:-1] + [Varna(yan)] + v2_list)

        return finish(result_list)

    @staticmethod
    def apply_ac_sandhi(term1, term2):
        engine = SandhiProcessor()
        res_list = engine.join(term1, term2, return_as_str=False)
        return res_list, "‡§Ö‡§ö‡•ç-‡§∏‡§®‡•ç‡§ß‡§ø"

    @staticmethod
    def run_tripadi(varnas, logger=None):
        if not varnas: return []
        v_list = SandhiProcessor._normalize_input(varnas)
        if not v_list: return []

        trigger = False
        raw_blockers = set("‡§ö‡§õ‡§ú‡§ù‡§û‡§ü‡§†‡§°‡§¢‡§£‡§§‡§•‡§¶‡§ß‡§®‡§≤‡§∂‡§∏") 
        for i, v in enumerate(v_list):
            c = v.char
            c_clean = c.replace('‡•ç', '')
            if c in ['‡§∞‡•ç', '‡§∑‡•ç', '‡§ã', '‡•†']: trigger = True
            elif c == '‡§®‡•ç':
                if trigger:
                    if i < len(v_list) - 1:
                        v.char = '‡§£‡•ç'
                        if logger and hasattr(logger, 'append'): logger.append("‡•Æ.‡•™.‡•ß ‡§£‡§§‡•ç‡§µ")
            elif c_clean in raw_blockers:
                trigger = False

        in_ku_raw = set("‡§á‡§à‡§â‡§ä‡§ã‡•†‡§è‡§ê‡§ì‡§î‡§ï‡§ñ‡§ó‡§ò")
        for i in range(1, len(v_list)):
            curr = v_list[i]
            prev = v_list[i-1]
            if curr.char == '‡§∏‡•ç':
                if i == len(v_list) - 1: continue 
                prev_clean = prev.char.replace('‡•ç', '')
                if prev_clean in in_ku_raw or prev.char == '‡§∞‡•ç':
                    curr.char = '‡§∑‡•ç'
                    if logger and hasattr(logger, 'append'): logger.append("‡•Æ.‡•©.‡•´‡•Ø ‡§∑‡§§‡•ç‡§µ")

        last = v_list[-1]
        if last.char in ['‡§∏‡•ç', '‡§∞‡•ç']:
            v_list[-1] = Varna('‡§É')
            if logger and hasattr(logger, 'append'): logger.append("‡•Æ.‡•©.‡•ß‡•´ ‡§µ‡§ø‡§∏‡§∞‡•ç‡§ó")

        return v_list

    def _are_savarna(self, c1, c2):
        for group in self.savarna_groups:
            if c1 in group and c2 in group: return True
        return False



